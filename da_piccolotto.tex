% Technische Universität Dresden
% Fakultät Informatik
% Institut für Software- und Multimediatechnik
% Seniorprofessur für Multimediatechnik
%
% Example document demonstrating the usage of mmthesis.sty
% 2012-10-26 Andreas Rümpel
% 
% ### build hints (% = filename of tex file) ###
% pdflatex: pdflatex %.tex
% biber: biber % (biber is a modern backend for bibtex, http://biblatex-biber.sourceforge.net)
% glossaries and acronyms: makeglossaries %
%
% Das LATEX2e-Sündenregister: ftp://ftp.dante.de/tex-archive/info/l2tabu/german/l2tabu.pdf
% KOMAScript-Guide: ftp://ftp.dante.de/tex-archive/macros/latex/contrib/koma-script/scrguide.påådf
% Einige typographische Grundregeln und ihre Umsetzung in LaTeX: http://www2.informatik.hu-berlin.de/sv/lehre/typographie.pdf

\documentclass[
	headsepline,
	footsepline,
	fontsize=12pt,
	%draft, % use this for finding overfull boxes
	%parskip, % use this for alternative paragraph formatting
	bibliography=totoc
]{scrbook}

\usepackage{mmthesis}
\usepackage{listings}
\usepackage{color}
\lstset{ %
  backgroundcolor=\color{white},   % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}
  basicstyle=\footnotesize,        % the size of the fonts that are used for the code
  breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  captionpos=b,                    % sets the caption-position to bottom
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
  frame=single,                    % adds a frame around the code
  firstnumber=1,
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  keywordstyle=\color{blue},       % keyword style
  language=Octave,                 % the language of the code
  morekeywords={*,...},            % if you want to add more keywords to the set
  numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
  numbersep=8pt,                   % how far the line-numbers are from the code
  %numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
  numberfirstline=false,
  rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  stepnumber=5,                    % the step between two line-numbers. If it's 1, each line will be numbered
  stringstyle=\color{gray},     		% string literal style
  tabsize=2,                       % sets default tabsize to 2 spaces
  title=\lstname                   % show the filename of files included with \lstinputlisting; also try caption instead of title
}
\colorlet{punct}{red!60!black}
\definecolor{delim}{RGB}{20,105,176}
\lstdefinelanguage{json}{
    basicstyle=\small\ttfamily,
    showstringspaces=false,
    breaklines=true,
    literate=
     *{:}{{{\color{punct}{:}}}}{1}
      {,}{{{\color{punct}{,}}}}{1}
      {\{}{{{\color{delim}{\{}}}}{1}
      {\}}{{{\color{delim}{\}}}}}{1}
      {[}{{{\color{delim}{[}}}}{1}
      {]}{{{\color{delim}{]}}}}{1},
}



% \usepackage{showkeys} % used to show labels
\addbibresource{library.bib} % put name of bib file here with extension

%### switches
%\printoutput % make link colors black, leave deactivated for screen output

%### define metadata
\mmtype{Diplomarbeit} %Diplomarbeit|Großer Beleg|Bachelorarbeit|Masterarbeit|Seminararbeit
\mmtitle{Semantik-gestütztes Hilfesystem für ein komposites Informationsvisualisierungssystem}
\mmtshorttitle{Hilfesystem für komposite InfoVis}
\mmtauthor{Nikolaus Piccolotto}
\mmtsubmissionmonth{November 2013}
\mmtsubmissiondate{30. November 2013}
\mmtsupervisor{Dipl.-Medieninf. Martin Voigt}
%\mmtsupervisorii{Dipl.-Medieninf. Foo Bar} % Co-supervisor, optional

\mmthypersetup % has to be called after setting metadata

%### acronyms
\newacronym{PDF}{PDF}{Portable Document Format}
\newacronym{RCP}{RCP}{Rich Client Platform}
\newacronym{RIA}{RIA}{Rich Internet Application}
\newacronym{RELAXNG}{RELAX NG}{Regular Language Description for XML New Generation}
\newacronym{SGML}{SGML}{Standard Generalized Markup Language}
\newacronym{SWT}{SWT}{Standard Widget Toolkit}
\newacronym{WDC}{W3C}{World Wide Web Consortium}
\newacronym{WPF}{WPF}{Windows Presentation Foundation}
\newacronym{XPath}{XPath}{XML Path Language}
\newacronym{XHTML}{XHTML}{Extensible Hypertext Markup Language}
\newacronym{XML}{XML}{Extensible Markup Language}
% my acronyms
\newacronym{InfoVis}{InfoVis}{Informationsvisualisierung}

\begin{document}
\frontmatter
\pagenumbering{Roman}
\mmtfrontmatter

\listoffigures
\listoftables
\printglossary[type=\acronymtype,style=long,title=Abkürzungsverzeichnis,toctitle=Abkürzungsverzeichnis]
%\printglossary %Glossar

\mainmatter

% ###################################################
\chapter{Einleitung}
\label{chapter:einleitung}

% Grundlage der Arbeit ist ein komposites Infovis-System, also sollte vielleicht erst erläutert werden, warum man das überhaupt braucht --> immer mehr daten, aus denen man erkenntnisse gewinnen kann.

Im Laufe der letzten Jahre wurden immer mehr Daten veröffentlicht und im Internet auffindbar gemacht. Dazu gehören sowohl Fotos und Statusupdates in sozialen Netzwerken, als auch semantische Daten, die von Community-Projekten wie der DBpedia oder Regierungsorganisationen bereitgestellt werden. Die DBpedia ist eine maschinenlesbare Version der Wikipedia, mit ihr können mit Hilfe der Abfragesprache SPARQL automatisch Fragen beantwortet werden, deren manuelle Recherche zu aufwändig wäre. In data.gov.uk finden sich Informationen, die für alle Steuerzahler im Vereinigten Königreich relevant sein können, wie z.\,B. Organigramme und Gehälter von Regierungsorganisationen. Aus diesen frei verfügbaren Daten können viele Erkenntnisse gewonnen werden.

% ###################################################
\section{Motivation}
\label{section:einleitung:motivation}

% InfoVis sind gut, weil man Patterns, Ausreisser und Trends in Daten schneller erkennen kann, sie also das Verständnis der Daten fördern.

In roher Form können Menschen diese Daten aber nur sehr schwer verarbeiten: Ein Computer kann mehrere Megabyte Text innerhalb von Sekunden lesen und im Arbeitsspeicher halten, ein Mensch benötigt viel Zeit und vergisst große Teile wieder. Hier setzen dem Sprichtwort \enquote{Ein Bild sagt mehr als tausend Worte} folgend Informationsvisualisierungen an. Sie bereiten Daten visuell auf, beispielsweise in Form von Diagrammen, und machen so die enthaltenen Informationen für Menschen einfacher zugänglich. So können in den Daten enthaltene Muster, Ausreisser, Zusammenhänge und Trends leicher erkannt werden.

% Komposite InfoVis sind für den Benutzer gut, weil der mehr als eine Sicht auf die Daten hat. Für den Systembetreiber sind sie gut, weil...? Jeder macht, was er am besten kann?

Bei komplexen Daten, die mehrere Variablen unterschiedlichen Typs beinhalten, ist es sinnvoll mehrere Informationsvisualisierungen zu kombinieren. Sie bieten verschiedene Sichten auf den Datensatz, beispielsweise eine Karte für die enthaltenen Länder und ein Balkendiagramm für die Entwicklung des BIP in den letzten Jahren. Auf diese Weise wird der Erkenntnisgewinn gefördert, da zum Beispiel sichtbar wird, dass Länder mit geringem BIP in ähnlichen Regionen liegen.

% komposite infovis sind mashups. die infovis stammen von verschiedenen entwicklern, schauen verschieden aus, haben verschiedene interaktionsmetaphern, unterschiedliches look and feel, unterschiedliche funktionen

Diese verschiedenen, kombinierten Informationsvisualisierungen stellen ein sogenanntes Mashup von User Interfaces dar. Dessen einzelne Komponenten können dabei von unterschiedlichen, unabhängigen Entwicklern erstellt werden. Das ist sinnvoll, da auf diese Weise die Anzahl an vorhandenen Komponenten und damit der Nutzen für den Anwender maximiert werden kann. Diese Strategie bringt aber auch Nachteile für den Anwender mit sich. Da die Komponenten von unterschiedlichen Entwicklern gebaut werden, können sie unterschiedlich aussehen: Was bei einer Komponente eine Auswahl signalisiert, ist bei der anderen normale Hintergrundfarbe. Die Komponenten verfügen möglicherweise über unterschiedliche Interaktionsmetaphern: Beim Balkendiagramm von Entwickler A müssen die Buttons geklickt werden, beim Liniendiagramm von Entwickler B reicht ein \texttt{mouseover}. Aus diesen und anderen Gründen muss dem Anwender eine einheitliche, universelle Hilfestellung angeboten werden.


% ###################################################
\section{Problemstellung und Zielsetzung}
\label{section:einleitung:problemstellung}

% welche probleme? Visualisierungen auseinanderhalten und einordnen können (intro), visualisierungen bedienen können (bedienung), fragen über daten stellen können (kommentare), konzept der zusammenarbeit von komponenten verstehen (kommunikation), fehler melden können (Feedback), unbekannte konzepte beschrieben bekommen (verlinkung)

Einem Anwender, der ein Mashup aus Informationsvisualisierungen nutzen will, stellen sich einige Fragen. Zunächst sieht er mehrere unterschiedliche Komponenten und muss diese nach der Reihe inspizieren und einordnen: Welche Daten stellen sie dar, wie sind diese kodiert und wie müssen sie interpretiert werden? Außerdem ist unklar, welche Funktionen die Komponenten zur Verfügung stellen und wie diese aufgerufen werden: Kann die Tabelle sortiert werden und wenn ja, wie? Welche Operation auf welchen Elementen führt welche Sortierreihenfolge aus? Welchen Alternativen gibt es? Möglicherweise tauschen Komponenten untereinander Nachrichten aus, um gegenseitig ihr User Interface zu aktualisieren. Dieser Vorgang ist für den Benutzer unsichtbar und seine Auswirkungen wahrscheinlich irritierend. Warum aktualisiert sich die Karte, wenn die Interaktion im Balkendiagramm stattfindet? Während der Inspektion der Daten werden sich dem Anwender weitere Fragen stellen: Was bedeutet ein bestimmter Begriff, wie ist eine Metrik definiert und warum fällt sie so plötzlich ab?

% ziel der arbeit: hilfesystem konzept, prototypisch umsetzen, aber quasi "real-world" prototyp. kein paper mockup.

Ziel dieser Arbeit ist die Entwicklung eines Konzepts für ein semantik-gestütztes Hilfesystem für VizBoard, ein komposites Informationsvisualisierungssystem auf Basis der Mashupplattform CRUISe. Das Konzept soll die eben beschriebenen Probleme lösen, den Aufwand für Komponentenentwickler so gering wie möglich halten und auf alle Komponenten anwendbar sein. Das Konzept soll prototypisch umgesetzt und in CRUISe integriert werden.

Daraus leiten sich die folgenden Teilziele der Arbeit ab: % Welche teilziele? Erstmal gucken, was es so für infovis gibt, was man so über assistance wissen muss. und sonst so?


% ###################################################
\section{Aufbau der Arbeit}
\label{section:einleitung:aufbau}

% Aufbau der Arbeit erklären, kommt zum Schluss
Zunächst wird die Aufgabenstellung noch einmal an einem beispielhaften Szenario verdeutlicht und daraus Anforderungen an das Konzept abgeleitet. Da für die Entwicklung des Konzepts Kenntnisse der betroffenen Themengebiete nötig sind, werden in den Grundlagen CRUISe und VizBoard, semantische Daten, Informationsvisualisierungen und User Assistance eingeführt. Danach werden in den verwandten Arbeiten die Vor- und Nachteile bestehender Lösungen betrachtet und Schlussfolgerungen für das Konzept gezogen, welches in Kapitel XY vorgestellt wird. In Kapitel XYZ wird auf die Umsetzung des Prototypen eingegangen und evaluiert. Danach wird die Arbeit mit einer Zusammenfassung und einem Ausblick geschlossen.

% ###################################################
\chapter{Stand der Forschung und Technik}
\label{chapter:standderforschung}

Der folgende Abschnitt besteht aus drei Teilen. Zuerst wird die Aufgabenstellung in einem Szenario verdeutlicht (Abschnitt~\ref{section:standderforschung:szenario}). Daraus werden Anforderungen an das Hilfesystem abgeleitet (Abschnitt~\ref{section:standderforschung:anforderungsanalyse}) und danach die Grundlagen von semantischen Daten, Informationsvisualisierungen und Software Support erläutert (Abschnitt~\ref{section:standderforschung:grundlagen}).

% ###################################################
\section{Szenario}
\label{section:standderforschung:szenario}

% kurze einleitung noch mal

Wie in Kapitel~\ref{chapter:einleitung} erläutert, ist das komposite InfoVis-System Teil der webbasierten Anwendung VizBoard. Sie leitet den Benutzer in mehreren Schritten von der Auswahl eines Datensatzes zur finalen, kompositen Informationsvisualisierung. Im vorletzten Schritt wählt dieser mit Hilfe eines Facettenbrowsers geeignete Visualisierungskomponenten aus, welche danach angezeigt werden. Um die Problemstellung noch einmal zu verdeutlichen, wird im folgenden ein mögliches Szenario beschrieben.

% einführung der problemstellung
Anna möchte für ihr Biologiestudium mehr über die geografische Verteilung verschiedener Genvarationen herausfinden. Dazu sucht sie im Internet nach einem Datensatz, welchen sie auch findet. 
% unbekanntes format, kann es nirgends ordentlich öffen und selbst wenn es in excel ginge, wüsste sie nicht, welche charts sie am besten erstellen sollte
Leider ist er in einem für Anna unbekannten Format abgespeichert, nämlich OWL. Sie versucht die Datei mit Microsoft Excel und SPSS zu öffnen, weil sie keine anderen Programme zur Datenverarbeitung kennt, aber scheitert. Anna stellt fest, dass nur ihr Texteditor OWL öffnen und vernünftig darstellen kann. Als sie die Datei überfliegt, kann sie den Inhalt zwar erahnen, aber es ist einfach zu viel Text um ihn vollständig zu lesen. Davon abgesehen sind geografische Breite und Länge als Zahlenkombination keine anschauliche Repräsentation von Orten, auch Verteilungen von Werten sind so schwer ersichtlich. Anna würde viel Zeit aufwenden müssen um sehr wenig des Inhalts zu verstehen. Aber selbst wenn sie die Datei in Excel hätte öffnen können, hätte sie nicht gewusst, mit welchen Diagrammen die vorhandenen Daten am Besten verstanden würden. Anna hört von einem Freund, dass VizBoard gut geeignet ist, um semantische Datensätze anzusehen und probiert es aus.

% Der Benutzer ist laut unserem Rollenmodell weder Developer noch Visualisierungsexperte, d.h. er hat erstmal Schwierigkeiten zu erfassen, was hier überhaupt abgeht

Anna hat ihren Datensatz auch bei VizBoard gefunden und ist neugierig: Sie wählt eine Karte, ein Balkendiagramm, eine Tabelle und eine Treemap aus (Abbildung~\ref{figure:szenario-skizze}); kurz darauf werden ihr die Visualisierungskomponenten angezeigt. Anna benutzt VizBoard zum ersten Mal und macht außer Facebook und YouTube auch sonst nicht viel im Internet, das heißt sie ist zunächst von den vier unterschiedlichen Fenstern etwas überfordert.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.75\textwidth]{images/szenario-skizze.png}
	\caption{Skizze der VizBoard Visualisierungskomponenten}
	\label{figure:szenario-skizze}
\end{figure}

VizBoard bietet Anna aber sofort eine einführende Übersicht und erklärt kurz die Darstellungsform und den Inhalt jeder Komponente. Eine denkbare Erklärung der Treemap wäre zum Beispiel:

\begin{quote}
Eine Treemap ist eine hierarchische Visualisierung, um Größenverhältnisse anschaulich zu machen. In dieser werden die Anzahl von Genvariationen pro geografischer Region dargestellt.
\end{quote}

% Was sind das für Fenster? Welche Komponente ist welche? Welche macht was? Wie kann ich sie bedienen? HUUUPS da ändert sich ja was obwohl ich dort nix gemacht hab! Wie hängen die zusammen? Was sind das für Daten, die dargestellt werden? 

Damit bekommt Anna einen Überblick über die verfügbaren Visualisierungen und weiß, welches Fenster welche Visualisierung enthält und für was diese gut sind. Nun möchte sie die Tabelle, in der die durch die Treemap visualisierten Daten stehen, nach der Spalte \enquote{Anzahl} sortieren. Anna sieht aber nicht, wie sie das machen soll, da in der Tabelle kein offensichtliches Kontrollelement wie z.\,B. ein Button vorhanden ist. Sie bemerkt ein Fragezeichen in der Titelleiste des Fensters und klickt darauf. Der verfügbare Viewport wird abgedunkelt und es erscheint ein neues Fenster, welches die verfügbaren Aktionen mit Hilfe von Text, Bildern und Animationen erklärt. Anna lernt, dass sie mit einem einfachen Linksklick auf den jeweiligen Kopf einer Tabellenspalte nach dieser sortieren kann und außerdem eine oder mehrere Zeilen auswählen kann. Sie sortiert die Tabelle wie gewollt und wählt die ersten drei Zeilen aus. Plötzlich verkleinert die Karte ihr Zoomlevel und Anna ist verwirrt: Sie hat nur mit der Tabelle interagiert und es bestand keine sichtbare Verbindung zwischen den beiden Fenstern. Allerdings wurde nach der Zeilenauswahl ein Pfeil von der Tabelle zur Karte gezeichnet, welcher mit einem Icon in Form eines Briefes versehen ist. Anna vermutet, dass doch irgendeine Verbindung zwischen den beiden Visualisierungen besteht und klickt auf den Brief. Ähnlich wie vorhin bei der Hilfe zur Tabelle wird der Viewport abgedunkelt und ein neues Fenster wird eingeblendet. Es erklärt die Kommunikation zwischen den Visualisierungen mit Hilfe von Animationen, Text und Bildern. Nun weiß Anna auch, wie die verschiedenen Fenster zusammenhängen und kann sich ihrer eigentlichen Aufgabe widmen.

% Was heißt GDP? Wie wird das berechnet? Was soll die Spitze bei 1990? Woher kommt die? Diese eine Komponente scheint kaputt zu sein, wo kann ich mich beschweren?

In der Tabelle findet sie auch eine Spalte \enquote{SNP}. Anna weiß zwar, dass sie die Abkürzung schon einmal gesehen hat, kennt aber im Moment ihre Bedeutung nicht. Praktischerweise ist der Spaltenkopf mit der Wikipedia verlinkt und sie wird sofort auf die entsprechende Seite weitergeleitet. Anna erinnert sich, dass \enquote{SNP} \enquote{Single-nucleotide polymorphism} bedeutet und sie bekommt auch gleich zusätzliche Informationen zu diesem Thema. Sie widmet sich weiter der Tabelle und stellt fest, dass die Ortsbezeichnung \enquote{Kopenhagen} nicht mit der Markierung in der Karte übereinstimmt. Außerdem ist sie erstaunt, wie hoch die Verbreitung eines bestimmten SNPs dort ist und würde gerne die Ursache dafür wissen. In der Hilfe zur Tabelle wurde sie auch über die Möglichkeit, Kommentare an den Daten vorzunehmen, aufgeklärt. Anna kommentiert sowohl die falschen Geokoordinaten als auch ihre Frage über die Verbreitung des SNPs, sodass sie später über Antworten informiert wird. Nun kann Anna sich mit der vierten Visualisierung, dem Balkendiagramm, beschäftigen. Allerdings reagiert es auf keine Mausklicks und macht auch sonst nicht den Eindruck, die Daten akkurat darzustellen. Anna meldet die kaputte Visualisierung über die eingebaute Feedback-Funktion und schließt das Fenster, um sich den anderen drei Visualisierungskomponenten zuzuwenden.

% ###################################################
\section{Anforderungsanalyse}
\label{section:standderforschung:anforderungsanalyse}

Aus dem Szenario (Kapitel~\ref{section:standderforschung:szenario}) lassen sich nun verschiedene Anforderungen an ein Hilfesystem für komposite Informationsvisualisierungssysteme ableiten.

\subsection{Funktionale Anforderungen}
\label{section:standderforschung:anforderungsanalyse:funktionale_anforderungen}

Blabla

\begin{itemize}
	\item\textbf{Intro}: Das Hilfesystem soll einen kurzen Überblick über das InfoVis-System geben und Darstellungsform sowie Inhalt jeder Komponente kurz erläutern.
	\item\textbf{Bedienung}: Das Hilfesystem soll erklären können, wie eine Komponente bedient wird. Diese Informationen umfassen beispielsweise welche Operationen welche Aktionen (eventuell auf welchen Daten) ausführen.
	\item\textbf{Feedback}: Fehler in Komponenten sollen über ein Feedback-System gemeldet werden können.
	\item\textbf{Verlinkung}: Das Hilfesystem soll nicht-triviale Begriffe mit einer Wissensbasis‚ verlinken, sodass nicht nur auf die Begriffsbedeutung hingewiesen werden, sondern dem Benutzer auch zusätzliche Informationen zur Verfügung gestellt werden können.
	\item\textbf{Kommunikation}: Das Hilfesystem soll erklären können, wie gegebene Komponenten miteinander kommunizieren.
	\item\textbf{Kommentare}: Der Benutzer soll die Möglichkeit haben Daten zu kommentieren und Bereiche der Visualisierung zu markieren und mit ebenfalls mit einem Kommentar zu versehen, sodass auch auf fehlende Daten hingewiesen werden kann.
\end{itemize}

% was muss also ins related work?
% wie der wissensaufnahmeprozess funktioniert, weil ich ja erklärungen gebe, speziell planerklärung
% was es so für infovis gibt, weil ich mit denen arbeite
% was es so für hilfekonzepte gibt, weil es das ist was ich tue
% social web, weil kommentare implementiert werden

\subsection{Nichtfunktionale Anforderungen}
\label{section:standderforschung:anforderungsanalyse:nichtfunktionale_anforderungen}

Bla bla

\begin{itemize}
	\item\textbf{Korrektheit}: Eine gegebene Hilfestellung darf keine Fehlinformationen enthalten, weil sie sonst mehr verwirrt als hilft.
	\item\textbf{Vollständigkeit}: Eine gegebene Hilfestellung muss alle Informationen enthalten, die der Nutzer benötigt um danach seine gewünschte Aufgabe ausführen zu können.
	\item\textbf{Verständlichkeit}: Hilfestellungen müssen in einer Form präsentiert werden, die der Benutzer schnell und mit geringem mentalen Aufwand verarbeiten kann.
	\item\textbf{Einheitlichkeit}: Das Look \& Feel von Teilen des Hilfesystems (z.B. Kommentare) muss komponentenübergreifend einheitlich sein, damit der Benutzer einmal gelerntes wiederverwenden kann.
	\item\textbf{Minimalität}: Der Komponentenentwickler soll seine Komponente mit möglichst wenig Aufwand zum Hilfesystem kompatibel machen können, ansonsten werden nur sehr wenige Komponenten -- und damit der Benutzer -- davon profitieren.
	\item\textbf{Universalität}: Das Hilfesystem soll für alle Komponenten und Visualisierungen in gleicher Qualität funktionieren.
	\item\textbf{Wiederverwendbarkeit}: Die Kommentare sollen möglichst in allen Visualisierungen wiederverwendet werden, damit viele Benutzer von den Erkenntnissen anderer profitieren können.
	\item\textbf{Unaufdringlichkeit}: Das Hilfesystem soll den Benutzer nicht von seinen Aufgaben ablenken und nur auf Anfrage zum Einsatz kommen oder es soll selbständig erkennen, wenn der Benutzer Hilfe benötigt.
\end{itemize}

% ###################################################
\section{Grundlagen}
\label{section:standderforschung:grundlagen}

Hurrrrr derp herp

\subsection{CRUISe, EDYRA \& VizBoard}
\label{section:standderforschung:grundlagen:cruise_vizboard}

% grundlagen von cruise edyra vizboard. wichtig weil mein hilfesystem dort eingesetzt wird
CRUISe \cite{Pietschmann2009, Pietschmann2012} ist ein Framework zur Konstruktion von webbasierten, kompositen User Interfaces (auch Mashups). Diese bestehen aus mehreren voneinander unabhängigen, wiederverwendbaren User Interface Services (z.\,B. eine Karte, eine Tabelle und ein Kalender) welche zur Laufzeit hinzugefügt, konfiguriert und ausgetauscht werden können. Abbildung~\ref{figure:cruise_architektur} zeigt die Architektur von CRUISe. Zuerst werden Komponenten von Entwicklern erstellt und modelliert (1). Danach interpretiert CRUISe das Kompositionsmodell (2), matcht es gegen die Kontextanforderungen (3), bildet ein Ranking (4) und integriert schließlich die am besten geeignete Komponente ins User Interface (5).

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{images/grundlagen-cruise_component_integration.png}
	\caption{CRUISe Architektur aus \cite{Pietschmann2012}}
	\label{figure:cruise_architektur}
\end{figure}

CRUISe geht davon aus, dass professionelle Softwarentwickler Komponenten zu kompositen Sichten modellieren, welche dann von Endnutzern nur noch aufgerufen werden. EDYRA \cite{Ruempel2011} greift auf das CRUISe Framework zurück, um es Endnutzern selbst zu ermöglichen, diese Aufgabe auszuführen. Dazu schlägt EDYRA zur Laufzeit Komponenten vor, welche sofort integriert oder gelöscht werden können.

VizBoard \cite{Voigt2013} benutzt das CRUISe Framework, um Endnutzern die Möglichkeit zu geben, semantische Datensätze mit Hilfe verschiedener InfoVis verstehen zu können. Abbildung~\ref{figure:vizboard_architektur} zeigt die Architektur von VizBoard. Die Daten werden zuerst aus verschiedenen Quellen in eine semantische Repräsentation konvertiert und im Data Repository (DaRe, 2) gespeichert. Das Composition Repository (CoRe, 4) verwaltet die verschiedenen Visualisierungskomponenten und ist für Matching und Ranking von Komponenten zuständig, bevor sie in der Runtime (5) integriert werden. Sowohl das DaRe als auch das CoRe greifen auf die Visualization Ontology (VISO, 1) zurück, die Wissen über verschiedene Aspekte von Visualisierungen, wie z.\,B. Struktur der visualisierten Daten, Mapping der Daten auf visuelle Attribute oder Interaktionsmöglichkeiten, enthält \cite{Polowinski2013}.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.75\textwidth]{images/grundlagen-vizboard_architektur.png}
	\caption{VizBoard Architektur aus \cite{Voigt2013}}
	\label{figure:vizboard_architektur}
\end{figure}

\subsubsection{Data Repository}
\label{section:standderforschung_data_repository}

% dare --> vizboard paper, beleg
Im DaRe werden Daten aus verschiedenen Quellen in einer semantischen Repräsentation gespeichert. Dabei durchläuft das DaRe verschiedene Phasen: Zuerst wird der Datensatz \emph{analysiert} und Metainformationen gesammelt, beispielsweise werden Subklassen gezählt und wichtige Konzepte identifiziert. Diese werden an den Datensatz \emph{annotiert}. Zur Laufzeit müssen diese Erkenntnisse wieder aus dem Datensatz \emph{extrahiert} werden. Das DaRe stellt eine REST API zur Verfügung, über die ein Datensatz abgerufen werden kann \cite{Piccolotto2012}.

\subsubsection{Komponentenbeschreibung}
\label{section:standderforschung:grundlagen:cruise_vizboard:komponentenbeschreibung}

% komponentenbeschreibung 5.1.3
Komponenten in CRUISe werden generisch und einheitlich durch propertys, Events und Operationen sowie Metainformationen beschrieben. propertys geben Auskunft über den Zustand einer Komponente, also beispielsweise Breite und Höhe oder die Sortierreihenfolge der Elemente. Events weisen andere Komponenten auf interne Zustandsänderungen hin, zum Beispiel wenn sich die Sortierreihenfolge geändert hat. Operationen sind Methoden einer Komponente, die durch Events ausgelöst werden, z.\,B. \texttt{reassignNumbers(order)}, um die Nummerierung der Pins in einer Karte anzupassen. Zu den Metainformationen gehören u.\,a. der Name einer Komponente oder der Preis.

\subsubsection{Kommunikationsmodell}
\label{section:standderforschung:grundlagen:cruise_vizboard:kommunikationsmodell}

% kommunikationsmodell 5.2.2
Die Kommunikation von Komponenten untereinander ist ereignisgesteuert, d.\,h. eine Komponente veröffentlicht ein Event, dessen Nachricht mit Hilfe des Publish/Subscribe Paradigma an alle Subscriber in diesem Kanal (Link) übertragen wird. Subscriber reagieren auf das Event, indem sie bestimmte Operationen ausführen. Die Übertragung der Nachrichten wird durch sogenannte Links umgesetzt, welche $n$ Events mit $m$ Operationen verbinden. Spezielle Links sind Backlinks, die eine Zweiwegekommunikation zwischen Komponenten ermöglichen und PropertyLinks, die propertys synchron halten. Ein Überblick über die verschiedenen Links ist in Abbildung~\ref{figure:cruise_links} zu sehen.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.75\textwidth]{images/grundlagen-cruise_links.png}
	\caption{CRUISe Links aus \cite{Pietschmann2012}}
	\label{figure:cruise_links}
\end{figure}

\subsubsection{Laufzeitumgebung}
\label{section:standderforschung:grundlagen:cruise_vizboard:laufzeitumgebung}

Die Laufzeitumgebung (Mashup Runtime Environment, MRE) ist für die Ausführung und Verwaltung der kompositen Anwendung verantwortlich und besteht aus mehreren Modulen (Abbildung~\ref{figure:cruise_mre}).

% laufzeitumgebung (tsr) 6.2, 7.2.2
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.75\textwidth]{images/grundlagen-cruise_mre.png}
	\caption{Mashup Runtime Environment Architektur aus \cite{Pietschmann2012}}
	\label{figure:cruise_mre}
\end{figure}

Der \textbf{Application Manager} initialisiert alle anderen Module und ist für die globale Fehlerbehandlung zuständig. Für den Lebenszyklus der einzelnen Komponenten ist der \textbf{Component Manager} zuständig. Die Integration übernimmt allerdings der \textbf{Integration Manager}. Im Mashup Modell definierte Sichten und Übergänge zwischen ihnen werden vom \textbf{Screenflow Manager} interpretiert. Gerendert werden die Komponenten aber vom \textbf{Layout Manager}. Nachrichten zwischen Komponenten der Anwendung und Modulen der MRE werden durch den \textbf{Event Broker} übermittelt. Sind die Parameter von Event und Operation syntaktisch nicht äquivalent, aber semantisch aufeinander abbildbar (z.\,B. zwei gleiche Konzepte aus verschiedenen Namespaces wie \texttt{dbpedia:city} und \texttt{geonames:city}), übernimmt dies der \textbf{Mediator}. Die dynamische Anpassung der Anwendung (z.\,B. von Komponenten, Layout und Kommunikationsmodell) wird gegebenenfalls durch den \textbf{Adaptation Manager} durchgeführt. Der \textbf{Context Service} \cite{Pietschmann2008} speichert Informationen über den Nutzungskontext, beispielsweise den Aufenthaltsort des Nutzers. Letztlich erlaubt das \textbf{Service Access} Modul Zugriff auf Web-Dienste und Ressourcen im Backend.

\subsubsection{VISO}
\label{section:standderforschung:grundlagen:cruise_vizboard:viso}

% viso
In der Visualization Ontology (VISO) ist Visualisierungswissen gespeichert. Sie kann dabei helfen, zur Laufzeit die Domäne dargestellter Daten zu identifizieren oder notwendiges Wissen zur User Assistance (Abschnitt~\ref{section:standderforschung:grundlagen:user_assistance}) zur Komponentenbeschreibung hinzuzufügen. Unter anderem enthält sie folgende Konzepte und deren Verbindungen untereinander:

\begin{itemize}
	\item Visualisierte Daten (\texttt{viso:data})
	\begin{itemize}
		\item Scale of Measurement (nominal, ordinal, quantitativ, unstrukturiert)
		\item Struktur der Daten (tabellarisch, Tripel, verlinkt)
		\item Art der Variable (abhängig, unabhängig, Dimension etc.)
		\item Domäne
	\end{itemize}
	\item Aktivitäten (\texttt{viso:activity})
	\begin{itemize}
		\item Nutzeraktivitäten (Operationen, Aktionen, Aufgaben)
		\item Visualisierungspipeline (Editieren, Visual Mapping, Datentransformation etc.)
	\end{itemize}
	\item Grafikvokabular (\texttt{viso:graphic})
	\begin{itemize}
		\item Visuelle Attribute (Größe, Farbe, Textur etc.)
		\item Koordinaten (kartesisch, Zylinder, Kugel etc.)
		\item Art der grafischen Repräsentation (Karten, Chart mit zwei Achsen, animierte InfoVis etc.)
		\item Beziehungen zwischen Objekten (Clustering, Labeling, verlinkt etc.)
	\end{itemize}
	\item System (\texttt{viso:system})
	\begin{itemize}
		\item Hardware
		\item Software
		\item Bildschirmauflösung
		\item Rundes, eckiges oder unstrukturiertes Display
	\end{itemize}
\end{itemize}

Dieses Wissen wird in VizBoard auf verschiedene Art und Weise genutzt (Abbildung~\ref{figure:viso}). Mit Hilfe der VISO kann Wissen von Visualisierungsexperten formalisiert und im Rankingalgorithmus berücksichtigt werden (2). Gleichermaßen wird sie zur Annotation der Daten im Data Repository (Abschnitt~\ref{section:standderforschung_data_repository}) benutzt (3). Visualisierungskomponenten (4) und Nutzer- bzw. Systemkontext (5) werden durch VISO-Konzepte beschrieben.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.75\textwidth]{images/grundlagen-viso.png}
	\caption{Nutzung der VISO in VizBoard}
	\label{figure:viso}
\end{figure}

\subsection{Semantische Datensätze}
\label{section:standderforschung:grundlagen:semantische_daten}

% Grundlagen von RDF, RDFS, OWL. Wichtig weil später Kommentare wieder in einer Ontologie abgelegt werden müssen
Eine Ontologie ist \enquote{an explicit specification of a conceptualization} \cite{Gruber1995} und wird benutzt um domänenspezifisches Wissen abzubilden \cite{Chandrasekaran1999}. Sie besteht aus mehreren Elementen:

\begin{itemize}
	\item Eine Klasse repräsentiert ein Konzept, eine Entität, ein Ding, beispielsweise ein \textit{Smartphone}.
	\item Eine Instanz ist ein konkretes Objekt einer Klasse, zum Beispiel das \textit{iPhone mit der Seriennummer XYZ-ABC}.
	\item Datatype propertys beschreiben eine Instanz näher, zum Beispiel die \textit{Seriennummer} oder \textit{Bildschirmgröße} des iPhones.
	\item Objektattribute beschreiben Beziehungen zwischen Klassen und deren Instanzen, beispielsweise eine Person \textit{besitzt} ein Smartphone.
	\item Außerdem existieren noch Axiome, Regeln, Funktionen und Einschränkungen, welche die Logik einer Ontologie beschreiben.
\end{itemize}

Um eine Ontologie maschinenlesbar darzustellen, hat das World Wide Web Consortium (W3C) verschiedene Beschreibungssprachen eingeführt. Die bekanntesten sind Resource Description Framework (RDF), RDF Schema (RDFS) und Web Ontology Language (OWL). Mit diesen Sprachen lässt sich unterschiedlich viel Semantik u.\,a. in Form von Ontologien, Thesauren oder Vokabularen ausdrücken; die Komplexität der Dokumente und damit der Aufwand, sie zu erstellen, verhalten sich aber direkt proportional (siehe Abbildung~\ref{figure:semantic_spectrum}).

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.75\textwidth]{images/grundlagen-semantic_spectrum.png}
	\caption{Semantic Spectrum \cite{Bergman2007}}
	\label{figure:semantic_spectrum}
\end{figure}

% rdf

RDF ist von den genannten die Sprache mit den wenigsten Features, sie kann nur Tripel der Form (Subjekt, Prädikat, Objekt) darstellen. Die Elemente der Tripel sind Resourcen (durch URIs gekennzeichnet), welche Objekte beschreiben. So drückt der Tripel (\texttt{http://alice.de}, \texttt{http://foaf.de/knows}, \texttt{http://bob.de}) aus, dass das Element \enquote{Alice} mit \enquote{Bob} über die Relation \enquote{knows} verbunden ist. In RDF existieren noch keine Vererbung, Klassen, propertys oder Logik.

% rdfs

RDFS ist eine Erweiterung von RDF, nämlich um Klassen und Vererbung, Datatype propertys und Objektattribute. Allerdings ist RDFS damit noch immer nicht so mächtig wie OWL.

% owl

OWL erweitert wiederum RDFS um einige Konzepte. So können beispielsweise Axiome definiert werden, Attribute können als transitiv oder symmetrisch deklariert werden, es existieren Mengenoperationen und Kardinalitäten und Wertebereiche können eingeschränkt werden. OWL existiert in zwei Versionen, da in den meisten Fällen nicht der volle Funktionsumfang benötigt wird: OWL Lite ist für Anwendungen gedacht, die kaum mehr als eine Klassenhierarchie und Attribute benötigen. OWL-DL ist auf die Logik in der Ontologie fokussiert und wird vor allem für Reasoner eingesetzt, um selbstständig Schlüsse innerhalb des vorgegebenen formalen Systems ziehen zu können. OWL 2 wurde 2009 eingeführt, dieser Standard erweitert OWL zum Beispiel um asymmetrische, reflexive und disjunkte Attribute.

\subsection{Informationsvisualisierung}
\label{section:standderforschung:grundlagen:informationsvisualisierung}

% InfoVis Grundlagen. Wichtig weil das die Komponenten sind, mit denen ich zu tun habe.

Card et al. \cite{Card1999} definieren den Begriff \enquote{Informationsvisualisierung} wie folgt:

\begin{quote}
The use of computer-supported, interactive, visual representations of abstract data to amplify cognition.
\end{quote}

Beispiele dafür sind Balkendiagramme, Treemaps \cite{Shneiderman1992} und Parallel Coordinates \cite{Inselberg1991} (Abbildung~\ref{figure:parallel_coordinates}). Mangels Interaktivität sind Infografiken \cite{Smiciklas2012} von den eben definierten Informationsvisualisierungen ausgeschlossen.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/grundlagen-parallel_coordinates.png} 
   \caption{Parallel Coordinates}
   \label{figure:parallel_coordinates}
\end{figure}

% visualisierungsprozess

Informationsvisualisierungen können besonders bei der Exploration großer Datenmengen hilfreich sein \cite{Kohlhammer2011}. Die Wissensaneignung erfolgt dabei iterativ (Abbildung~\ref{figure:visual_analytics_process}). Zuerst werden Daten auf eine Visualisierung gemappt, deren Parameter vom Benutzer geändert werden können. Daraus lernt dieser etwas über die Daten und kann danach (\enquote{Feedback loop}) von vorne anfangen und eine andere Visualisierung wählen oder die Daten transformieren.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/grundlagen-visual_analytics_process.png} 
   \caption{Visual Analytics Process nach \cite{Kohlhammer2011}}
   \label{figure:visual_analytics_process}
\end{figure}

Van Wijk \cite{vanWijk2005} stellt ein ähnliches Modell für den Prozess der Wissensaufnahme über Visualisierungen vor (Abbildung~\ref{figure:visualization_model}). Am Anfang stehen die Daten $D$, welche anhand einer Visualisierungsspezifikation $S$ in eine Visualisierung $V$ transformiert werden. Diese wird vom Benutzer aufgenommen ($P$) und in Wissen ($K$) umgesetzt. Danach startet die Exploration der Daten $E$ indem die Spezifikation geändert und neues Wissen aufgenommen wird (entspricht der \enquote{Feedback loop} aus \cite{Kohlhammer2011}).

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/grundlagen-visualization_model.png} 
   \caption{Generic Model on Visualization nach \cite{vanWijk2005}}
   \label{figure:visualization_model}
\end{figure}

% überblick über infovis

Im Folgenden wird ein Überblick über verschiedene Informationsvisualisierungen gegeben. Dieser orientiert sich an Keim \cite{Keim2002}, welcher Informationsvisualisierungen nach dargestellten Daten, Visualisierungs- und Interaktionstechnik klassifizierte. Die Abbildungen stammen, sofern nicht anders angegeben, aus \cite{Heer2010}.

\subsubsection{Dargestellte Daten}
\label{section:standderforschung:grundlagen:informationsvisualisierung:dargestellte_daten}

\textbf{Eindimensionale Daten} sind beispielsweise Zeitreihen, also Folgen von Daten (1992, 1993, 1995...). Nach Keim können diese aber mit anderen Datenobjekten assoziiert sein. Beispiele für InfoVis eindimensionaler Daten wären demnach ein Index Chart (Abbildung~\ref{figure:index_chart}) oder eine einfache Timeline.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/grundlagen-index_chart.png}
   \caption{Index Chart}
   \label{figure:index_chart}
\end{figure}

\textbf{Zweidimensionale Daten} haben zwei unterschiedliche Dimensionen, wie zum Beispiel eine Geokoordinate (geografische Länge und Breite). Beispiele für InfoVis dieser Daten sind eben Karten (Abbildung~\ref{figure:karte}) oder häufig verwendete zweidimensionale Visualisierungen wie z.\,B. ein Balkendiagramm.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/grundlagen-karte.png}
   \caption{Karte}
   \label{figure:karte}
\end{figure}

\textbf{Multidimensionale Daten} haben demnach mehr als zwei unterschiedliche Dimensionen, typischerweise komplexe Objekte wie Autos (Hubraum, Maximalgeschwindigkeit, Leistung, Benzinverbrauch...) oder Digitalkameras (Megapixel, Sensorgröße, maximale Lichtempfindlichkeit, Gewicht...). Um diese Daten darzustellen, werden oft Parallel Coordinates (Abbildung~\ref{figure:parallel_coordinates}) oder Scatterplot Matrizen (Abbildung~\ref{figure:scatterplot_matrix}) verwendet.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/grundlagen-scatterplot_matrix.png}
   \caption{Scatterplot Matrix}
   \label{figure:scatterplot_matrix}
\end{figure}

\textbf{Text} kann erst nach einer Vorverarbeitungsphase mit Zahlen beschrieben werden (z.\,B. Wörter zählen), ansonsten schlagen herkömmliche Visualisierungsansätze fehl. Ein im Web verbreitetes Beispiel ist die Tag Cloud (Abbildung~\ref{figure:tag_cloud}\footnote{\url{http://4.bp.blogspot.com/-WvicpJ9QqQs/TpbqvbKhX3I/AAAAAAAADGc/3PczLY2P0xs/s1600/uni_tag_cloud_wordle.png}}). Je häufiger ein Begriff im Textkorpus vorkommt, desto größer wird er dargestellt.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/grundlagen-tag_cloud.png}
   \caption{Tag Cloud}
   \label{figure:tag_cloud}
\end{figure}

\textbf{Hierarchien und Netzwerke} beschreiben Relationen und Verbindungen zwischen Objekten. Ein Beispiel für InfoVis von Hierarchien ist der klassische Baum (Abbildung~\ref{figure:baum}), für Netzwerke ein Node-Link-Diagramm (Abbildung~\ref{figure:node-link-diagramm}).

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.75\textwidth]{images/grundlagen-baum.png}
   \caption{Baum}
   \label{figure:baum}
\end{figure}

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.25\textwidth]{images/grundlagen-node-link-diagramm.png}
   \caption{Node-Link-Diagramm}
   \label{figure:node-link-diagramm}
\end{figure}

% Am Schluss hat Keim noch Software/Algorithmen, aber ich sehe den Unterschied zu Multidimensionalen Daten nicht. Außerdem kann man - wenn schon mal grundlos neue Kategorien eingeführt werden - dann auch Produktionsprozesse oder what not gesondert betrachten

\subsubsection{Visualisierungstechniken}
\label{section:standderforschung:grundlagen:informationsvisualisierung:visualisierungstechniken}

% standard 2d/3d

\textbf{Standard 2D/3D} Visualisierungen beinhalten Balkendiagramme, Liniendiagramme, sowie andere zweidimensionale Plots und Karten. Ein Beispiel dafür ist das Index Chart (Abbildung~\ref{figure:index_chart}).

% multidimensional
\textbf{Multidimensionale} Visualisierungen\footnote{Die Bezeichnung stammt von Chi \cite{Chi2000} und wird verwendet, da sie logischer erscheint als Keims \enquote{geometrically transformed displays}.} sind Darstellungen multidimensionaler Datensätze jeder Art. Beispiele sind Parallel Coordinates (Abbildung~\ref{figure:parallel_coordinates}) und die Scatterplot Matrix (Abbildung~\ref{figure:scatterplot_matrix}).

% iconic displays

\textbf{Symbolische} Visualisierungen setzen auf verschiedene Art und Weise Symbole ein. Das können auf eine Karte projizierte Kuchendiagramme sein (Abbildung~\ref{figure:symbol_map}) oder Smileys, die abhängig von den Daten lächeln oder weinen \cite{Chernoff1973}.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/grundlagen-symbol_map.png}
   \caption{Symbol Map}
   \label{figure:symbol_map}
\end{figure}

% dense pixel displays

\textbf{Dense Pixel} Visualisierungen assoziieren jeden Wert einer Dimension mit einem eingefärbten Pixel und platzieren die Pixel einer Dimension nebeneinander. Ein Beispiel dafür ist das Recursive Pattern \cite{Keim1995} (Abbildung~\ref{figure:recursive_pattern}).

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/grundlagen-recursive_pattern.png}
   \caption{Recursive Pattern}
   \label{figure:recursive_pattern}
\end{figure}

% stacked displays

\textbf{Verschachtelte} Visualisierungen repräsentieren Hierarchien, wobei Kindknoten innerhalb ihrer Eltern dargestellt werden. Beispiele dafür sind Treemaps \cite{Shneiderman1992} oder Nested Circles (Abbildung~\ref{figure:nested_circles}).

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.25\textwidth]{images/grundlagen-nested_circles.png}
   \caption{Nested Circles}
   \label{figure:nested_circles}
\end{figure}

\subsubsection{Interaktionstechniken}
\label{section:standderforschung:grundlagen:informationsvisualisierung:interaktionstechniken}

% dynamische projektionen

\textbf{Dynamische Projektionen} zeigen dem Benutzer automatisch beispielsweise verschiedene Scatterplots des Datensatzes. Diese Interaktionstechnik eignet sich besonders für multidimensionale Datensätze. Umgesetzt wurde sie zum Beispiel in XGobi \cite{Swayne1998}.

% interaktives filtern

Durch \textbf{interaktives Filtern} bestimmt der Benutzer, welche Teilmenge des Datensatzes visualisiert wird. Das kann durch direktes Auswählen (Browsing) oder durch Bestimmen von Eigenschaften der gewünschten Daten (Querying) passieren. Letzteres ist in modernen E-Commerce-Systemen durch Facetten \cite{Yee2003} umgesetzt (Abbildung~\ref{figure:faceted_browsing}).

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/grundlagen-faceted_browsing.png}
   \caption{Faceted Browsing bei Amazon.de}
   \label{figure:faceted_browsing}
\end{figure}

% interaktives zoomen

\textbf{Interaktives Zoomen} ermöglicht es dem Benutzer mehr oder weniger Details anzuzeigen. Damit ist nicht nur der computergrafische Vorgang der Skalierung gemeint (wie etwa bei einem Mikroskop), sondern auch schlecht sichtbare Elemente auszublenden (wie z.\,B. bei Google Maps, siehe Abbildung~\ref{figure:zoom}).

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/grundlagen-zoom.png}
   \caption{Interaktiver Zoom bei Google Maps: Im rechten, ausgezoomten Bild fehlt beispielsweise die Interstate 278 (grüne Markierung)}
   \label{figure:zoom}
\end{figure}

% distortion (fisheyes and such)

Durch \textbf{Verzerrung} kann ein Bereich der Visualisierung mit hohem Detailgrad angezeigt werden, während der Rest nur wenig detailliert sichtbar ist. Ein bekanntes Beispiel dafür ist das Fisheye (Abbildung~\ref{figure:fisheye}).

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/grundlagen-fisheye.png}
   \caption{Fisheye: Das Zentrum der Verzerrung befindet sich ungefähr beim hellblauen Knoten in der Mitte}
   \label{figure:fisheye}
\end{figure}

% link & brush

\textbf{Linking \& Brushing} wird vor allem bei mehreren verschiedenen Visualisierungen eingesetzt. Die in einer Visualisierung markierten Daten werden auch in allen anderen Visualisierungen hervorgehoben. Das können zum Beispiel Scatterplots (siehe multidimensionale Visualisierungen in Abschnitt~\ref{section:standderforschung:grundlagen:informationsvisualisierung}), verschiedene Histogramme (Abbildung~\ref{figure:link_brush}\footnote{\url{http://square.github.io/crossfilter/}}) oder gemischte Visualisierungen sein.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.75\textwidth]{images/grundlagen-link_brush.png}
   \caption{Linking \& Brushing bei Crossfilter.js: Ausgewählt wurden Flüge mit mehr als 80 Minuten Verspätung, die betroffenen Bereiche in anderen Histogrammen wurden automatisch markiert.}
   \label{figure:link_brush}
\end{figure}

In diesem Abschnitt wurde ein Überblick über verschiedene mögliche Informationsvisualisierungen gegeben, welche bei der Konzeption berücksichtigt werden müssen. Die enthaltenen Daten können beliebig viele Dimensionen besitzen, in Form von Text auftreten oder Netzwerke beschreiben. Das zu erarbeitende Hilfesystem muss also mit jeder Form von Daten umgehen können. Mögliche Visualisierungstechniken beinhalten Standard 2D/3D Visualisierungen (z.\,B. Balkendiagramme), können aber auch multidimensional sein oder verschachtelt beziehungsweise symbolisch. Für das Hilfesystem bedeutet das, dass von keiner festen Darstellung der Daten ausgegangen werden kann. Die Interaktionstechniken umfassen Filtern, Zoomen und Verzerren der Datendimensionen. Das Hilfesystem kann also beispielsweise keine Annahmen über die verwendete Skala, den sichtbaren Bereich oder die sichtbaren Daten machen.

\subsection{User Assistance}
\label{section:standderforschung:grundlagen:user_assistance}

% was ist assistance?

Der Begriff \enquote{User Assistance} steht für verschiedene Möglichkeiten, einem Benutzer zu helfen seine Ziele zu erreichen. Gapenne et al. \cite{Gapenne2002} definieren vier Beziehungstypen zwischen Mensch und Technologie, welche auch konkret auf Software übertragen werden können. Einer davon ist Assistance:

\begin{quote}
The assistance relationship appears as a sub-category of supplementation since it is not a crucial one for the actual and main activity. The function of this type of technology is to qualify and display the state and/or the becoming of the supplementation device which the subject is engaged in.
\end{quote}

Assistance sind also zum Beispiel eine Einparkhilfe im Auto oder eine Eieruhr in der Küche: Erfolgreiches Einparken oder Kochen ist auch ohne sie möglich, aber leichter mit ihnen. Supplementation hingegen erweitert die Fähigkeiten des Anwenders, also zum Beispiel eine Handprothese mit der die Pfanne angefasst werden kann.

% wie kann man assistance klassifizieren?

Rech et al. \cite{Rech2007} beschreiben intelligente Assistance in der Softwareentwicklung. Prinzipiell müssen zuerst Daten gesammelt werden, bevor die Assistance generiert und angeboten werden kann (Abbildung~\ref{figure:intelligent_assistance}). Folgende Punkte müssen in den einzelnen Schritten beachtet werden.

\begin{itemize}

	\item Daten sammeln
	\begin{itemize}
		\item Welche Datenquellen sollen benutzt werden?
		\item Wann soll die Datenanalyse stattfinden?
		\item Wie können Erkenntnisse aus den Daten gewonnen werden?
	\end{itemize}
	\item Assistance generieren
	\begin{itemize}
		\item Für wen ist die Assistance gedacht?
		\item Was soll durch Assistance erleichtert werden?
		\item Für welchen Prozess/Vorgang ist die Assistance gedacht?
		\item Was ist die Zielumgebung der Assistance?
	\end{itemize}
	\item Assistance anbieten
	\begin{itemize}
		\item Wann soll Asssistance angeboten werden?
		\item Welche Modalität (visuell, akustisch usw.) soll die Assistance anbieten?
		\item Wo soll die Information angezeigt werden?
		\item Warum muss dem Benutzer geholfen werden?
	\end{itemize}
\end{itemize}

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/grundlagen-intelligent_assistance.png}
   \caption{Intelligente Assistance nach \cite{Rech2007}}
   \label{figure:intelligent_assistance}
\end{figure}

Besonders die Modalität der Assistance erscheint von großer Bedeutung für eine schnelle und effektive Wissensaufnahme. Wie Information wahrgenommen wird, hat Auswirkungen sowohl auf Verständnis (\enquote{Ein Bild sagt mehr als tausend Worte}) als auch auf die benötigte Zeit. Tausend Worte können auf der Suche nach relevanten Informationen immer noch überflogen werden, eine zehnminütige akustische Hilfestellung nicht.

% effektivität von textuellen, akustischen, visuellen, gemischten erklärungen

Da kein Medium (Film, Audio, Buch etc.) besser zum Lernen geeignet ist als ein anderes \cite{Clark1994, Kozma1994} und multimodale Erklärungen effektiver als monomodale sind \cite{Mayer2002}, stellt sich die Frage, wie Multimedia-Hilfe konstruiert werden soll. Dazu kann auf die kognitive Multimedia-Lerntheorie zurückgegriffen werden. Sie geht davon aus, dass Menschen Wissen grundsätzlich über zwei Kanäle (visuell und verbal) aufnehmen, entsprechende Repräsentationen bilden und mit vorhandenem Wissen verknüpfen (Abbildung~\ref{figure:kognitive_multimedia_lerntheorie}). Die beiden Aufnahmekanäle sind in ihrer Kapazität beschränkt. Müssen zu viele Informationen verarbeitet werden, kommt es zum \enquote{Cognitive Overload} und die Lernfähigkeit wird eingeschränkt. Daraus ergeben sich vier Richtlinien zur Kontruktion der Multimedia-Erklärungen:

\begin{itemize}
	\item \textbf{Gleichzeitigkeit}: Werden akustische und visuelle Mittel eingesetzt, so sollen sie gleichzeitig präsentiert werden \cite{Mayer1991}. So können Lernende ihre visuellen und verbalen Wissensrepräsentationen besser miteinander verknüpfen.
	\item \textbf{Prägnanz}: Unterhaltsame aber irrelevante Details fördern die Erinnerungsfähigkeit an einen Text nicht \cite{Garner1989}. Deswegen sollen nur relevante Informationen vermittelt werden.
	\item \textbf{Multimodalität}: Informationen sollten möglichst auf visuelle und verbale Art vermittelt werden, um zu verhindern, dass ein Aufnahmekanal überlastet wird (bspw. durch die Darstellung einer Animation mit On-Screen-Text) \cite{Moreno1999}.
	\item \textbf{Keine Redundanz}: Aus dem selben Grund warum zweikanälige Erklärungen vorzuziehen sind, sollte auch Redundanz in einem Aufnahmekanel vermieden werden.
\end{itemize}

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.75\textwidth]{images/grundlagen-kognitive_multimedia_lerntheorie.png}
   \caption{Kognitive Multimedia-Lerntheorie nach \cite{Mayer2002}}
   \label{figure:kognitive_multimedia_lerntheorie}
\end{figure}

% user assistance möglichkeiten für jede modalität

Wie kann User Assistance im visuellen bzw. verbalen Aufnahmekanal aussehen? Verbale Erklärungen können zur Laufzeit generiert werden \cite{Bauer2011, Gesell2012, Matheson2012}, sind jedoch tendenziell zu langatmig formuliert und enthalten viele Wiederholungen. Auf Grund der vorhin erwähnten Designprinzipien \enquote{Prägnanz} und \enquote{Keine Redundanz} sollte davon wahrscheinlich abgesehen und verbale Erklärungen handgeschrieben oder sehr kurz gehalten werden.

Die naheliegendste Möglichkeit für visuelle User Assistance sind Bilder. Illustrationen/Schemata sind in der Tat hilfreich, solange sowohl die Bestandteile des Systems (z.\,B. eine Luftpumpe) als auch die einzelnen Schritte des Prozesses (z.\,B. Luft einziehen, Luft auspumpen) dargestellt werden \cite{Mayer1990}. Auch Comics sind gut geeignet um Sachverhalte zu erklären (Beispiele dafür sind u.\,a. \cite{McCloud1994, McCloud2008}) und eine ansprechende Variante für User Assistance \cite{Webb2012}.

Animationen im Sinne von kurzen Videos mit abstrahiertem Inhalt können ebenfalls ein geeigneter Weg sein um Wissen zu vermitteln, sofern die erwähnten Designprinzipien eingehalten werden \cite{Mayer2002a}. Allerdings ist es möglich, dass Benutzer mit wenig Vorwissen weniger davon profitieren also solche mit viel Vorwissen \cite{Kalyuga2008}. Wenn Animationen eingesetzt werden, sollte den Benutzern Kontrolle über die Geschwindigkeit der Animation gegeben und wichtige Teile gekennzeichnet werden \cite{Wong2011}. Bei Web User Interfaces besteht die Möglichkeit konkrete Elemente der InfoVis für die Animation heranzuziehen. Das würde dem Prinzip der \enquote{Semantic Transparency} \cite{Kohlhase2009} entsprechen, wonach Benutzer möglichst direkt auf den für ihre Ziele relevanten UI-Elementen arbeiten sollen.

\subsubsection{Sensemaking}
\label{section:standderforschung:grundlagen:user_assistance:sensemaking}

% was ist der unterschied zwischen learning und sensemaking?
Im vorhergehenden Abschnitt wurde der Prozess der Wissensvermittlung betrachtet. Um Wissen dauerhaft aufzunehmen, müssen Lernende den Inhalt \emph{verstehen}. Der Begriff \enquote{Understanding} (gleichbedeutend mit Sensemaking) wird angewandt, wenn das Gehirn mehr Elemente des Inhalts (z.\,B. Variablen einer Gleichung) verarbeiten muss als ins Arbeitsgedächtnis passen \cite{Sweller1998}. \emph{Verstanden} hat der Lernende dann, wenn diese Elemente zu einem sogenannten Schema (mentalen Modell) verarbeitet wurden und als ein einziges Element im Arbeitsgedächtnis gehalten werden können (z\,B. eine komplexe Zahl statt drei Variablen $a$, $b$ und $i$).

% wie funktioniert der prozess der wissensaneignung?

Klein \cite{Klein2006a} beschreibt in seinem Data/Frame-Modell (Abbildung~\ref{figure:data_frame_model}), wie dieser Prozess funktioniert. \enquote{Data} beschreibt dabei die Elemente des Inhalts und \enquote{Frame} das mentale Modell oder Schema. Ähnlich dem Visual Analytics Process (Abschnitt~\ref{section:standderforschung:grundlagen:informationsvisualisierung}) ist Sensemaking ein iterativer Prozess, aber ohne wirklichen Anfang oder Ende. Der Lernende startet mit einem Frame, versucht die Daten einzupassen und nimmt Anpassungen vor bzw. verwirft ein Frame, wenn es nicht weiter durch Daten gestützt wird. Dabei sollte der Lernende möglichst selbstständig zu einer Lösung kommen, nicht zu viele Daten gleichzeitig sehen und während des Prozesses keine Hypothesen aufstellen müssen, die nicht überprüft werden können \cite{Klein2006}.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.75\textwidth]{images/grundlagen-data_frame_model.png}
   \caption{Data/Frame Modell nach \cite{Klein2006}}
   \label{figure:data_frame_model}
\end{figure}

% was ist dabei zu beachten?

Während des Verständnisprozesses ist es außerdem hilfreich, Wissen in irgendeiner Form externalisieren zu können, beispielsweise mit Hilfe einer Mind Map \cite{Qu2005, Novak2007, Umapathy2010}. Andere Menschen können dadurch auf bereits durchgeführte Verständnisprozesse anderer aufbauen, wobei die Struktur aber wichtiger ist als der tatsächliche Inhalt \cite{Fisher2012}.

Nachdem betrachtet wurde, wie Verständnis funktioniert, stellt sich die Frage, \emph{was} vermittelt werden soll um Menschen mit wenig InfoVis-Erfahrung zu helfen. Dazu gehört laut Grammel \cite[S. 127]{Grammel2012} unter anderem das mentale Modell des Benutzers zu verwenden, beispielsweise indem dieselben Bezeichnungen verwendet werden, und zu lehren, wie Visualisierungen verwendet und interpretiert werden.  Liu und Stasko \cite{Liu2010} schlagen folgende Definition für ein mentales Modell im Bereich der Informationsvisualisierung vor, wobei vor allem der erste Punkt über Struktur und Verhalten für ein Hilfesystem wichtig erscheint:

\begin{quote}
A mental model is a functional analogue representation to an external interactive visualization system with the following characteristics:
	\begin{itemize}
		\item The structural and behavioral propertys of external systems are preserved in mental models.
		\item A mental model can preserve schematic, semantic or item-specific information about the underlying data.
		\item Given a problem, a mental model of an interactive visualization can be constructed and simulated in working memory for reasoning.
	\end{itemize}
\end{quote}

\section{Verwandte Arbeiten}
\label{section:standderforschung:verwandte_arbeiten}

Im Folgenden werden verwandte Arbeiten behandelt. Zuerst befasst sich Abschnitt~\ref{section:standderforschung:verwandte_arbeiten:mashups} mit Mashup Plattformen. Darauf folgen Visualisierungstools und Teilaspekte davon, die das Sensemaking der Nutzer verbessern sollen. Danach werden verwandte Arbeiten zu User Assistance Konzepten in Mashups und im Allgemeinen vorgestellt und zuletzt eine Zusammenfassung gegeben.

\subsection{Webbasierte Mashup Plattformen}
\label{section:standderforschung:verwandte_arbeiten:mashups}

In diesem Abschnitt werden Mashup Plattformen vorgestellt, mit denen Endnutzer Datenquellen oder UI Komponenten kombinieren können.

% yahoo pipes kombiniert nur datenquellen
% gut: intro und kommunikation
% schlecht: es können kaputte kompositionen erstellt werden (iso norm aussagekräftige fehlermeldungen)

Yahoo Pipes\footnote{\url{http://pipes.yahoo.com/pipes/}} ist eine Mashup Plattform von Yahoo, bei dem der Benutzer verschiedene Webservices mit Hilfe von Operatoren kombiniert, indem er sie interaktiv verdrahtet.
Pipes erfüllt die funktionale Anforderung \emph{Intro}, da zwei Tutorialvideos angeboten werden und eine kurze Beschreibung zu jedem Element inklusive Link zu einem Beispiel und mehr Informationen vorhanden ist. Die \emph{Kommunikation} ist durch die Drähte sichtbar, allerdings ist die Richtung des Datenflusses nicht sofort eindeutig. Pipes erleichtert die \emph{Bedienung} indem während der Drag \& Drop Operation mögliche Anknüpfungspunkte für Drähte blau eingefärbt werden.
Allerdings erschwert es die Bedienung gleichermaßen, da kaputte Kompositionen erstellt werden können und Pipes keine aussagekräftigen Fehlermeldungen ausgibt.
Für die Arbeit mit VizBoard ist es ebenfalls wichtig, die Kommunikation zwischen Komponenten nachvollziehen zu können. Da bei VizBoard der Datenfluss in beide Richtungen fließen kann, sollte darauf geachtet werden, dessen Richtung klar ersichtlich ist.

% dashmash kombiniert ui elemente und datenquellen
% gut: nutzerstudie
% schlecht: 

DashMash \cite{Cappiello2011} ist eine Mashup Plattform, die besonders auf Endnutzer ausgerichtet ist. Dazu setzt es auf das WYSIWYG\footnote{What you see is what you get.} Prinzip und abstrahiert von Mashup-Interna wie dem Binding zwischen Datenquellen und Komponenten. Es ist nicht möglich Erkenntnisse aus den Daten mit anderen zu teilen oder selbst Anmerkungen anderer zu lesen. Obwohl keine sichtbaren\footnote{Ein Demo-Video ist unter \url{http://home.dei.polimi.it/cappiell/demo/DemoDashMash.mov} verfügbar.} Hilfestellungen bezüglich \emph{Intro}, \emph{Bedienung} oder \emph{Kommunikation} verfügbar sind, fiel die Nutzerstudie mit 35~Teilnehmern durchweg positiv aus. Der Grund dafür ist wahrscheinlich, dass die Erklärungen am Anfang der Studie so gewählt wurden, dass die Testpersonen ein \enquote{korrektes} mentales Modell von DashMash hatten. Für die Hilfe in VizBoard sollte deswegen auch soweit möglich Technisches abstrahiert oder vor dem Benutzer versteckt werden. Des weiteren sollten Erklärungen dem mentalen Modell des Benutzers entsprechen.

% omelette auch (weil datenquellen in komponenten drin)
% gut: einfache interaktion (widget hinzufügen und das wars
% schlecht: hilfestellungen hauptsächlich für erstellung als nutzung

Apache Rave\footnote{\url{http://rave.apache.org/}} ist eine Mashup Plattform von Apache und Grundlage für OMELETTE \cite{Chudnovskyy2012}. OMELETTE stellt dem Benutzer verschiedene Widgets zur Verfügung, die er kombinieren kann. Zum Beispiel ein Widget zur Visualisierung des Wasserpegels und eine Karte, die Hochwassermeldungen zeigt. Im Gegensatz zu VizBoard besteht keine Einschränkung auf eine bestimmte Domäne. Es ist möglich Widgets zu kommentieren. Die \emph{Kommentare} werden aber nur im Widget Store angezeigt, da sie eher dem Feedback zum Widget als dem Verständnis des Inhalts dienen. Bezüglich der \emph{Bedienung} oder \emph{Kommunikation} bestehen keine Hilfestellungen. Ein \emph{Intro} wird im Widget Store in Form einer kurzen Beschreibung gegeben, welche der Entwickler verfasst hat. Die Hilfestellungen für den Benutzer fokussieren sich eher auf die Erstellung von Mashups als deren Nutzung \cite{Chowdhury2013}. So wird ein Pattern Recommender eingesetzt, der weitere Widgets zur Integration in die Komposotion vorschlägt sowie eine Automatic Composition Engine, die Widgets automatisch verbindet und damit Daten- und Kontrollflüsse ermöglicht.

% lessons learned

% man braucht gar nicht so viele hilfestellungen, wenn änderungen in der ui auf eigene interaktionen zurückgeführt werden können (nichts anderes heißt ein korrektes mentales modell zu haben)
% es muss klar sein, wo der datenfluss hingeht

In diesem Abschnitt wurden Mashup Plattformen vorgestellt, mit deren Hilfe Webservices oder UI Komponenten kombiniert werden können. Die wichtigste Erkenntnis war dabei, dass kaum Hilfestellungen nötig sind, wenn der Benutzer ein passendes mentales Modell der Anwendung hat. Dieses kann mit Hilfe von Erklärungen vermittelt werden. Erklärungen des Hilfesystems sollten deswegen ein konsistentes Modell der Anwendung und einheitliche Begriffe verwenden.

\subsection{Visualisierungstools}
\label{section:standderforschung:verwandte_arbeiten:visualisierungstools}

Im Folgenden werden Visualisierungstools vorgestellt. Sie bieten mindestens multiple Sichten (ähnlich wie Mashups), sind selbst Mashups (wenn nicht anders angegeben webbasiert) oder besonders populär.

% weave
% gut: ist ein mashup
% schlecht: user interface, keine hilfestellungen

Weave\footnote{\url{http://oicweave.org/}} ist eine Webapplikation, mit der Benutzer ein Mashup aus Visualisierungen erstellen können. Mögliche Datenquellen sind strukturierte Daten wie Tabellen und CSV Dateien. Benutzer können aus verschiedenen Visualisierungen wählen und diese an Daten binden. Das User Interface (Abbildung~\ref{figure:weave}) ist allerdings sehr komplex und Hilfe gibt es nur in Form einer Online-Dokumentation und einem kurzen Tutorialvideo.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.75\textwidth]{images/verwandte_arbeiten-weave.png}
   \caption{Weave User Interface}
   \label{figure:weave}
\end{figure}

% polaris/tableau
% gut: interaktivität, drag & drop zeug
% schlecht: keine verlinkung

Tableau\footnote{\url{http://www.tableausoftware.com/}} ist eine Desktopapplikation, mit der aus Tabellen oder Datenbanken Diagramme erstellt werden können. Es ist der kommerzielle Nachfolger von Polaris \cite{Stolte2000} und laut Gartner \cite{Gartner2013} unter den Marktführern im Bereich Business Intelligence Platforms. Tableau setzt das Prinzip von \enquote{Semantic Transparency} um, indem der Benutzer die zu visualisierenden Daten per Drag \& Drop auf dem Diagramm platziert. Die Software muss keine umfassenden Hilfestellungen zur \emph{Bedienung} anbieten, da der Benutzer hauptsächlich Daten an das Diagramm bindet und den Diagrammtyp wechselt. Jede Aktion hat einen sofort sichtbaren Effekt, welcher mit der Undo-Funktion rückgängig gemacht werden kann. Diese drei Eigenschaften von Tableau (Semantic Transparency, Effekt sofort sichtbar, Undo/Redo) machen es sehr interaktiv, ohne dabei den Benutzer zu frustrieren. Allerdings geht Tableau davon aus, dass der Benutzer die Daten und damit verbundenen Konzepte kennt und bietet diesbezüglich keine Hilfestellungen an.

% choosel
% gut: drag n drop
% schlecht: kenntnis der daten wird vorausgesetzt

Choosel \cite{Grammel2010} ist ein Mashup, welches besonders in der Domäne Informationsvisualisierung unbedarfte Nutzer dabei unterstützen soll, Daten zu erforschen und Visualisierungen iterativ zu verfeinern. Dabei setzt es auf direkte Manipulation in Form einer erweiterten Drag \& Drop Funktion. Mögliche Drop-Ziele werden während des Vorgangs hervorgehoben und eine Vorschau des Drop-Ergebnisses wird  angeboten. Wie Tableau setzt Choosel voraus, dass der Benutzer die verwendeten Daten kennt. Im Gegensatz zu VizBoard sind bei Choosel die verfügbaren Komponenten festgelegt und stammen vom selben Entwickler. Falls im Hilfesystem für VizBoard Drag \& Drop angewendet wird, ist Choosel ein gutes Vorbild.

% mosaic
% ? ? ? 

MoSaiC \cite{Schuster2011} ist ein Tool mit dem Benutzer online kollaborativ Dokumente erstellen können. Wie bei VizBoard ist die Domäne damit festgelegt. Das Tool besteht aus verschiedenen Sichten für die Rollen der Beitragenden (Collaborators) und Organisatoren (Coordinators) und ist damit komposit, es können aber keine zusätzlichen Views aufgerufen werden. Inwieweit MoSaiC den Benutzern Hilfestellungen gibt, ist nicht bekannt, da der Autor keine Screenshots oder Videos finden konnte.

\subsubsection{Sensemaking}
\label{section:standderforschung:verwandte_arbeiten:sensemaking}

Dieser Abschnitt befasst sich mit Teilfunktionen von Visualisierungstools, die das Sensemaking der Benutzer verbessern sollen. Hauptsächlich wird dafür eine Kommentar- bzw. Annotationsfunktion eingesetzt.

% annotation
% gut: einfach zu verwenden
% schlecht: nicht geeignet wenn man keine beliebigen navigationsmöglichkeiten hat

Groth und Streefkerk \cite{Groth2006} präsentieren ein generisches Annotationssystem für Informationsvisualisierungen am Beispiel einer 3D Visualisierung von Molekülen. Grundlage des Systems sind Nutzerinteraktionen wie \enquote{rotieren}, \enquote{zoomen} etc., welche geloggt und als Graph abgespeichert werden. An den Knoten des Graphen -- Zustände der InfoVis -- können beliebig viele \emph{Kommentare} abgelegt werden. Es ist allerdings nicht möglich, innerhalb dieser Sichten noch einmal Elemente zu referenzieren (z.\,B. ein bestimmtes Atom), weswegen das System am besten für InfoVis mit uneingeschränkten Navigationsmöglichkeiten geeignet ist. Zum Beispiel einer Karte, wo mit Hilfe der Interaktionen Pan \& Zoom theoretisch ein beliebiger Punkt auf der Welt den Viewport ausfüllen kann und so eindeutig ist, worauf sich der Kommentar bezieht.

% sense.us
% gut: kommentare, diskussionen, annotationen
% schlecht: kommentare nicht an daten, kenntnis der daten wiederum vorausgesetzt

Heer et al. \cite{Heer2007} entwickelten mit sense.us einen Prototyp zur asynchronen Kollaboration mit interaktiven Visualisierungen. Benutzer können \emph{Kommentare} zu Visualisierungen hinzufügen und sie mit grafischen Annotationen (z.\,B. geometrische Formen, Pfeile, Text) versehen. Die Kommentare wurden dabei aber nicht an die Daten selbst, sondern an die Visualisierung hinzugefügt. Es war möglich, Kommentare in anderen Visualisierungen zu referenzieren. Die am meisten verwendeten Annotationstypen waren Pfeile und Text. Das alles sollte beim Entwurf der Kommentarfunktion des Hilfesystems berücksichtigt werden.

% manyeyes
% gut: kommentare
% schlecht: 

Ebenfalls erwähnenswert ist ManyEyes \cite{Viegas2007}. Benutzer können Datensätze hochladen und eine aus mehreren vorgegebenen Visualisierungen wählen. Danach können sie ähnlich wie bei sense.us die Visualisierungen \emph{kommentieren}. Wie bei sense.us können bestimmte Elemente oder Bereiche einer Visualisierung mit Kommentaren versehen werden, diese werden aber nicht visualisierungsübergreifend wiederverwendet.

% bi dashboards
% gut: annotation an daten
% schlecht: nix, eigentlich isses ziemlich geil

Elias und Bezerianos \cite{Elias2012} entwickelten ein Annotations- bzw. \emph{Kommentarsystem} für Business Intelligence Dashboards.
Dafür interviewten sie Domänenexperten und erarbeiteten sieben funktionale Anforderungen an ein annotationsgestütztes Dashboard. Dazu gehört, dass Kommentare mehrere Datenpunkte und Charts referenzieren können. Sie beschreiben außerdem ihr Handling von Annotationen und Kommentaren bei dynamischem Kontext sowie von unterschiedlichen Granularitätsstufen (Jahr/Monat/Tag). 
Diese Erkenntnisse können für VizBoard ebenfalls nützlich sein.

% infovis mit sensemaking
% gut: knowledge view
% schlecht: nur cool wenn alle inhalte fusioniert werden können. und dann ist immer noch die frage, ob man sowas wirklich braucht. bin skeptisch mit zu viel features

Shrinivasan et al. \cite{Shrinivasan2008} entwickelten ein Framework zur Informationsvisualisierung, welches den analytischen Denkprozess unterstützen soll.
Es besteht aus drei verschiedenen Views: Den InfoVis selbst, einem \enquote{Knowledge View} und einem \enquote{Navigation View}. Im Knowledge View kann der Benutzer seine Hypothesen und Analysen externalisieren, verwalten und überprüfen, sowie mit Zuständen der InfoVis verlinken. Der Navigation View erlaubt es ihm, zu einem beliebigen Punkt im Laufe der Interaktionen zurück zu gehen.
In VizBoard könnte ein Variante des Knowledge Views dazu verwendet werden, um eine nutzergenerierte, strukturierte Zusammenfassung eines Datensatzes zu erstellen. Mit dessen Hilfe könnte der Verständnisprozess zukünftiger Benutzer unterstützt werden. Ein Navigation View könnte zusätzlich die \emph{Bedienung} in VizBoard verbessern.

% lessons learned 

% weave: wenn UI zu komplex wird, macht es keinen spaß
% sense.us: es gibt annotationstypen, die sehr populär sind, aber nicht auf daten bezogen werden können (eben pfeile und text)
% manyeyes: keine ahnung. weder sieht es gut aus noch ist es toll zu nutzen nach heutigen standards (JAVA ALERT) noch hat es viele features.
% bi dashboards: cool wie sie das gelöst haben mit dynamischen kontext. wenn er sich ändert, wird ein snapshot vom kontext zusammen mit der annotation gespeichert. außerdem: UI für kommentare genau wie meine!!

In diesem Abschnitt wurden verschiedene Visualisierungstools und Ansätze, um das Sensemaking in ihnen zu verbessern, vorgestellt. Dabei zeigte sich am Beispiel Tableau, dass wenig Hilfestellungen nötig sind, sofern der Benutzer Systemzustände als Effekt eigener Interaktionen einfach identifizieren kann und die Anwendung offensichtliche Rücksetzmöglichkeiten bietet. Im Fall von VizBoard ist die Situation etwas anders, da mehrere Views gleichzeitig sichtbar sind (bei Tableau ist es immer nur ein Diagramm) und der Systemzustand sich unabhängig von einer Nutzerinteraktion verändern kann (durch Komponenten, die Daten externer Webservices laden). Die Rücksetzmöglichkeit ist aber auch Teil von Shneidermans Mantra \cite{Shneiderman1996} und der ISO Norm~9241-110 \enquote{Grundsätze der Dialoggestaltung}, weswegen sie auf alle Fälle umgesetzt werden sollte.

Um den Verständnisprozess des Benutzers zu unterstützen, verwenden die meisten Systeme grafische Annotationen in Kombination mit Kommentaren. Im Fall von \cite{Elias2012} konnten die Kommentare den Benutzern helfen, neue Diagrammtypen zu verstehen. Probanden in sense.us fanden sowohl eigene als auch fremde Kommentare hilfreich. In Tableau ist es wie in \cite{Elias2012} möglich, Kommentare an Datenpunkten zu erstellen. Die Nützlichkeit von Kommentaren scheint damit außer Frage zu stehen und sie sollten auch in VizBoard implementiert werden. Dabei ist die Arbeit von Elias et al. ein guter Startpunkt, wobei aber zu beachten ist, dass die Visualisierungskomponenten bei VizBoard von fremden Entwicklern stammen und \enquote{Black Boxes} sind. Von keiner der Arbeiten aufgegriffen wurde die Möglichkeit, dass dem Benutzer Teile der Daten oder der darin verwendeten Konzepte unklar sind.

\subsection{User Assistance}

Dieser Abschnitt befasst sich mit verschiedenen Ansätzen zur User Assistance, welche die Anforderungen Verständnis, Vollständigkeit oder Unaufdringlichkeit betrifft. Dazu zählen notwendige Funktionen des Hilfesystems, mögliche Fragestellungen des Nutzers oder Interaktionskonzepte. Zunächst werden Ansätze vorgestellt, die behandeln, was dem Benutzer erklärt werden muss. Darauf folgen Konzepte zur Präsentation der Erklärung und zuletzt zur Reduktion von notwendigen Erklärungen (beispielsweise durch kluge Interaktionstechniken).

% was man erklären muss

% fragestellungen in kontextadaptiven anwendungen
% gut: welche fragen tauchen auf
% schlecht: nicht direkt für uns geeignet

Lim und Dey \cite{Lim2009} kategorisieren mögliche Fragestellungen von Nutzern in kontextadaptiven Anwendungen. Dabei ändert die Anwendung abhängig vom Nutzer- bzw. Nutzungskontext ihren Zustand (z.\,B. schaltet Smartphone auf lautlos) und der Benutzer will wissen, warum (z.\,B. weil er Abends in der Oper ist). Grundlage für Lims Ausführungen ist die Annahme, dass der Nutzer nur eingeschränkt Einfluss auf die Arbeitsweise des Systems hat, etwa durch Hinzufügen eigener Regeln. Das ist im letzten Schritt des VizBoard Workflows nicht gegeben, da der Benutzer die Visualisierungskomponenten selbst ausgewählt hat. Die Fragestellungen könnten aber hilfreich sein, wenn es um die Komponenten selbst geht (\enquote{Warum werden gerade diese Daten angezeigt?}) und so die \emph{Verständlichkeit} und \emph{Vollständigkeit} erhöhen.

% mashup debugging strategien
% gut: kam raus dass datenfluss evtl nicht so klar ist
% schlecht: 

Abgesehen von allgemeinen Fragestellungen wäre es wichtig zu wissen, ob bestimmte Mashupkonzepte besondere Beachtung finden müssen. Cao et al. \cite{Cao2010} untersuchten mit Hilfe der Thinking Aloud Methode \cite{vanSomeren1994} das Verhalten von Endnutzern, wenn sie Mashups erstellen, sowie deren Debuggingstrategien, wenn etwas nicht funktioniert. Dazu benutzten sie das inzwischen eingestellte Microsoft Popfly. In ihrer Studie hatten alle Probanden Probleme mit dem Konzept des Datenflusses, also welche Daten wann zwischen welchen Komponenten ausgetauscht werden. In VizBoard sollte überlegt werden, den Daten- bzw. Kommunikationsfluss explizit anzuzeigen und damit die \emph{Verständlichkeit} zu verbessern.

% inter widget communication
% überblick, is nix gut oder schlecht

In einem Mashup kommunizieren die beteiligten Komponenten miteinander. Weder ist dieser Vorgang für den Benutzer offensichtlich noch sollte er das Kommunikationsparadigma des Mashups lernen müssen. Chudnovskyy et al. \cite{Chudnovskyy2013} kategorisieren Probleme und Lösungsansätze, mit deren Hilfe Benutzer die Kommunikation zwischen Komponenten besser wahrnehmen können. Darunter finden sich Self-Descriptive Design, welches visuelle Hinweise und Annotationen verwendet, sowie die Surprise-Explain-Reward Strategie (Überraschung, Erklärung, Belohnung), die zeitgleich mit einem ungewöhnlichen Vorgang eine Erklärung dazu anbietet. Diese beiden Lösungsansätze könnten gut mit einer expliziten Darstellung des Kommunikationsflusses kombiniert werden.

% grammel phd & mental models
% gut: vorschläge
% schlecht: 

VizBoard ist ein Mashup von Informationsvisualisierungen, weswegen häufige Hindernisse für Endnutzer in diesem Bereich identifiziert werden müssen. Grammel \cite{Grammel2012} verfasste seine Doktorarbeit zum Thema, wie InfoVis-Anfänger Visualisierungen konstruieren. Um sie dabei zu unterstützen und ihr \emph{Verständnis} zu verbessern, schlägt er unter anderem vor, ihr mentales Modell zu verwenden (z.\,B. mit ihnen bekannten Begriffen), kontextuelle Hilfe anzubieten und es ihnen zu erleichtern, mehr über InfoVis zu lernen. Was genau ein mentales Modell bei InfoVis ausmacht, untersuchten Liu et al. \cite{Liu2010}. Demzufolge ist es besonders wichtig, die Struktur und das Verhalten der kompositen InfoVis zu erklären.

% wie man erklären kann

% textuelle erklärungen
% gut: es geht
% schlecht: sie sind langatmig

Erklärungen können nicht nur Bilder oder Videos sein, sondern auch texbasiert. Einige Arbeiten, wie z.\,B. \cite{Gesell2012, Matheson2012}, befassen sich mit der Generierung von textuellen Erklärungen. In beiden Arbeiten ist eine formale Repräsentation des Erklärungsgegenstands notwendig, beispielsweise als Baum von Vorbedingungen und \enquote{ist Teil von} Relationen oder einer Ontologie. In der Evaluation von Matheson et al. merkten einige Probanden an, dass deren Erklärungen zu langatmig seien, was gegenläufig zur Anforderung \emph{Verständlichkeit} ist.

% erklärung mit screenshots
% gut: visuell
% schlecht: nicht automatisch

Um kontextuelle Hilfe mit Bildern einfach umsetzen zu können, entwickelten Yeh et al. \cite{Yeh2011} ein Tool für Entwickler, Lehrer oder den technischen Support. Mit dieser Software sollen sie einfach Screenshots einer Anwendung erstellen und Kommentare sowie grafische Annotationen hinzufügen können. Eine Nutzerstudie wurde nicht durchgeführt, dennoch erscheint dieser Ansatz geeignet, um einfache Ursache-Wirkung Relationen zu veranschaulichen. Um in VizBoard die \emph{Einheitlichkeit} der Hilfe zu gewährleisten, müsste die Generierung aber automatisiert werden.

% user assistance mit comics
% gut: effektiv und besser als PP
% schlecht: 

Ein ähnlicher Ansatz von Hilfe mit Bildern ist der Einsatz von Comics. Webb et al. \cite{Webb2012} überprüften in einer Nutzerstudie, wie User Assistance in Form eines Comics gegenüber einer PowerPoint-Präsentation angenommen wird. Comics lagen in allen Fragestellungen (einfache Nutzung, attraktiv, nützlich, verständlich) vorne, am Besten wurden Comics angenommen, die eine Metapher beinhalteten. Da von Komponentenentwicklern nicht erwartet werden kann, einen Comic zu erstellen, müsste dieser generiert werden. Damit befassten sich unter anderem schon \cite{Kurlander1996, Shamir2006, Chan2009, Wen2012} in unterschiedlichen Kontexten, es ist also möglich.

% kontextuelle hilfe im web

Um auf Webseiten kontextuelle Hilfe anbieten zu können, entwickelten Chilana et al. LemonAid \cite{Chilana2012}. Dabei wählen Benutzer ein beliebiges UI Element aus und bekommen dann eine Liste von Fragen und Antworten dazu angezeigt. Beispielsweise könnte ein HTML \texttt{input} Element ausgewählt werden, in das die Telefonnummer eingetragen werden muss. LemonAid erklärt, warum die Telefonnummer unverzichtbar ist, indem es auf die entsprechende FAQ Seite verweist. Da VizBoard webbasiert ist, kann dasselbe Interaktionspattern auch dort angewendet werden. Visualisierungskomponenten können UI Elemente aber dynamisch erzeugen, darauf müsste Rücksicht genommen werden.  

% wie man bedarf an erklärungen reduzieren kann

% heuristiken für infovis
% gut: undo/redo, visuelle konsistenz
% schlecht: anwendbarkeit? visuelle konsistenz haben wir ja nicht und wollen nicht.

Erklärungen zur Bedienung sind nötig, wenn der Benutzer nicht weiß, wie er eine Aktion ausführen kann (\enquote{Gulf of Execution} nach Norman \cite{Norman1986}). Der Bedarf an Erklärungen kann somit reduziert werden, wenn es die Anwendung nicht zu diesem Gulf of Execution kommen lässt. Zu diesem Zweck wurden einige Richtlinien zur User Interface Gestaltung entwickelt. Dazu gehören unter anderem die ISO9241-110, Sheidermans Mantra \cite{Shneiderman1996} oder die Heuristiken nach Nielsen \cite{Nielsen1994}. Forsell und Johansson \cite{Forsell2010} führten eine Nutzerstudie durch, um aus diesen verschiedenen Richtlinien bzw. Heuristiken zur Heuristischen Evaluation \cite{Nielsen1994} diejenigen herauszufiltern, welche bei Informationsvisualisierungen hilfreich sind. Darunter finden sich Support für Undo/Redo, visuelle Konsistenz und den mentalen Aufwand des Nutzers gering zu halten. So kann die \emph{Verständlichkeit} und \emph{Unaufdringlichkeit} des Hilfesystems von VizBoard erhöht werden.

% mashup debugging
% gut: präventiv fehler erkennen, undo
% schlecht: 

Mit Designrichtlinien im weitesten Sinne beschäftigten sich auch Kuttal et al. \cite{Kuttal2013}. Ein Nachteil von Yahoo Pipes war, dass kaputte Mashups entstehen können. Also entwickelten sie ein System zur automatischen Fehlererkennung in Yahoo Pipes, welches auch gleichzeitig die Fehlermeldungen verständlicher formulierte. In der Nutzerstudie zeigte sich, dass Benutzer mit dem System erfolgreicher Mashups erstellen konnten als ohne. Die Autoren stellen in ihrer Arbeit auch Designrichtlinien vor und raten dazu, keine technische Begriffe zu verwenden und Undo-Möglichkeiten sowie kontextuelle Hilfe anzubieten. Das deckt sich mit den Empfehlungen bisher betrachteter verwandter Arbeiten.

% grafische history für tableau
% gut: verständlich, einfach zu nutzen
% schlecht: 

Um die Undo-Funktionalität in Tableau zu verbessern entwickelten Heer et al. \cite{Heer2008} eine grafische History für Tableau. Sie zeigt Screenshots des Visualisierungszustands, die chronologisch wie eine Timeline angeordnet sind. Ein Klick auf einen Screenshot setzt die Visualisierung in den angezeigten Zustand zurück. Dieses Konzept könnte zur \emph{Verständlichkeit} von VizBoard beitragen, wenn es umsetzbar ist.

% lessons learned

% was muss erklärt werden: struktur und verhalten von infovis
% wie kann erklärt werden: kontextuelle hilfe mit bildern scheint gute möglichkeit
% wie kann weniger erklärt werden: visuelle konsistenz, undo/redo, 

In diesem Abschnitt wurden verschiedene Ansätze zur User Assistance im Allgemeinen und bei Mashups sowie InfoVis im Speziellen betrachtet. Zu der Frage, was erklärt werden muss, konnte als Antwort die Struktur und das Verhalten der Anwendung identifiziert werden, da diese Teil des mentalen Modells des Benutzers sind. Es wurde außerdem gezeigt, dass textuelle Erklärungen langatmig und deswegen visuelle Hilfestellungen besser geeignet sein können. Dazu können Screenshots oder Comics verwendet werden. Die Herausforderung bei VizBoard wäre in diesem Fall, dass sie automatisch generiert werden müssten. Um die Interaktion mit VizBoard besser zu gestalten, kann auf Designrichtlinien für Informationsvisualisierungen zurückgegriffen werden. Diese beinhalten unter anderem visuelle Konsistenz, Undo/Redo, zusätzliche Informationen anzeigen oder den mentalen Aufwand des Benutzers zu reduzieren. Bei VizBoard sind viele der Richtlinien abhängig von den Komponentenentwicklern, aber einige können auch durch das Hilfesystem umgesetzt werden.

\section{Zusammenfassung}
\label{section:standderforschung:zusammenfassung}

In diesem Abschnitt wird eine Zusammenfassung des Kapitels gegeben, welches aus dem Szenario (Abschnitt~\ref{section:standderforschung:szenario}), der Anforderungsanalyse (Abschnitt~\ref{section:standderforschung:anforderungsanalyse}), den Grundlagen (Abschnitt~\ref{section:standderforschung:grundlagen}) und den verwandten Arbeiten (Abschnitt~\ref{section:standderforschung:verwandte_arbeiten}) besteht.

% szenario

Im Szenario wurde eine mögliche Situation anschaulich gemacht und Problemstellungen aufgezeigt. Dazu gehört unter anderem, dass der Benutzer nicht weiß, wie er Komponenten bedienen kann oder wie sie miteinander kommunizieren. Eine weitere Hilfestellung ist, dass in den Daten enthaltene Konzepte erklärt werden sollen. 

% anforderungsanalyse

Auf Basis des Szenarios wurde eine Anforderungsanalyse durchgeführt. Funktionale Anforderungen beinhalten die zu leistenden Hilfestellungen, unter anderem wie erwähnt zur Bedienung, Kommunikation oder Verlinkung. Als nichtfunktionale Anforderungen wurden unter anderem die Korrektheit, Vollständigkeit, Wiederverwendbarkeit und Verständlichkeit der Hilfestellung selbst und die Unaufdringlichkeit der Präsentation identifiziert.

% grundlagen: cruise, semantische daten, infovis, user assistance

Danach wurde in den Grundlagen ein Überblick über die CRUISe Mashup Plattform gegeben, auf der EDYRA und VizBoard aufbauen. Es wurde aufgeführt, dass propertys den Zustand einer Komponente vollständig beschreiben und Komponenten über Links zwischen Events und Operationen miteinander Nachrichten austauschen. Darauf folge eine kurze Einführung in semantische Daten. Dort wurden die wichtigsten Konzepte (Klassen, Instanzen und propertys) erläutert sowie gängige Beschreibungssprachen (RDF, RDFS, OWL) aufgezeigt. Im Abschnitt über Informationsvisualisierungen wurde der Begriff als \enquote{the use of computer-supported, interactive, visual representations of abstract data to amplify cognition} definiert. Mit Hilfe einer Klassifikation anhand der dargestellten Daten, Visualisierungs- und Interaktionstechnik einer InfoVis konnte ein Überblick über selbige gegeben werden. Zuletzt wurden in diesem Abschnitt die Begriffe \enquote{User Assistance} und \enquote{Sensemaking} erklärt. User Assistance ist eine Hilfestellung für den Benutzer, der sein Ziel aber auch ohne sie erfüllen kann. Sensemaking meint den menschlichen Verständnisprozess. Es wurde beispielsweise festgestellt, dass das Medium selbst keinen Einfluss auf die Lernfähigkeit einer Person hat und möglichst gleichzeitig multimodal erklärt werden sollte. In der Domäne InfoVis müssen besonders das Verhalten und die Struktur einer Visualisierung erklärt werden, um das mentale Modell des Benutzers anzusprechen.

% verwandte arbeiten: mashups, visualisierungstools, user assistance

% was ist der wissenschaftliche mehrwert? --> woher weiß ich das überhaupt, wenn das konzept erst später kommt? soll ich die lücken beschreiben, die ich später schließe? wahrscheinlich.

% bedienung, weil automatisch generiert wird, was für den zweck der user assistance bis jetzt neuartig ist. die siggraph typen haben es quasi gemacht "weils geht" oder für storytelling oder was weiß ich. webb2012 haben die handgefertigt.
% kommunikation? weiß nicht... die prinzipien sind dieselben wie im icwe paper
% verlinkung, weil das bis jetzt noch nicht viele zu bedacht haben scheinen
% kommentare, weil entweder haben die leute die komponenten selbst geschrieben oder sie wurden nicht an den daten selbst (sondern der visualisierung) gespeichert und konnten nicht wiederverwendet werden
% history, weil komponenten black boxes, is bei choosel zb nicht so gewesen.
% meta-hilfe... keine ahnung. zwar wird tbr für arme eingesetzt, aber ob das jetzt so wissenschaftlichen mehrwert bietet?

Nach den Grundlagen folgte ein Überblick über verwandte Arbeiten. Dieser wurde in webbasierte Mashup Plattformen, Visualisierungstools und Konzepte zur User Assistance eingeteilt. Nach der Betrachtung von Mashups konnte am Beispiel von DashMash festgestellt werden, dass kaum Hilfestellungen nötig sind, wenn der Benutzer ein passendes mentales Modell der Anwendung hat. Das lässt darauf schließen, dass Erklärungen in VizBoard besonders Rücksicht auf jenes Modell nehmen sollten. Die Visualisierungstools setzten zur Unterstützung des Benutzers auf Undo/Redo, wobei aber im Unterschied zu VizBoard die Anwendung von denselben Entwicklern geschrieben wurde wie die Visualisierungen und somit mehr Kontrolle darüber möglich war. Ein Teilabschnitt über Visualisierungstools befasste sich mit Konzepten, welche das Sensemaking von Daten verbessern sollen. Das populärste davon war Benutzern zu erlauben, Kommentare und Annotationen zu erstellen. Diese wurden aber entweder nicht an den Daten selbst gespeichert und waren kaum wiederverwendbar (sense.us \cite{Heer2007}, ManyEyes \cite{Viegas2007}) oder die Entwickler des Kommentarsystems schrieben auch die Visualisierungen (Business Intelligence Dashboard \cite{Elias2012}). Dann konnten sie Annahmen über die vorhandenen Visualisierungen treffen und die Darstellung und Interaktion der Kommentare entsprechend anpassen. Im Abschnitt über User Assistance waren Undo/Redo, visuelle Konsistenz und das mentale Modell des Benutzers zu verwenden, wiederkehrende Vorschläge. Es wurde außerdem gezeigt, dass Hilfestellungen mit Hilfe von Bildern gegeben werden können, beispielsweise in Form von Screenshots oder Comics. Letztere konnten in unterschiedlichen Kontexten (Chats \cite{Kurlander1996}, Storytelling \cite{Chan2009,Wen2012} usw.) bereits automatisch generiert werden, weswegen das bei VizBoard kein Hindernis sein sollte. Beachtenswert ist, dass kaum eine der vorgestellten Arbeiten berücksichtigte, dass in den Daten enthaltene Konzepte (wie z.\,B. BIP, Yen usw.) dem Benutzer unbekannt sein könnten.

% ###################################################
\chapter{Konzeption}
\label{chapter:konzeption}

Basierend auf dem Szenario (Abschnitt~\ref{section:standderforschung:szenario}), den Grundlagen (Abschnitt~\ref{section:standderforschung:grundlagen}) und den Erkenntnissen aus den verwandten Arbeiten (Abschnitt~\ref{section:standderforschung:verwandte_arbeiten}) wird ein Konzept zur User Assistance für das webbasierte, komposite Informationsvisualisierungssystem VizBoard erarbeitet. Die einzelnen Hilfestellungen können dabei in allgemeine, in jedem CRUISe-basierendem Mashup Einsetzbare (Abschnitte~\ref{section:konzeption:intro}, \ref{section:konzeption:bedienung}, \ref{section:konzeption:feedback}, \ref{section:konzeption:kommunikation}, \ref{section:konzeption:history}, \ref{section:konzeption:meta-hilfe}) und domänenspezifische, besonders für Informationsvisualisierungen Nützliche (Abschnitte~\ref{section:konzeption:verlinkung}, \ref{section:konzeption:kommentare}), eingeteilt werden. Die Ziele richten sich nach der Anforderungsanalyse (Abschnitt~\ref{section:standderforschung:anforderungsanalyse}).

\section{Einführung}
\label{section:konzeption:einfuehrung}

In diesem Abschnitt werden für die Konzeption notwendige Vorbetrachtungen getätigt. So wird zunächst ein Rollenmodell eingeführt (Abschnitt~\ref{section:konzeption:einfuehrung:rollenmodell}), damit Aufgaben korrekt verteilt werden. Danach werden Designrichtlinien für das User Interface des Hilfesystems entworfen (Abschnitt~\ref{section:konzeption:einfuehrung:ui}). Zuletzt wird auf die formative Nutzerstudie eingegangen, welche nach dem ersten Entwurf des Konzepts durchgeführt wurde (Abschnitt~\ref{section:konzeption:einfuehrung:nutzerstudie}). Deren Ergebnisse wurden im zweiten Entwurf, welcher in den folgenden Kapiteln vorgestellt wird, bereits berücksichtigt.

\subsection{Rollenmodell}
\label{section:konzeption:einfuehrung:rollenmodell}

Bei der Konzeption spielt eine große Rolle, wer für welche Tätigkeit verantwortlich ist. Um diese Fragen klären zu können, wird an dieser Stelle ein Rollenmodell für VizBoard eingeführt (Abbildung~\ref{figure:rollenmodell}).

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/konzeption-rollenmodell.png}
   \caption{Rollenmodell von VizBoard}
   \label{figure:rollenmodell}
\end{figure}

Das System VizBoard muss von jemandem betrieben werden. Der \textbf{Operator} bezahlt die Serverkosten und ist für Wartung und Instandhaltung von VizBoard verantwortlich. Für ihn ist wichtig, dass die anderen Parteien zufrieden sind, sodass sein System auch genutzt wird.

VizBoard greift auf die VISO zurück, eine Ontologie von Wissen über Informationsvisualisierung. Der \textbf{Visualization Expert} besitzt Expertenwissen in der Domäne der InfoVis und formalisiert sein es in der VISO, um VizBoard zu verbessern.

Ein wichtiger Teil von VizBoard sind die vorhandenen Daten. Der \textbf{Data Provider} stellt Datensätze in unterschiedlichen Formaten (z\,B. APIs, RDF, OWL oder Excel Daten) zur Verfügung, die von Administratoren -- also letztlich dem Betreiber -- in VizBoard hochgeladen werden können.

Ebenso wichtig wie die Daten sind die Komponenten, die sie visualisieren. Sie werden von \textbf{Component Developers} geschrieben und bei VizBoard registriert. Komponentenentwickler können programmieren und kennen sich teilweise auch mit InfoVis aus.

Der \textbf{User} verwendet VizBoard, um Wissen in semantischen Datensätzen aufnehmen zu können. Er weiß weder über InfoVis noch über semantische Daten Bescheid und verfügt auch nicht über Programmierkenntnisse.

\subsection{User Interface}
\label{section:konzeption:einfuehrung:ui}

Im Laufe der Konzeption werden zum besseren Verständnis einige User Interface Mockups entworfen. Diese basieren auf der Grundlage des Szenarios (Abschnitt~\ref{section:standderforschung:szenario}). Die dort erwähnte Komposition enthält eine Karte, eine Treemap, eine Tabelle und ein Balkendiagramm (Abbildung~\ref{figure:ui-grundlage}). In den verwandten Arbeiten (Abschnitt~\ref{section:standderforschung:verwandte_arbeiten}) war die visuelle Konsistenz eine Designrichtlinie, welche das Bedürfnis nach Hilfestellungen verringern kann. Aus diesem Grund wird im folgenden ein Styleguide für das Hilfesystem beschrieben.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/konzeption-ui-grundlage.png}
   \caption{Grundlage der UI Mockups}
   \label{figure:ui-grundlage}
\end{figure}

\subsubsection{Art}

% wie sieht ui für dings grob aus?

Das User Interface für die ausgewählte Hilfefunktion wird links oder rechts der Komponente in einer Sidebar dargestellt (Abbildung~\ref{figure:ui-basics},~1). Gegenüber einem Popover (2) hat sie den Vorteil, dass sie sowohl links als auch rechts funktioniert. Ein Popover kann nur über der Titelleiste angezeigt werden, ansonsten werden große Teile der Komponente verdeckt (3). Die Sidebar kann in der Größe variieren (4), da für die Kommentare vermutlich mehr Platz benötigt wird als beispielsweise für die Feedbackfunktion.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/konzeption-ui-basics.png}
   \caption{Verschiedene Möglichkeiten zur Platzierung der Hilfe UI}
   \label{figure:ui-basics}
\end{figure}

\subsubsection{Optik}

Visuelle Konsistenz ist wichtig, damit der Benutzer Elemente gleichen Typs erkennen kann (Abschnitt~\ref{section:standderforschung:verwandte_arbeiten}). Deswegen hat der Bereich, in der Hilfefunktionen angezeigt werden, abgerundete Ecken. So hebt sich die UI für Hilfe von der normalen UI der Komponente, welche spitze Ecken aufweist, ab. Aus demselben Grund wird für die Hilfe UI ein dunkler Hintergrund gewählt, da der Hintergrund von VizBoard hell gehalten ist. Um etwas hervorzuheben, wird prinzipiell die Farbe Orange benutzt, da dies im bestehenden VizBoard Farbschema so festgelegt wurde. Eine Überlagerung der Komponente mit einem leichten Grau dient der Blickführung zu einem nicht überlagerten Element. Ist die Komponente hingegen mit einem tiefen Grau überlagert, signalisiert die dunkle Fläche eine \enquote{No Click Area}, wo keine Interaktionen ausgeführt werden können. 

Offensichtlich sind die gewählten visuellen Effekte nicht mehr so nützlich, wenn eine Komponente einen dunklen Hintergrund aufweist. Schwarz mit Dunkelgrau zu überlagern macht für das menschliche Auge nur wenig Unterschied. Deswegen werden in diesem Fall dieselben Effekte mit Weiß und Hellgrau verwendet.

\subsection{Nutzerstudie}
\label{section:konzeption:einfuehrung:nutzerstudie}

Das entworfene Konzept wurde mit einer formativen Nutzerstudie evaluiert und danach entsprechend überarbeitet. Die wichtigste zu beantwortende Frage war dabei, ob die Kommunikationshilfe statisch (d.\,h. nach Klick auf einen Button) oder dynamisch (d.\,h. sobald eine Nachricht zwischen Komponenten ausgetauscht wurde) aufgerufen werden soll. Dazu wurde ein Paper Mockup \cite{Virzi1996} erstellt (Abbildung~\ref{figure:paper-mockup}). Er besteht aus einem Balkendiagramm, einer Karte und einer Tabelle. Als Datengrundlage wurden NBA Spieler gewählt. Die Balken des Balkendiagramms konnten ausgewählt werden, woraufhin sich die Tabelle und die Karte anpassten.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=\textwidth]{images/konzeption-paper-mockup.png}
   \caption{Die ersten zwei Seiten des Paper Mockups}
   \label{figure:paper-mockup}
\end{figure}

\subsubsection{Teilnehmer}

Die Nutzerstudie wurde mit fünf Teilnehmern zwischen 23 und 25~Jahren durchgeführt (Tabelle~\ref{table:mockup:teilnehmer}). Dabei waren 60~\% der Personen männlich. Bei der Auswahl der Probanden wurde darauf geachtet, dass beide Geschlechter und auch andere Domänen außer Informatik vertreten sind.

\begin{table}[htbp]
	\centering
    \begin{tabular}{c|c|c|c}
    Teilnehmer   & Geschlecht & Alter & Domäne      \\
    \hline
    Teilnehmer 1 & M          & 25    & Informatik  \\ %fabi
    Teilnehmer 2 & W          & 23    & Zahnmedizin \\ %anna
    Teilnehmer 3 & M          & 23    & Informatik  \\ %kirsche
    Teilnehmer 4 & M          & 25    & Informatik  \\ %sebastian
    Teilnehmer 5 & W          & 25    & Zahnmedizin \\ %karo
    \end{tabular}
    \caption{Teilnehmer der Nutzerstudie}
    \label{table:mockup:teilnehmer}
\end{table}

\subsubsection{Methode}

% einführung

Zuerst wurde den Teilnehmern eine einführende Erklärung gegeben, wie sie später die Einführung in eine Komponente (Abschnitt~\ref{section:konzeption:intro}) übernehmen soll. Dabei wurde der Typ des Diagramms erklärt (wenn notwendig) und die enthaltenen Daten erwähnt. Über die Kommunikation zwischen Komponenten wurde keine Aussage gemacht, einige Teilnehmer konnten allerdings einfach schließen, dass diese in irgendeiner Form stattfinden musste. 

% ablauf

Nach der Einführung sollten die Testpersonen die Anwendung benutzen, wobei zwei mögliche Fragestellungen erwähnt wurden, denen sie nachgehen konnten. MouseOver-Interaktionen wurden explizit beschrieben, da sie im Paper Mockup nicht sichtbar sind. Die Probanden wurden gebeten, während der Nutzung ihre Gedanken laut mitzuteilen (\enquote{Thinking Aloud} Methode \cite{vanSomeren1994}). Im Laufe des Tests wurden die Teilnehmer beispielsweise gefragt, warum sie bestimmte Dinge annahmen, ob die gezeigten Informationen ausreichen, welche Interaktionsmöglichkeiten sie in einer Situation sahen, welche Veränderungen sie erwarteten oder ob eine alternative Interaktion beziehungsweise ein verändertes User Interface besser geeignet wäre. Wenn sie eine Funktion nicht von selbst wählten (etwa einen Kommentar zu verfassen), wurden sie darauf hingewiesen, sodass jeder Teilnehmer alle Funktionen benutzte.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/konzeption-paper-mockup-anna.jpg}
   \caption{Eine Teilnehmerin der Nutzerstudie}
   \label{figure:paper-mockup-anna}
\end{figure}

Um die Hauptfrage, ob Kommunikationshilfe (Abschnitt~\ref{section:konzeption:kommunikation}) statisch oder dynamisch präsentiert werden soll, zu klären, wurde die dynamische Variante drei der fünf Teilnehmer gezeigt. Die anderen zwei testeten die statische Kommunikationshilfe. Allen Teilnehmern wurde am Ende der Studie die andere Variante erklärt. Sie wurden dann gefragt, ob ihnen die Alternative mehr geholfen hätte oder besser verständlich gewesen wäre.

\subsubsection{Einschränkungen}

% generelle nachteile von thinking aloud
% sehr kleiner mockup
% kein hover, kein scrollen, kein zoomen, keine transparenz...

Die gewählte Methode weist gewisse Einschränkungen auf, denen man sich bei der Auswertung bewusst sein sollte. Einerseits werden Teilnehmer bei \enquote{Thinking Aloud} doppelt belastet. Sie müssen sowohl ein unbekanntes User Interface benutzen, was mentalen Aufwand darstellt, als auch gleichzeitig ihre Gedanken formulieren. Das kann zu Inkonsistenzen in ihren Äußerungen führen.

Andererseits war der Mockup sehr klein, er beinhaltete nur drei Komponenten und zwei Kommunikationskanäle. Gerade letztere konnten die Teilnehmer auch ohne Hilfe verstehen, da sich der \enquote{Bildschirm} nur langsam und schrittweise änderte. Außerdem bezogen sich die Äußerungen und Vorschläge nur auf die vorgestellten Komponenten, ohne Alternativen zu berücksichtigen (beispielsweise Scatterplots, Parallel Coordinates etc.).

Zuletzt liegt es in der Natur des Paper Mockups, dass Interaktionen wie MouseOver, scrollen oder zoomen nur mit viel Aufwand umgesetzt werden können. Da dies im beschriebenen Mockup nicht der Fall war, konnte die Wirksamkeit dieser Interaktionen nicht überprüft werden.

\subsubsection{Ergebnisse}


% Dass Comic = Beschreibung nicht offensichtlich. Mehr beschreiben, in Zukunft vielleicht auch schickeret Panel-Layout, sodass er als Comic und nicht als Reihe von Bildern identifiziert wird. Basti meinte auch, dass Pfeile als letzter Schritt markiert werden sollten, weil er das so als entweder/oder sah. Weiters meinen einige, dass Panels 3-5 ausreichen. Basti sagt, dass zeitlicher Abstand, also quasi Reihenfolge besser deutlich gemacht werden sollte.
% Statische Hilfe hat gewonnen, aber siehe Einschränkungen. Vielleicht macht man in Zukunft einen Threshold, ab dem dynamische Komm.hilfe verwendet wird? Kann man ja in einer weiteren Nutzerstudie austesten, wo die Grenze liegt.
% Dass Kommentare Annotationen enthalten können, war nicht ohne Erklärung klar. Auch nicht, wie man sie hinzufügt --> Ins Intro.
% Auge-Icon versteht irgendwie keiner.
% Voting war nicht klar, Assoziationen mit scrollen. Was mich vor allem bei Typen wundert, die vermutlich täglich bei StackOverflow reinschauen (müssen).
% Wie mit Kommentaren umgehen, die keine Annotationen enthalten? Basti: Badge an Visualisierung.
% Kommentar-Badges ohne Toggle Button? Ich find ja nicht, weil die übelst ablenken können (Scatterplot)
% Brief-Icon war nicht klar, Assoziationen mit Email und Facebook
% Animation von Mauszeiger in Comics: Ausblick.
% Auswahlhilfe für Annotationen: Ausblick.

Die Bedienungshilfe (Abschnitt~\ref{section:konzeption:bedienung}) wurde als ein Comic mit vier Panels vorgestellt, welche die Fragen \enquote{Welche Komponente?}, \enquote{Welche Elemente?}, \enquote{Welche Operation?} und \enquote{Was für ein Ergebnis?} beantworten sollten. Zwei der Teilnehmer konnten sofort erkennen, dass die vier Bilder einen Comic und dieser wiederum eine Anleitung darstellte. Das sollte zusätzlich mit Text beschrieben werden. Außerdem könnte ein ansprechenderes Layout der Panels dazu führen, dass sie mehr als Comic und weniger als vier unabhängige Bilder wahrgenommen werden. Einer der Teilnehmer merkte zusätzlich an, dass nicht ganz klar ist, ob der durch die Pfeile der statischen Kommunikationshilfe (Abschnitt~\ref{section:konzeption:kommunikation}) angedeutete Nachrichtenaustausch immer, nacheinander oder gleichzeitig stattfindet. Nachdem das für das Hilfesystem auch nicht eindeutig ist, kann in dieser Hinsicht leider nicht viel getan werden. Vier der fünf Teilnehmer waren sich einig, dass die letzten drei Panels des Comics auch ausreichen würden, da die Information in den ersten beiden redundant ist: Durch die Auswahl des Pfeils ist klar, um welche Komponenten es geht.

Prinzipiell waren zwei Varianten der Kommunikationshilfe (Abschnitt~\ref{section:konzeption:kommunikation}) denkbar: Einmal würde sie zeitgleich mit der Bedienungshilfe auf Anfrage des Benutzers angezeigt (statisch) und einmal angeboten, sobald ein Nachrichtenaustausch zwischen Komponenten stattfindet (dynamisch). Es gab keinen eindeutigen Sieger bezüglich der Frage, ob sie statisch oder dynamisch angeboten werden soll (Tabelle~\ref{table:paper-mockup-kommunikationshilfe}). Jeder Teilnehmer schätzte die jeweilige Variante der Hilfestellung als notwendig bzw. hilfreich ein ($+$) oder nicht ($-$), wobei ein Teilnehmer sich nicht festlegen wollte (0). Es stellte sich heraus, dass die Probanden sich uneins waren, welche Form die Hilfestellung haben sollte: Je ein Teilnehmer fand beide gut oder beide schlecht, zwei bevorzugten die statische Variante und einer die dynamische. Es ist zu beachten, dass diese Anmerkungen nach einer sehr übersichtlichen Situation im Mashup gemacht wurden. Wäre die Nutzerstudie mit mehr Komponenten durchgeführt worden, böte sich wahrscheinlich ein anderes Bild. Deswegen sollten in einer weiteren Nutzerstudie Grenzwerte für die Anzahl an Komponenten und Kommunikationskanälen bestimmt werden, bei denen Benutzer die Kommunikation nicht mehr ohne weiteres nachvollziehen können. Das Hilfesystem kann dann beim Start der kompositen Anwendung entscheiden, ob zusätzlich die dynamische Kommunikationshilfe eingesetzt werden muss.

\begin{table}[htbp]
	\centering
    \begin{tabular}{c|c|c}
    Teilnehmer   & Dynamisch	& Statisch      \\
    \hline
    Teilnehmer 1 & +			& +  \\ %fabi
    Teilnehmer 2 & -         	& +   \\ %anna
    Teilnehmer 3 & -         	& +    \\ %kirsche
    Teilnehmer 4 & +        	& 0     \\ %sebastian
    Teilnehmer 5 & -         	& -      \\ %karo
    \hline
    Gesamt		& -1			& +2 
    \end{tabular}
    \caption{Wertung der Kommunikationshilfe}
    \label{table:paper-mockup-kommunikationshilfe}
\end{table}

Auffallend war außerdem, dass Teilnehmer, wenn sie über notwendige Ausführungsschritte sprachen, ein anderes Vokabular als die Kommunikationshilfe (Abschnitt~\ref{section:konzeption:kommunikation}) benutzten. Anstatt in Operationen (\enquote{hier auf einen Balken klicken}) sprachen sie in Aktionen (\enquote{hier einen Spieler auswählen}). Das lässt darauf schließen, dass das Hilfesystem ebenfalls in Aktionen sprechen sollte, wenn es die Zusammenhänge zwischen Komponenten erklärt, da es eher dem mentalen Modell der Benutzer entspricht (Abschnitt~\ref{section:standderforschung:grundlagen}).

Ein Teilnehmer schlug vor, die verschiedenen Hilfestellungen zur Kommunikation zusätzlich in der ursprünglich für die Bedienung vorgesehenen Sidebar aufzulisten. Dieser Ansatz ist sowohl einfach als auch für Benutzer offensichtlich. Vermutlich könnte diese Liste, welche dann alle Anleitungen zu Aktionen in der Komponente, alle Effekte von ausgehenden Nachrichten und alle Reaktionen auf eingehende Nachrichten enthielte, schnell sehr lang werden. Es ist zu befürchten, dass Benutzer in diesem Fall die Liste wegen zu viel dargestellter Information gar nicht mehr beachten würden. Deshalb wird dieser Vorschlag vorerst nicht umgesetzt.

Den Teilnehmern war nicht allein aufgrund der UI klar, dass Kommentare (Abschnitt~\ref{section:konzeption:kommentare}) Annotationen enthalten können und wie diese hinzugefügt oder angezeigt werden. Die Kommentare sollten deswegen am Ende des Intros (Abschnitt~\ref{section:konzeption:intro}) zusätzlich erklärt werden. Dasselbe Problem war bei der Bewertungsfunktion von Kommentaren zu beobachten. Die abstrakten, von StackOverflow\footnote{\url{http://stackoverflow.com}} inspirierten Icons wurden auch von Informatikern teilweise mit \enquote{scrollen} anstatt \enquote{bewerten} assoziiert. Deswegen sollte noch einmal explizit mit Text beschrieben werden, dass sie eine Bewertungsfunktion darstellen und welche Semantik sich hinter ihnen verbirgt (\enquote{agree/disagree}). Falls die Funktionalität dann immer noch nicht verständlich ist, können die abstrakten Icons durch Daumen hoch/runter ersetzt werden. Eine weitere Erkenntnis diesem Sachverhalt ist, dass Scrollmöglichkeiten immer explizit dargestellt werden sollten. Das kann entweder in Form einer Scrollbar oder wie im Metro User Interface von Windows Phone~7 mit angeschnittenen Interaktionselementen passieren.

Von zwei Teilnehmern kam der Vorschlag, die Anzahl der Kommentare (Abschnitt~\ref{section:konzeption:kommentare}) in einer Visualisierung ständig darzustellen und nicht über einen Button in der Titelleiste zu toggeln. Hier ist aber zu beachten, dass die Komponenten im Paper Mockup sehr einfach gehalten waren und sehr eingeschränktes Interaktionspotential boten. Bei einem großen Scatterplot oder Parallel Coordinates ist diese Variante nicht mehr praktikabel. Aufgrund des Ziels der \emph{Einheitlichkeit} sollten auch keine Ausnahmen gemacht werden.

Weitere Vorschläge, die hier den Rahmen sprengen würden und in weiteren Arbeiten behandelt werden können, beinhalten zusätzlich einen Mauszeiger im Comic zu animieren oder Vorschläge für mögliche Auswahlrechtecke bei den Annotationen anzubieten.

\section{Intro in die Funktionalität einer Komponente}
\label{section:konzeption:intro}

Aus dem Szenario (Abschnitt~\ref{section:standderforschung:szenario}) und den verwandten Arbeiten (Abschnitt~\ref{section:standderforschung:verwandte_arbeiten}) wurde deutlich, dass dem Endnutzer zuerst ein Überblick über die verschiedenen ausgewählten Komponenten gegeben werden muss, sodass ihm die Struktur der kompositen InfoVis klar wird. Diese beinhaltet folgende Punkte.

% was kommt rein?

\begin{enumerate}
	\item Art der Visualisierung, z.\,B. \enquote{Balkendiagramm}
	\item Beschreibung der Visualisierung, z.\,B. \enquote{Ein Diagramm, das durch auf der x-Achse senkrecht stehende, nicht aneinander grenzende Rechtecke die Häufigkeitsverteilung einer diskreten Variable veranschaulicht.}
	\item Informationen über enthaltene Daten, z.\,B. BIP auf der y-Achse und Länder auf der x-Achse.
	\item Links zu Tutorials, Videos und Erklärungen
	\item Vor- und Nachteile der ausgewählten Visualisierung, z.\,B. \enquote{übersichtlich, wenn wenige Farben vorhanden sind}
\end{enumerate}

% abgrenzung zu "der dev macht das"
Eine Möglichkeit -- so ist die Beschreibung einer Komponente bereits umgesetzt -- ist den Komponentenentwickler selbst einen Text dazu schreiben zu lassen. Er fügt diesen in die Komponentenbeschreibung ein, von wo das Hilfesystem ihn dann auslesen kann. Allerdings kann auf diese Weise kein \emph{einheitliches} Vokabular bezüglich Informationsvisualisierungen sichergestellt werden. Ein einheitliches Vokabular ist aber wichtig, da unterschiedliche Bezeichnungen derselben Konzepte kontraproduktiv für das Verständnis sind. Deswegen werden die Informationen direkt zu den entsprechenden Konzepten in der VISO hinzugefügt. Von dieser zentralen Stelle kann das Hilfesystem sie dann auslesen und anzeigen, sodass die verwendeten Vokabeln konsistent bleiben. Außerdem kann eine einheitliche Beschreibung die Forderungen nach \emph{Vollständigkeit} und \emph{Korrektheit} erfüllen.

% was bleibt draußen?

% links zu externen quellen
Nach Grammel \cite{Grammel2012} können Links zu Tutorials und Erklärungen hilfreich sein, Endnutzern Visualisierungen zu erklären. Da externe Quellen aber nicht durch das Hilfesystem kontrolliert werden, kann es nicht sicherstellen, dass überall ein einheitliches Vokabular benutzt wird. Wie bereits erwähnt ist ein konsistentes Vokabular wichtig für effektive Hilfestellungen, weswegen dieser Punkt in dieser Form nicht umgesetzt werden kann. Was allerdings möglich ist, sind vom VizBoard-Betreiber erstellte Tutorialvideos in Form von vertonten Animationen, die Aufbau und Vor- bzw. Nachteile grafischer Repräsentationen erklären. Das sind zwar viele Videos, aber die Anzahl der Repräsentationen ist endlich und nicht alle sind gleich wichtig\footnote{Ein Balkendiagramm ist gängiger und deswegen leichter verständlich als eine Scatterplot Matrix.}, weswegen der nötige Aufwand gerechtfertigt scheint.

% vor- und nachteile
Grammel schreibt ebenfalls, dass InfoVis-Novizen die Vor- und Nachteile von verschiedenen Visualisierungstypen und visuellen Mappings lernen sollten \cite[S. 125]{Grammel2012}. Es wäre möglich, allgemeine Eigenschaften von grafischen Repräsentationen in der VISO zu beschreiben. Diese sind abhängig von den dargestellten Daten und den visuellen Mappings. Die Eigenschaft \enquote{Übersichtlichkeit} ist bei einem Balkendiagramm mit drei Balken gegeben (Vorteil), bei 15 Balken nicht (Nachteil). Ähnlich verhält es sich mit der Farbkodierung: Ein Mensch kann bis zu acht Farben in einer Visualisierung gut unterscheiden (Vorteil) \cite{Mazza2009}, aber mehr nicht (Nachteil). Das Hilfesystem müsste dem Benutzer demnach sowohl die unterschiedlichen Vor- und Nachteile als auch deren Bedingungen präsentieren, was sehr viel Information für eine Einführung darstellt. Im schlechtesten Fall kann der Benutzer auch keinen Bezug zur konkreten Visualisierung herstellen, weil keine der aufgeführten Bedingungen erfüllt ist. Er kann die aufgestellte Hypothese nicht am Beispiel überprüfen, was laut Grundlagen schlecht für seinen Verständnisprozess ist (Abschnitt~\ref{section:standderforschung:grundlagen:user_assistance:sensemaking}). Hinzu kommt, dass diese Erklärung einen Schritt früher im VizBoard Workflow konzeptionell mehr Sinn macht. Dort wählt der Benutzer -- von VizBoard unterstützt -- die visuellen Mappings aus.

Aus den eben aufgeführten Gründen zeigt das Intro für eine Komponente folgende Informationen:

\begin{enumerate}
	\item Art der Visualisierung
	\item Beschreibung
	\item Enthaltene Daten
	\item Tutorialvideo, wenn vorhanden
\end{enumerate}

Davon ist Punkt~3 spezifisch für die Domäne der Informationsvisualisierung, da CRUISe Komponenten keine Daten visualisieren müssen. Die anderen Punkte sind für alle auf CRUISe basierenden Mashups hilfreich.

% interaktionshilfen - kommen später

Über die Interaktion mit der Visualisierung wird hier noch keine Aussage gemacht, da sie sehr umfangreich sein kann und den Rahmen des Intros sprengen würde. In Abschnitt~\ref{section:konzeption:bedienung} wird eine Hilfestellung zur Bedienung einer Komponente erarbeitet.

\subsection{User Interface und Interaktion}
\label{section:konzeption:intro:ui}

Nachdem der Benutzer bei der Visualisierung angekommen ist und die Komponenten sieht, wird der gesamte Viewport abgedunkelt und eine Sidebar neben der ersten Komponente (von links oben nach rechts unten) eingeblendet (Abbildung~\ref{figure:ueberblick}). Dort sind die im vorigen Abschnitt erläuterten Informationen zu finden: Die Art der Visualisierung (\enquote{Karte}), darunter eine Beschreibung einer Karte, Informationen zu den dargestellten Daten und zuletzt ein Tutorialvideo, wenn vorhanden. So werden die Fragen \enquote{Was ist das für eine Visualisierung?}, \enquote{Wie soll ich sie interpretieren?} und \enquote{Was zeigt sie für Daten?} beantwortet. Mit den Pfeilen links und rechts kann zwischen den Beschreibungen für verschiedene Komponenten gewechselt werden. Über die Meta-Hilfe (Abschnitt~\ref{section:konzeption:meta-hilfe}) kann das Intro wieder aufgerufen werden, wenn es geschlossen wurde.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.75\textwidth]{images/konzeption-ueberblick.png}
   \caption{UI Mockup: Intro}
   \label{figure:ueberblick}
\end{figure}

\subsection{Backend}
\label{section:konzeption:intro:backend}

Die VISO (Abschnitt~\ref{section:standderforschung:grundlagen:cruise_vizboard:viso}) enthält bereits ein Vokabular für Informationsvisualisierungen. Deswegen ist es naheliegend, die Beschreibung der Visualisierung in die VISO hinzuzufügen. Die Art der grafischen Repräsentation muss der Komponentenentwickler bereits jetzt in der Komponentenbeschreibung hinzufügen. Das bedeutet das Hilfesystem kann die entsprechenden Daten auslesen. Die in der Visualisierung verwendeten Daten entsprechen dem Domain Assignment, welches der Komponente von der Laufzeitumgebung mitgeschickt wird. Das Domain Assignment ist das Mapping vom während der Integration erstellten generischen Datenschema auf Konzepte, die in einer externen Wissensbasis wie der DBpedia beschrieben werden \cite{Voigt2012a}.

% core erweiterung

Damit das Hilfesystem aber die URIs der aktuell visualisierten Datatype propertys bekommt, muss das CoRe erweitert werden. Aktuell gehen die URIs bei der Transformation in das generische Datenschema verloren, weil sie umbenannt werden. Um dem Komponentenentwickler Aufwand zu ersparen sollte deswegen das CoRe dahingehend erweitert werden, dass das ursprüngliche Mapping der MRE mitgeliefert wird.


\section{Bedienung einer Komponente}
\label{section:konzeption:bedienung}

In den verwandten Arbeiten (Abschnitt~\ref{section:standderforschung:verwandte_arbeiten}) wurde festgestellt, dass das Hilfesystem den Benutzer über das Verhalten der InfoVis aufklären muss. Da die Komponenten \enquote{Black Boxes} sind und von verschiedenen Entwicklern stammen, kann der Benutzer weder von verfügbaren möglichen Aktionen wie z.\,B. zoomen noch von einheitlicher Gestaltung der Interaktionen ausgehen. Beispielsweise wann eine Interaktion durch \texttt{MouseOver} anstatt \texttt{Click} ausgeführt wird. Zusätzlich sind die verschiedenen Komponenten wahrscheinlich visuell inkonsistent, einmal gelerntes kann nur schwer wiederverwendet werden. Deswegen ist eine Hilfestellung zur Bedienung notwendig.

% wieder erste möglichkeit: dev baut selbst hilfe ein. text+bilder: kein einfluss auf wortwahl, art der bilder, ausführlichkeit etc. Comics: für jede aktion eins, übelster aufwand, kann man nicht verlangen, außerdem 2. wer sagt dass ein prof. sw-entwickler das können soll?

Die einfachste Umsetzung der Hilfe zur Bedienung ist dem Komponentenentwickler eine Möglichkeit zu geben, Text und Bilder zu diesem Thema in die Komponentenbeschreibung einzufügen. Das hat allerdings den Nachteil, dass das Hilfesystem keinen Einfluss auf die Wortwahl, Gestaltung der Bilder oder Ausführlichkeit der Erklärung hat (Ziele der \emph{Einheitlichkeit}, \emph{Vollständigkeit}, \emph{Korrektheit}, \emph{Verständlichkeit}).

Hilfestellungen zur Bedienung würden vom Benutzer wahrscheinlich am besten verstanden, wenn sie tatsächlich vorhandene, konkrete Elemente der Komponente verwendete (\enquote{Semantic Transparency} \cite{Kohlhase2009}). Um zu demonstrieren, dass nach einem Klick die Tabelle sortiert sein wird, könnten die Zeilen derselben beispielhaft ihre Position wechseln. Assistance in dieser Form kann auf zwei Arten umgesetzt werden, die beide ihre Nachteile haben.

Einerseits könnten Aktionen mit Hilfe einer festgelegten Grammatik beschrieben werden. Beispielsweise würde die Aktion \enquote{sortieren} beinhalten, dass Elemente in Abhängigkeit eines Attributwerts ihre Position in der Visualisierung ändern. Dann könnte das Hilfesystem selbst die Tabellenzeilen demonstrativ sortieren, da es nun weiß, was die Aktion \enquote{sortieren} bedeutet. Der große Nachteil daran ist, dass es vermutlich immer einen Komponentenentwickler geben wird, der eine unvorgesehene Aktion in seiner Komponente umsetzen will und sie nicht beschreiben kann. Die zweite Lösung, eine semantisch transparente Assistance umzusetzen, ist den Komponentenentwickler für jede Aktion eine Methode in seiner Komponente hinzufügen zu lassen, die diese demonstriert. Zur Laufzeit würde die Methode einfach vom Hilfesystem aufgerufen. Das hat allerdings den Nachteil, dass dem Komponentenentwickler erheblicher Mehraufwand aufgebürdet wird und keine Einheitlichkeit der Assistance garantiert werden kann. Aus diesen Gründen ist eine andere Lösung notwendig.

Wie in den Grundlagen (Abschnitt~\ref{section:standderforschung:grundlagen:user_assistance}) gezeigt, können Comics eine effektive und attraktive Lösung für User Assistance sein. Allerdings stellt es für den Entwickler erheblichen Mehraufwand dar, für jede mögliche Aktion verschiedene Comicpanels zu erstellen. Davon abgesehen können (und sollen) die gestalterischen Fähigkeiten dazu nicht von ihm erwartet werden (\emph{Minimalität}) und das Problem der Kontrolle über den Inhalt ist auch nicht gelöst (\emph{Korrektheit}, \emph{Vollständigkeit}, \emph{Verständlichkeit}).

Aus diesem Grund werden die Comicpanels vom Hilfesystem automatisch erstellt. Es bleibt die Frage der Präsentation: Aus den Grundlagen geht hervor, dass eine multimodale Ausgabe (akustisch-verbal und visuell) zur Lerneffektivität beiträgt. Darauf wird aber aus zwei Gründen verzichtet. Einerseits sollen beide Kanäle gleichzeitig ausgegeben werden. Das ist problematisch, weil vier Panels darzustellen wesentlich schneller möglich ist als eine verbale Erklärung für den Vorgang zu sprechen. Die Darstellung der Panels müsste sich der Audioausgabe anpassen und würde wesentlich langsamer vonstatten gehen. Eine nichtfunktionale Anforderung an die Hilfestellung ist aber, dass der Benutzer die Hilfe schnell aufnehmen und verarbeiten können soll. Zweitens wird automatische Soundausgabe gemeinhin als schlechte Usability angesehen. Hauptsächlich weil der Nutzen von Screenreadern dadurch eingeschränkt wird, aber auch weil der Benutzer automatische Wiedergabe nicht kontrollieren kann und die Audiodaten möglicherweise unerwünscht Bandbreite beanspruchen.

% also bleibt es an uns hängen.

\subsection{API und Komponentenbeschreibung}
\label{section:konzeption:bedienung:api}

% ### daten sammeln

Die VISO enthält im Namensraum \texttt{viso:activity} Konzepte der hierarchischen Aktivitätstheorie nach Kuutti \cite{Kuutti1996}:

\begin{itemize}
	\item \textbf{Aktivitäten} stellen langfristige Ziele des Benutzers dar, die nicht unmittelbar zu Ergebnissen führen (müssen). In Bezug auf das Szenario (Abschnitt~\ref{section:standderforschung:szenario}) wäre die Aktivität von Anna \enquote{mehr über die geografische Verteilung verschiedener Genvariationen lernen}.
	\item \textbf{Aktionen} sind Teilziele der Aktivität. Im Szenario sind das \enquote{VizBoard aufrufen}, \enquote{Komponenten auswählen}, \enquote{Tabelle sortieren} etc.
	\item Aktionen bestehen wiederum aus einer Kette von \textbf{Operationen}, also beispielsweise Klicks oder Drags.
\end{itemize}

Für das Hilfesystem sind Operationen und Aktionen relevant, da Aktivitäten nicht beeinflusst werden können. Aktionen einer Komponente sind beispielsweise zoomen, suchen oder filtern; Operationen sind etwa Klicks, Drags oder Multitouch-Gesten.

Die CRUISe Komponentenbeschreibung gibt bereits Auskunft über die verfügbaren Aktionen in einer Komponente (Capabilities). Diese können entweder mit (UI Capability) oder ohne Nutzerinteraktion (System Capability) ausgeführt werden. Für die Bedienungshilfe sind erster Linie UI Capabilities interessant. Allerdings wird sich bei der Hilfe zur Kommunikation (Abschnitt~\ref{section:konzeption:kommunikation} zeigen, dass System Capabilities ebenfalls behandelt werden müssen. Im Folgenden werden zunächst UI Capabilities beschrieben.

\subsubsection{UI Capabilities}

In der Komponentenbeschreibung fehlen Informationen darüber, welche Operationen auf welchen Elementen eine Aktion ausführen. Um dem beizukommen, werden Operationen aus der VISO (\enquote{welche Operationen}) zusammen mit CSS Selektoren (\enquote{welche Elemente}) in der Komponentenbeschreibung definiert. Aktionen können oft auf verschiedene Weise ausgeführt werden, haben also so gesehen eine Menge von äquivalenten Operationen. Wenn beispielsweise eine Tabelle sowohl durch einen Klick auf den Spaltenkopf als auch über ein separates Menü sortiert werden kann, werden diese Aktionen als äquivalent zusammengefasst. Sequentielle Operationen werden ebenfalls zusammengefasst, wobei die Reihenfolge im Markup die notwendige Ausführungsreihenfolge darstellt. So können auch zusammengesetzte Operationen, wie beispielsweise für ein HTML \texttt{select} Element nötig, abgebildet werden. Parallele Operationen werden nach demselben Prinzip zusammengefasst, allerdings ist hier die Reihenfolge irrelevant, da sie gleichzeitig ausgeführt werden müssen. Auf diese Weise können zusammengesetzte Operationen der der Art STRG+T abgebildet werden.

Außerdem kann der Komponentenentwickler eine Wartezeit definieren, die bei der Generierung der Panels beachtet werden soll. Zum Beispiel ist das sinnvoll, wenn längere Animationen zu erwarten sind. Der Entwickler könnte UI Elemente innerhalb von fünf Sekunden anstatt 500~Millisekunden einblenden wollen. Zusätzlich zur Wartezeit ist es möglich, dass der Entwickler Zusatzinformationen in Stichworten angibt. Zum Beispiel könnte bei einem Balkendiagramm die Skala \enquote{verändert} (Aktion) werden. Dabei ist es wichtig zu wissen, welche Skala verwendet werden wird, z.\,B. linear oder logarithmisch. Der Inhalt dieser Zusatzinformationen kann statischer Freitext oder eine Referenz auf eine Datenvariable im Schema der Komponente sein, deren Label zur Laufzeit mit Hilfe des Mappings zwischen Daten und Schema der Komponente angezeigt würde. Nach demselben Prinzip sollten auch Zusatzinformationen über die VISO Operation angegeben werden können. Vor allem bei Tastaturkürzel (z.\,B. j/k für vor/zurück) macht es Sinn, da so nicht für jede Taste eine VISO Operation erstellt werden muss. Die erwähnten Zusätze zur Komponentenbeschreibung sollten allerdings optional sein, falls der Komponentenentwickler keine Hilfe für bestimmte Aktionen anbieten will.

\subsubsection{System Capabilities}

System Capabilities unterscheiden sich von UI Capabilities dadurch, dass sie nicht durch Nutzerinteraktionen ausgeführt werden können. Sie werden an CRUISe Operationen annotiert, welche wiederum als Reaktion auf Events ausgeführt werden. Deswegen ist es nicht sinnvoll, hier VISO Operationen anzugeben. Stattdessen sollten in diesem Fall Beispieldaten aufgeführt werden, anhand derer die Operation im Kontext des Testdatensatzes ordnungsgemäß ausgeführt werden kann. Andere Annotationen wie z.\,B. die Wartezeit können beibehalten werden.

\subsubsection{Zusammenfassung}

Im folgenden werden die in diesem Abschnitt vorgenommenen Änderungen an der Komponentenbeschreibung noch einmal zusammengefasst:
\begin{itemize}
	\item Zu den Aktionen werden VISO Operationen angegeben, welche diese ausführen. Diese können atomar, sequentiell oder parallel sein.
	\item Zu den VISO Operationen werden CSS Selektoren angegeben, um die relevanten UI Elemente zur Laufzeit finden zu können.
	\item Die VISO Operationen können Zusatzinformationen beinhalten, um sie genauer und verständlicher zu definieren. Ein Beispiel ist die Taste zur Operation \enquote{tippen}.
	\item Zu den Aktionen wird eine Anzahl von Sekunden angegeben, welche die Zeit bis zur finalen Änderung des User Interfaces angeben (beispielsweise wenn alle Animationen beendet sind).
	\item Zu den Aktionen können Zusatzinformationen in Form Freitext oder Referenzen auf Datenvariablen angegeben werden, um sie näher zu beschreiben.
	\item Falls die Aktion eine System Capability ist, werden Beispieldaten angegeben, mit denen eine CRUISe Operation ordnungsgemäß ausgeführt werden kann.
\end{itemize}

\subsection{Generierung der Assistance}
\label{section:konzeption:bedienung:generierung}

% ### assistance generieren

% warum müssen wir bilder generieren und wie sehen die aus?

Die User Assistance zur Bedienung soll ein Comic werden, der per Definition wiederum aus mehreren Panels besteht, die Bilder und/oder Text enthalten \cite{McCloud1994}. Die Bilder der Panels können nicht a priori gezeichnet werden, da der Inhalt der Komponenten unbekannt ist (\enquote{Black Box} Prinzip). Aus diesem Grund müssen sie automatisch generiert werden. Die einfachste Möglichkeit dafür sind Screenshots der Komponente.

% wie machen wir das?

Dazu wird ein sogenannter \enquote{Headless Browser} eingesetzt. Das ist ein programmierbarer Browser ohne grafische Benutzeroberfläche, der z.\,B. Screenshots einer Seite abspeichern oder Testskripte ausführen kann. Beispiele sind unter anderem PhantomJS\footnote{\url{http://phantomjs.org/}}, HTMLUnit\footnote{\url{http://htmlunit.sourceforge.net/}} oder Ghost\footnote{\url{http://jeanphix.me/Ghost.py/}}.

% wie läuft das ab?

Bei der Generierung der Panels ist zuerst das Component Repository beteiligt. Sobald eine Komponente hinzugefügt oder upgedatet wurde, parst das CoRe die entsprechende Komponentenbeschreibung und schickt eine Anfrage an den Hilfeservice. Dieser kann ins CoRe integriert sein, sollte dem \enquote{Separation of Concerns} Designprinzip folgend aber davon getrennt sein, da es schon für Matching, Ranking und Verwaltung der Komponenten zuständig ist. Der Hilfeservice rendert die Komponente mit Hilfe des Headless Browsers in einer CRUISe Testumgebung. Sie besteht aus folgenden Komponenten:

\begin{itemize}
	\item Laufzeitumgebung: Sie ist unter anderem für die Initialisierung und das Layout der Komponenten nötig.
	\item Data Repository: Die Komponente muss Daten darstellen, welche aus dem DaRe kommen können (aber nicht müssen).
	\item Component Repository: Das CoRe enthält alle verfügbaren Komponenten und stellt sie dem Hilfeservice zur Verfügung.
\end{itemize}

Es wurde eben erklärt, dass das DaRe die (Test-)Daten für eine Komponente liefern kann. Der Komponentenentwickler gibt in der Komponentenbeschreibung den gewünschten Datensatz und die zu visualisierenden Daten in Form einer SPARQL Query an, welche die Laufzeitumgebung bei der Generierung der Assistance der Komponente zur Verfügung stellt. Das kann ein \enquote{echter} Datensatz oder ein vom VizBoard-Betreiber zur Verfügung gestellter Testdatensatz sein. Es kann allerdings passieren, dass das DaRe keine passenden Daten enthält, weil die Komponente sehr spezielle Daten visualisiert (z.\,B. 3-Sterne-Hotels in Andorra). Dann sollte der Komponentenentwickler zusammen mit der Komponente Testdaten hochladen können oder eine URL angeben, unter der sie zu finden sind. Das ist zwar etwas Mehraufwand, aber es kann angenommen werden, dass im Laufe der Entwicklung einer Komponente sowieso Testdaten verwendet wurden. Sie müssen in den meisten Fällen also nicht mehr erstellt, sondern nur noch zur Verfügung gestellt werden. Die Bedienungshilfe kann für alle auf CRUISe basierenden Mashups hilfreich sein. Allerdings kann nicht davon ausgegangen werden, dass diese über ein Data Repository verfügen. Dann muss der Komponentenentwickler in jedem Fall Testdaten zur Generierung der Hilfe zur Verfügung stellen.

Nachdem die Komponente von der Laufzeitumgebung vollständig initialisiert und integriert wurde, führt der Hilfeservice folgende Schritte aus:

\begin{enumerate}
	\item Für jede verfügbare UI Capability:
	\begin{enumerate}
		%\item Finde die Bounding Box der relevanten Elemente
		\item Für alle äquivalenten Operationen:
		\begin{enumerate}
			\item Für jede Operation:
			\begin{itemize}
				\item Finde die Bounding Box der betroffenen Elemente und speichere sie
				\item Hebe betroffene Elemente hervor
				\item Erstelle einen Screenshot der Komponente
				\item Setze Zustand der betroffenen Elemente zurück
			\end{itemize}
		\end{enumerate}
		\item Führe die Aktion aus
		\item Warte die definierte Anzahl an Sekunden
		\item Erstelle einen Screenshot vom Ergebnis der Aktion
	\end{enumerate}
\end{enumerate}

Falls die Operation in Schritt 2.a.i sequentiell sein sollte, muss der beschriebene Algorithmus die Bounding Box der Elemente jeder Teiloperation finden, genauso bei parallelen Operationen. Für System Capabilities wird derselbe Algorithmus verwendet, allerdings entfällt der Teil mit VISO Operationen. Stattdessen wird einfach die CRUISe Operation ausgeführt.

\begin{enumerate}
	\item Für jede verfügbare System Capability:
	\begin{enumerate}
		\item Führe die CRUISe Operation mit Beispieldaten aus
		\item Warte die definierte Anzahl an Sekunden
		\item Erstelle einen Screenshot vom Ergebnis der Aktion
	\end{enumerate}
\end{enumerate}

% hell und dunkel unterscheiden

Nachdem alle nötigen Screenshots der Komponente erstellt wurden, muss das Hilfesystem eine Kategorisierung in \enquote{helle Komponente} und \enquote{dunkle Komponente} vornehmen. Das ist nötig, damit das Hilfesystem zur Laufzeit weiß, ob es dunkle oder helle visuelle Effekte einblenden soll. Eine naive Möglichkeit dazu wäre mit Hilfe einer Bildverarbeitungsbibliothek wie OpenCV\footnote{\url{http://opencv.willowgarage.com/wiki/}} die Screenshots zu binärisieren, also in Bilder aus schwarzen und weißen Pixeln umzuwandeln. Enthält die Mehrzahl der Bilder mehr schwarze als weiße Pixel, wird die Komponente als \enquote{dunkel} eingestuft, ansonsten als \enquote{hell}.

% anbieten der assistance diskutieren: bilder in smcdl einbinden, eigener webservice, core.

Die Bilder der Comics können auf unterschiedliche Weise ans Hilfesystem ausgeliefert werden. Eine Möglichkeit ist die Bilder nach Generierung in der Komponentenbeschreibung zu definieren, so wie es bereits mit einem Screenshot der Komponente gemacht wird. Ebenso könnte ein Webservice die Bilder über eine REST API anbieten, von wo das Hilfesystem sie zur Laufzeit lädt. Dieser Webservice kann eigenständig oder im CoRe integriert sein.

\subsubsection{Einschränkungen}
\label{section:konzeption:bedienung:generierung:einschraenkungen}

% nachteile

Die vorgestellte Lösung hat auch Nachteile. Zunächst ist sie vom Document Object Model (DOM) abhängig, was eine automatische Hilfegenerierung für Komponenten ausschließt, die auf Flash, Silverlight oder ähnlichen Technologien basieren. Der Trend geht aber ohnehin zu HTML/SVG-basierten Visualisierungen (z.\,B. mit D3 \cite{Bostock2011} oder Raphaël\footnote{\url{http://raphaeljs.com/}}): Flash ist laut Adobe hauptsächlich für Videoauslieferung und Spiele gedacht \cite{Adobe2013} und Microsoft zieht HTML5 Silverlight vor \cite{Foley2010}. Deswegen sollte dieser Nachteil nicht ins Gewicht fallen.

Eine weitere Einschränkung ist, dass zeitabhängige Interaktionen wie zum Beispiel \enquote{MouseOver für 3 Sekunden} nicht modelliert werden können. Diese sind im Web aber ohnehin eher unüblich und werden als schlechte Usability betrachtet, weil sie nicht sichtbar und deswegen schwer zu entdecken sind.

\subsection{User Interface und Interaktion}
\label{section:konzeption:bedienung:ui}

% ### assistance anbieten

Die Hilfestellung zur Bedienung kann über einen ?-Button in der Titelleiste aufgerufen werden, den der Benutzer vielleicht von nativen Desktop-Applikationen kennt (Abbildung~\ref{figure:bedienung-step1}). Der Viewport der Komponente wird abgedunkelt und nur die Elemente, für die auch Hilfestellungen existieren, bleiben sichtbar. Neben der Komponente erscheint eine Sidebar, welche die verfügbaren Aktionen noch einmal auflistet. Die Assistance wird entweder nach einem Klick auf ein sichtbares UI Element oder ein Element der Liste aufgerufen. So kann der Benutzer sowohl die Frage \enquote{Was macht dieser Button?} als auch \enquote{Wie kann ich Aktion XY ausführen?} beantworten. Eine zweite Möglichkeit, wie die Assistance aufgerufen werden kann, ist über einen ?-Button am Interaktionselement selbst (Abschnitt~\ref{section:konzeption:verlinkung}).

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/konzeption-bedienung-step1.png}
   \caption{UI Mockup: Bedienung (Schritt~1)}
   \label{figure:bedienung-step1}
\end{figure}

Danach wird die kürzeste Operationsfolge für die ausgewählte Aktion erklärt. Es werden schrittweise mindestens drei Panels in der Komponente angezeigt (Abbildung~\ref{figure:bedienung-step2}). Der Inhalt der Panels ist in Abbildung~\ref{figure:bedienung-comic} zu sehen. Das erste Panel startet mit der ganzen Komponente, zoomt dann aber auf das erste relevante UI Element. Panel~2 startet wiederum mit dem Inhalt von Panel~1, überblendet dann aber eine notwendige Operation. Das dritte Panel startet mit dem Inhalt aus Panel~1, zoomt aber auf eine Gesamtansicht wie anfangs hinaus, sodass der Benutzer den Unterschied sehen kann. Sollte eine Aktion aus mehreren zusammenhängenden Operationen bestehen (sequentielle VISO Operation), wiederholen sich die Panels~1 und~2 dementsprechend. Falls mehrere gleichwertige Operationen (parallele VISO Operation) eine Aktion ausführen, so können die Panels~1 und~2 gescrollt werden.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/konzeption-bedienung-step2.png}
   \caption{UI Mockup: Bedienung (Schritt~2)}
   \label{figure:bedienung-step2}
\end{figure}

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.75\textwidth]{images/konzeption-bedienung-comic.png}
   \caption{UI Mockup: Comic}
   \label{figure:bedienung-comic}
\end{figure}

Die Panels haben eine festgelegte Mindestgröße, um lesbar zu bleiben. Heer et al. \cite{Heer2008} verwenden in ihrer History, die ebenfalls Screenshots enthält, eine Seitenlänge von 120~Pixel. Falls die Komponente nicht breit genug sein sollte, um die nötige Anzahl von 120~Pixel großen Panels in einer Zeile anzuzeigen, wird die Bedienungshilfe in einem Fenster angezeigt. So können unterschiedliche, alternative Operationen immer gescrollt werden.

Die Texte in den Panels werden zur Laufzeit hinzugefügt, da so beispielsweise auf die Sprache des Nutzers reagiert werden kann. Ansonsten müsste der Hilfeservice für jede unterstützte Sprache ein eigenes Bild erzeugen. Die dafür notwendigen Informationen sind:

\begin{itemize}
	\item Panel~1: Welche Elemente beteiligt sind.
	\item Panel~2: Name der Operation.
	\item Panel~3: Name der Aktion.
\end{itemize}

Diese werden aber schon im Schritt davor (Abbildung~\ref{figure:bedienung-step2}) benötigt, müssen also sowieso bekannt sein.

\section{Feedback zu einer Komponente}
\label{section:konzeption:feedback}

Wie bei jeder Software können bei den Komponenten in VizBoard Fehler auftreten. Externe APIs, die sie benutzen, wie zum Beispiel von Facebook oder Twitter können sich ändern. Visualisierte Daten können Fehler in der Komponente verursachen, beispielsweise durch nicht überprüfte \texttt{null} Werte oder wenn sie ein unerwartetes Format haben. Ebenso ist es möglich, dass VizBoard selbst Bugs enthält. Schlimmstenfalls fallen diese Fehler erst dem Endnutzer auf, welcher sie dann melden können soll.

Für diejenigen, die sich mit dem Bug Report befassen müssen -- also Komponentenentwickler bzw. VizBoard-Betreiber -- sind möglichst genaue Angaben sehr wichtig. Welcher Browser wurde benutzt? Welche Version? Welches Betriebssystem? Was genau hat nicht funktioniert? Ist der Fehler reproduzierbar? Wenn ja, wie? Diese und andere Fragen müssen beantwortet werden, um letzten Endes die Fehlerquelle zu finden. Liegt es an der Komponente (z.\,B. wegen veralteten API Anfragen), an VizBoard (z.\,B. ein Bug im Event Broker) oder keinen der beiden (z.\,B. fehlerhafte Daten von der externen API)? Aus Sicht des Endnutzers \enquote{funktioniert es nicht}, da er keine Kenntnisse der Programmierung besitzt und deswegen keine sinnvollen Hypothesen aufstellen, überprüfen und Schlußfolgerungen ziehen kann. Deswegen sollte der Endnutzer einen möglichst ausführlichen Text verfassen, um das Problem zu beschreiben, und die Möglichkeit haben, die Komponente prinzipiell als gut oder schlecht zu bewerten. Letztere Funktion existiert bereits in VizBoard und wird in die Feedback UI integriert. Die anderen Informationen, wie eben beispielsweise die Browserversion, sollten automatisch gesammelt und mitgeschickt werden.

\subsection{User Interface und Interaktion}
\label{section:konzeption:feedback:ui}

Der Nutzer klickt auf einen Button in der Titelleiste, beschreibt sein Problem und sendet ab (Abbildung~\ref{figure:feedback}). Optional kann er außerdem eine Bewertung abgeben \cite{Voigt2013b}.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/konzeption-reporting.png}
   \caption{UI Mockup: Feedback-Funktion}
   \label{figure:feedback}
\end{figure}

\subsection{Backend}
\label{section:konzeption:feedback:backend}

% was kann man über javascript vom browser auslesen?
Informationen über den Browser befinden sich im DOM Objekt \texttt{window.navigator} und beinhalten unter anderem:

\begin{itemize}
	\item User Agent String, welcher Betriebssystem, Browser und deren Versionen enthält
	\item Sprache des Browsers
	\item Ob Cookies aktiviert sind
	\item Installierte Plugins, wie Java oder Flash
\end{itemize}

% was kann man über den context service bekommen?
% woher weiß man überhaupt, was es gibt? --> domänenspezifisches kontextmodell, ist also festgelegt.

Diese und andere notwendige Informationen können mit Javascript einfach ausgelesen werden. Noch mehr Informationen über den Nutzungskontext können über den Context Service (Abschnitt~\ref{section:standderforschung:grundlagen:cruise_vizboard}) bezogen werden. Dieser beinhaltet u.\,a. den Ort oder das Geschlecht des Nutzers.

% noch sagen dass es denkbar wäre, das direkt an ein support system anzubinden

Das Feedback des Nutzers wird ans Rating Repository gesendet und gespeichert. Die gesammelten Informationen aus dem Context Service über Nutzer, Browser und Anwendungskontext werden im RaRe referenziert. Das RaRe könnte aus der vom Nutzer abgegebenen Bewertung und Textklassifikation \cite{Sebastiani2002} in \enquote{positiv} oder \enquote{negativ} bestimmen, ob ein Ticket in einem Support System (wie z.\,B. OSTicket\footnote{\url{http://osticket.com/}}) des VizBoard-Betreibers erstellt werden soll. Die positiven Kommentare könnten beispielsweise für Testimonials auf der Startseite von VizBoard verwendet werden.

\section{Kommunikation zwischen Komponenten}
\label{section:konzeption:kommunikation}

Im kompositen Infomationsvisualisierungssystem VizBoard kommunizieren Komponenten miteinander, indem sie Nachrichten austauschen (Abschnitt~\ref{section:standderforschung:grundlagen:cruise_vizboard:kommunikationsmodell}). Dieser Vorgang ist für den Benutzer nicht sichtbar und kann für Verwirrung sorgen, wenn andere Komponenten auf Interaktionen reagieren, die dort nicht getätigt wurden. Dem wird beigekommen, indem 

\begin{enumerate}
	\item die Kommunikation zwischen Komponenten sichtbar gemacht wird und
	\item die Abhängigkeiten zwischen Komponenten wie bei der Bedienung (Abschnitt~\ref{section:konzeption:bedienung}) mit Comics erklärt werden.
\end{enumerate}

\subsection{User Interface und Interaktion}
\label{section:konzeption:kommunikation:ui}

Wie im vorigen Abschnitt erläutert, wird zuerst der Nachrichtenaustausch zwischen Komponenten sichtbar gemacht (Abbildung~\ref{figure:kommunikation-step1}). Dazu wird ein Pfeil vom Sender der Nachricht zum Empfänger animiert und gezeichnet, der in der Mitte ein Fragezeichen enthält. Das Fragezeichen wurde gewählt, da es konsistent mit dem Rest der Hilfe ist und ein Brief in der Nutzerstudie Assoziationen mit \enquote{Email} oder \enquote{in sozialen Netzwerken teilen} weckte. Sollten mehrere Empfänger vorhanden sein, existiert für jeden davon ein Fragezeichen. Die Kommunikationshilfe wird gleichzeitig mit der Bedienungshilfe (Abschnitt~\ref{section:konzeption:bedienung}) aufgerufen, solange wenig genug Komponenten im Mashup vorhanden sind (Abschnitt~\ref{section:konzeption:einfuehrung:nutzerstudie}). Ansonsten wird zusätzlich bei jeder Nachricht ein entsprechender Pfeil eingeblendet und nach kurzer Zeit (ca. 200--500~ms) wieder ausgeblendet.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/konzeption-kommunikation-step1.png}
   \caption{UI Mockup: Kommunikationshilfe}
   \label{figure:kommunikation-step1}
\end{figure}

Wenn eine Akion ausgewählt wird, wird die Anzahl der gezeigten Pfeile entsprechend eingegrenzt (Abbildung~\ref{figure:kommunikation-step2}).

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/konzeption-kommunikation-step2.png}
   \caption{UI Mockup: Kommunikationshilfe mit eingeschränkten Optionen}
   \label{figure:kommunikation-step2}
\end{figure}

Die Abhängigkeiten zwischen den beiden Komponenten werden erklärt, nachdem auf das Fragezeichen geklickt wurde (Abbildung~\ref{figure:kommunikation-step3}). Ein Fenster wird geöffnet, welches fast den gleichen Comic wie in Abschnitt~\ref{section:konzeption:bedienung} enthält. Der einzige Unterschied ist, dass anstatt einer VISO Operation eine VISO Aktion genannt wird. Auf diese Weise wird die Frage beantwortet, wie sich die angezeigten Komponenten beeinflussen und was Aktionen in anderen Komponenten bewirken.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/konzeption-kommunikation-step3.png}
   \caption{UI Mockup: Comic erklärt Kommunikation. Verändern des Kartenausschnittes (Akßtion: Panning, Operation: Drag) bewirkt ein Update im Balkendiagramm.}
   \label{figure:kommunikation-step3}
\end{figure}

\subsection{Backend}
\label{section:konzeption:kommunikation:backend}

Die Kommunikation zwischen Komponenten kann über den Event Broker (Abschnitt~\ref{section:standderforschung:grundlagen:cruise_vizboard}) nachvollzogen werden, da dieser zentraler Austauschpunkt für Nachrichten ist. Das Hilfesystem zeichnet Pfeile, wenn es vom Event Broker über Nachrichten informiert wird und die dynamische Kommunikationshilfe aktiviert ist.

Für die Generierung des Comics muss das Konzept der User Assistance für Bedienung (Abschnitt~\ref{section:konzeption:bedienung:api}) nur leicht erweitert werden. Da Komponenten mit Operationen auf Nachrichten reagieren (Abschnitt~\ref{section:standderforschung:grundlagen:cruise_vizboard:kommunikationsmodell}), muss für das Ergebnis einer Operation ebenfalls ein Screenshot erstellt werden. Diese sind jetzt schon in der Komponentenbeschreibung vorhanden und können während der Panel-Generierung einfach ausgeführt werden. Sollten die Operationen Parameter erwarten, muss der Komponentenentwickler Beispieldaten in die Komponentenbeschreibung einfügen.

Zu beachten ist allerdings, dass es Operationen geben kann, welche das User Interface der Komponente nicht verändern. Das Konzept der Hilfestellung mit Comics fußt darauf, dass ein sichtbarer Unterschied zwischen den Zuständen vor und nach einer Interaktion bzw. Operation besteht. Ist jener nicht vorhanden, ergibt der Comic keinen Sinn mehr. Deswegen muss dem Komponentenentwickler eine Möglichkeit gegeben werden, Operationen zu identifizieren, für die keine Hilfe generiert werden soll. Das kann am einfachsten durch ein optionales Attribut in der Komponentenbeschreibung umgesetzt werden.

\section{Verlinkung von unbekannten Konzepten}
\label{section:konzeption:verlinkung}

% einführung - warum brauchen wir verlinkung?

Ein Punkt, der in den verwandten Arbeiten (Abschnitt~\ref{section:standderforschung:verwandte_arbeiten}) kaum behandelt wurde, ist dass der Benutzer mehr Informationen über die visualisierten Daten benötigen könnte. Er könnte auf vollständig (\enquote{Was ist ein Säurezeiger\footnote{Eine Pflanze, die nur auf Böden mit einem bestimmten ph-Wert wachsen kann.}?}) oder teilweise (\enquote{Wie ist das BIP definiert\footnote{Der Gesamtwert aller Waren und Dienstleistungen, die innerhalb eines Jahres in einer Volkswirtschaft hergestellt wurden und dem Endverbrauch dienen.}?}) unbekannte Begriffe treffen. Um das Verständnis der Daten zu fördern, müssen diese erklärt werden, weswegen sie mit einer externen Wissensbasis verlinkt sein sollen. Zu erklärende Begriffe werden vermutlich hauptsächlich in Legenden von Visualisierungen zu finden sein, können aber auch in Freitexten oder in Interaktionselementen vorkommen.

\subsection{Markup und Backend}
\label{section:konzeption:verlinkung:backend}

Um zu erklärende Begriffe für das Hilfesystem auffindbar zu machen, zeichnet der Komponentenentwickler sie mit einem dafür vorgesehenen Datenattribut aus: Eines für Legenden, eines für Freitext. Diese können entweder in der Komponentenbeschreibung angegeben und so selbst gewählt werden, oder sie werden vom Vizboard-Betreiber festgelegt. Hier wird die letzte Variante umgesetzt, weil sie dem Komponentenentwickler etwas Aufwand erspart und \enquote{Kollisionen} mit bereits vorhandenen Klassen erstens unwahrscheinlich sind und zweitens einfach behoben werden können (beispielsweise mit dem Präfix \texttt{my-}). Der zu erklärende Begriff ist dann der Textinhalt des Tags mit der entsprechenden Klasse. Bei Interaktionselementen sind die CSS Selektoren für die Bedienungshilfe (Abschnitt~\ref{section:konzeption:bedienung}) schon vorhanden und das Konzept wird in Form einer URI in die Komponentenbeschreibung eingefügt.

Auf diese Weise können die erklärungsbedürftigen Konzepte über CSS Selektoren gefunden werden. Allerdings stellt sich die Frage, wie das Hilfesystem die Beschreibung lesen kann. Die Konzepte sind im Falle von Freitext dynamisch, bei Legenden statisch, aber abhängig vom Datensatz und bei Interaktionselementen statisch in Abhängigkeit der Komponente. Es erscheint sinnvoll eine einheitliche Zugriffsschicht für Konzeptbeschreibungen zu etablieren. Dabei bietet sich im Fall von VizBoard das DaRe an, welches als einheitliche Zugriffsschicht auf Daten konzipiert ist. Bei anderen auf CRUISe aufbauenden Mashups sollte das CoRe diese Funktion übernehmen.

Das DaRe findet das Domain Assignment eigenständig, nachdem ein Datensatz hochgeladen wurde. Danach sollte eine Beschreibung aus der externen Wissensbasis abgerufen und gespeichert werden. Das hat den Nachteil, dass die Informationen zum Zeitpunkt der Anzeige möglicherweise nicht mehr aktuell sind. Da sich aber Beschreibungen zu Konzepten wie \enquote{logarithmische Skala} kaum ändern sollten und als Beispiel die DBpedia nur ein- bis zweimal pro Jahr ein Update bekommt\footnote{\url{http://blog.dbpedia.org/category/dataset-releases/} zeigt ein bis zwei Artikel im Jahr, abgerufen am 01.07.2013.}, sollte das kein Problem sein. Im Gegenzug ist das Hilfesystem unabhängig von der DBpedia verfügbar und schneller, da im Vergleich zum dynamischen Abruf der Beschreibung ein Network Round Trip eingespart wird.

Im Fall von Interaktionselementen parst das CoRe die Komponentenbeschreibung, nachdem eine Komponente hochgeladen wurde. Dabei extrahiert es die notwendigen Konzepte und schickt diese ans DaRe, welches die Beschreibungen dazu abruft und speichert.

\subsection{User Interface und Interaktion}

Bei Legenden und Freitext wird hinter die entsprechend markierten DOM Elemente (siehe Abschnitt~\ref{section:konzeption:verlinkung:backend}) ein Fragezeichen eingefügt, um eine Interaktionsmöglichkeit anzudeuten. Dieses kann angeklickt werden, woraufhin eine Sidebar mit einer kurzen Erklärung des Konzepts angezeigt wird (Abbildung~\ref{figure:verlinkung}), bei Interaktionselementen wird zusätzlich die Bedienungshilfe (Abschnitt~\ref{section:konzeption:bedienung}) angezeigt. Die Sidebar enthält auch einen Link, der zu einer Erklärung in einer externen Wissensbasis führt. Zur Erklärung des Konzepts gehört auf jeden Fall eine kurze Beschreibung, wie sie im ersten Absatz von Wikipedia-Artikeln gegeben ist und idealerweise ein Bild, falls vorhanden. Ist keine Beschreibung in der Sprache des Benutzers vorhanden, wird sie auf englisch angezeigt.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/konzeption-verlinkung.png}
   \caption{UI Mockup: Verlinkung von Legenden}
   \label{figure:verlinkung}
\end{figure}

Im Fall von Interaktionselementen wird bei \texttt{MouseOver} derselbe Hilfebutton eingeblendet (Abbildung~\ref{figure:verlinkung-bedienung}). Das hat den Grund, dass unbekannt ist, wie die Elemente angeordnet sind. Eine ständige Anzeige des Hilfebuttons könnte andere Elemente verdecken. Nachdem der Benutzer den Button gedrückt hat, werden falls vorhanden sowohl die Bedienungshilfe (Abschnitt~\ref{section:konzeption:bedienung}) als auch die ausgehende Kommunikation (Abschnitt~\ref{section:konzeption:kommunikation}) bei der betreffenden Aktion eingeblendet.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/konzeption-verlinkung-bedienung.png}
   \caption{UI Mockup: Verlinkung von Interaktionselementen}
   \label{figure:verlinkung-bedienung}
\end{figure}

Zwar wäre es wünschenswert, sowohl Legenden und Freitext als auch Interaktionselemente mit derselben UI kennzeichnen zu können. Das ist leider nicht ohne weiteres möglich. Würden Legenden und Freitext die UI der Interaktionselemente verwenden, wäre die Hilfefunktion nicht sichtbar. Wäre es andersherum, müsste der DOM auf nicht-triviale Weise manipuliert werden (Einfügen von eigenen Elternknoten usw.), was unerwünschte Auswirkungen auf CSS Selektoren des Entwicklers haben könnte.

\section{Kommentare in Visualisierungen}
\label{section:konzeption:kommentare}

% allgemeines zu kommentaren. woraus bestehen sie, was müssen sie können.

Kommentare waren in den verwandten Arbeiten (Abschnitt~\ref{section:standderforschung:verwandte_arbeiten}) eine populäre Variante, um das Verständnis der Daten zu fördern. Mit Hilfe von Kommentaren können Endnutzer andere auf beobachtete Fakten der Daten wie Ausreisser oder Trends hinweisen und so zum Verständnis beitragen. Der Begriff \enquote{Kommentartext} referenziert hier den Text, welcher von Benutzern geschrieben wird, und \enquote{Annotation} die Markierung in der Visualisierung. Ein \enquote{Kommentar} ist die Kombination aus beliebigen Annotationen und einem Kommentartext.

% wie können kommentare umgesetzt werden? dev vs us! warum machen wir es so wie geplant?

Prinzipiell gibt es zwei Varianten, wie Kommentare in einer InfoVis-Komponente umgesetzt werden können. In der ersten kümmert sich die Komponente darum, wie und wann sie Kommentare lädt und anzeigt. Der Vorteil daran ist, dass die Handhabung von Kommentaren speziell auf jede Komponente angepasst wird. Allerdings kann so kein \emph{einheitliches} Look \& Feel gewährleistet werden. Zwar könnten Designrichtlinien Aussehen und Interaktionen vorschreiben, sie sind aber zwecklos wenn der Komponentenentwickler sie nicht einhält. Außerdem erhöht diese Variante den Entwicklungsaufwand der Komponente stark (\emph{Minimalität}).

In der zweiten Variante ist es Aufgabe des Hilfesystems, Kommentare zu verwalten und anzuzeigen. Die vorhin genannten Nachteile werden hier zu Vorteilen: Einheitliches Look \& Feel wird sichergestellt und der Komponentenentwickler hat keinen zusätzlichen Entwicklungsaufwand. Allerdings hat das Hilfesystem auf Grund des \enquote{Black Box} Prinzips keinen Zugriff auf die in der Komponente verwendeten Daten. Aus demselben Grund kommt hinzu, dass das User Interface für Kommentare sich verschiedenen Interaktionen der Komponente wie z.\,B. scrollen, Tab wechseln, zoomen etc. anpassen muss, ohne darüber informiert zu werden. Im folgenden wird erläutert, wie diese Nachteile umgangen werden können.

\subsection{Features}
\label{section:konzeption:kommentare:features}

% ### funktionen eines kommentars

In diesem Abschnitt wird diskutiert, welche Funktionen das Kommentarsystem zur Verfügung stellen soll.

\subsubsection{URL einfügen}

Es ist wahrscheinlich, dass Benutzer zur Erklärung der Daten bzw. Visualisierung auf externe Quellen verweisen müssen. Da VizBoard ohnehin webbasiert ist, eignen sich Links in Form von URLs dafür sehr gut.

\subsubsection{Kommentar referenzieren}

Um Diskussionen und Konversationen zur Visualisierung zu fördern, müssen Kommentare einander referenzieren können \cite{Heer2007}. So wird es Benutzern erleichtert, zusammen eine Erklärung für Ausreisser oder Trends zu finden. 

\subsubsection{Voting}

Erfahrungsgemäß tragen nicht alle Kommentare gleich viel zur Diskussion bei. Man denke dabei an Hinweise auf Tippfehler oder das berüchtigte \enquote{Erster!}. Deswegen ist es notwendig, dass Benutzer Kommentare anderer bewerten können.

\subsubsection{Ranking}

Da Diskussionen und Konversationen nicht durch das User Interface eingeschränkt werden sollen, ist es nötig, Kommentare nach Datum sortieren zu können. So kann der Gesprächsverlauf nachvollzogen werden. Wenn Benutzer aber nicht an der Konversation teilnehmen, sondern schnell eine Antwort auf ihre Fragen haben wollen, bietet es sich an, nach Bewertung sortieren zu können.

\subsubsection{Kommentar editieren}

Den eigenen Kommentar editieren zu können, ist aus verschiedenen Gründen wichtig, z.\,B. wenn der Benutzer Tippfehler ausbessern oder ein paar Absätze zur Lesbarkeit einfügen will. Wichtig ist für andere, dass dies transparent geschieht und die Diskussion nachvollziehbar bleibt. Es gibt verschiedene Lösungsmöglichkeiten:

\begin{itemize}
	\item Der Kommentar kann nicht editiert werden. So bleibt alles perfekt nachvollziehbar, aber der Benutzer kann nichts ausbessern.
	\item Der Kommentar kann nur für $x$ Minuten editiert werden, danach ist er gesperrt. Diese Variante erlaubt immerhin noch Tippfehler auszubessern, aber der Benutzer kann beispielsweise nicht nach einer Stunde eine Quelle einfügen.
	\item Der Kommentar kann beliebig editiert werden. Diese Variante ist aus Nutzersicht am Besten, aber sie muss anderen gegenüber transparent gemacht werden. Es muss sichtbar sein, dass ein Kommentar editiert wurde und wann. Im Idealfall würde auch die Originalversion eines referenzierten Kommentars mit abgespeichert, sodass diese später eingeblendet werden kann.
\end{itemize}

\subsubsection{Kommentar löschen}

Gründe, um einen Kommentar zu löschen, beinhalten unter anderem Beschimpfungen oder mangelnde Aktualität, etwa wenn eine zitierte Studie widerlegt wurde. Wie beim Editieren von Kommentaren ist es hier notwendig, dass der Gesprächsverlauf nachvollziehbar bleibt. Die Lösungsansätze beinhalten:

\begin{itemize}
	\item Kommentare können nicht gelöscht werden. Das könnte Benutzer davon abhalten, Kommentare zu schreiben, was auch nicht Sinn der Sache ist.
	\item Kommentare können gelöscht werden, solange keine Referenz darauf besteht. So kann ein Diskussionsverlauf konsistent bleiben, allerdings ist dieser Weg aus Nutzersicht schwer verständlich.
	\item Kommentare können beliebig gelöscht werden. Diese Variante weckt keine Bedenken, den eigenen Kommentar nicht mehr löschen zu können. Es muss aber etwas mit den Referenzen auf gelöschte Kommentare geschehen, da ansonsten die Nachvollziehbarkeit der Diskussion leidet. Beispielsweise könnte die referenzierte Originalversion abgespeichert und eingeblendet werden.
\end{itemize}

\subsubsection{Visualisierung annotieren}

Um eine gemeinsame Grundlage für eine Diskussion zu schaffen ist es notwendig, Bereiche der Visualisierung markieren zu können, über die man in einem Kommentar spricht. Diese Bereiche können entweder Flächen, die Datenpunkte enthalten oder nicht (Bereichskommentare), oder Datenpunkte selbst sein (Punktkommentare, Abbildung~\ref{figure:datenbereiche}).

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/konzeption-datenbereiche.png}
   \caption{Ein Scatterplot mit eingezeichneten Annotationsmöglichkeiten: Leere Bereiche (A), nicht-leere Bereiche (B) und einzelne Datenpunkte (C).}
   \label{figure:datenbereiche}
\end{figure}

\subsection{API und Komponentenbeschreibung}
\label{section:konzeption:kommentare:api}

% konkreter. was gibt es für kommentare, wie unterscheiden sie sich, was ergeben sich für anforderungen daraus --> keine dynamischen daten, kein unvorhersehbares layout, keine aggregation, memento definieren, 

Um \emph{Wiederverwendbarkeit} über Komponenten hinweg zu fördern, sollten Kommentare sich möglichst auf die visualisierten Daten selbst beziehen (datenbezogene Kommentare) und nicht auf einen Bereich der Visualisierung (ortsbezogene Kommentare).

Komponenten, welche die Kommentarfunktion anbieten wollen, dürfen aus zwei Gründen keine externen Daten anzeigen (also beispielsweise die neuesten Tweets eines Twitter-Accounts): Erstens könnte der Kontext eines Kommentars sich ändern, etwa wenn Tweets gelöscht wurden. Die externen Daten unterliegen nicht der Kontrolle des Hilfesystems. Zweitens sind die externen Daten nicht im DaRe vorhanden, weswegen sie nicht über Komponenten hinweg wiederverwendet werden können. Dabei ist es unerheblich, ob die Komponente selbst externe Daten lädt oder externe Daten einer anderen Komponente anzeigt.

Um den Fall von eigenen externen Daten für das Hilfesystem beliebiger CRUISe Mashupts erkennbar zu machen, kann die Komponentenbeschreibung erweitert werden. Für den Fall von fremden externen Daten muss das Hilfesystem nach erfolgreicher Integration aller Visualisierungskomponenten selbst überprüfen, welche davon externe Daten laden und mit welchen diese über Links (Abschnitt~\ref{section:standderforschung:grundlagen:cruise_vizboard}) verbunden sind. Im Fall von VizBoard wird festgelegt, dass Daten nur aus dem DaRe kommen.

\subsubsection{Datenbezogene Bereichskommentare}

Damit Bereichskommentare Daten referenzieren können, müssen drei Voraussetzungen gegeben sein:

\begin{enumerate}
	\item Falls der Bereich leer ist, muss die grafische Repräsentation die Position als visuelles Mapping benutzen, damit eine Transformation zwischen kartesischen Koordinaten und Daten durchgeführt werden kann.
	\item In jedem Fall muss die Komponente eine Operation bereitstellen, welche kartesische Koordinaten $(x_1,y_1)$ in Datenbereiche (2000 \$, 14. Mai 1998) transformiert sowie deren Umkehrung. Komponenten sind \enquote{Black Boxes} und es kann deswegen keine Annahme über die verwendete Skala (linear oder logarithmisch) oder andere Interna getroffen werden. Aus diesem Grund ist es nicht möglich, aus Auswahlkoordinaten $(x_1,y_1,x_2,y_2)$ direkt auf Daten zu schließen.
	\item Die verwendeten Daten müssen im Data Repository gespeichert sein, da ansonsten keine Daten referenziert werden können. Aus diesem Grund darf weder die Komponente selbst Datenverarbeitung in Form von Aggregationen o.\,ä. durchführen, noch dürfen die Daten selbst bereits aggregiert in der Komponente ankommen.
\end{enumerate}

Erfüllt eine Komponente diese Bedingungen nicht vollständig, können nur ortsbezogene Bereichskommentare eingesetzt werden. Wenn datenbezogene Bereichskommentare angezeigt und von anderen Benutzern nachvollzogen werden sollen, muss das Hilfesystem die Komponente in den damals aktiven Zustand zurücksetzen können, da ansonsten die referenzierten Bereiche andere Daten enthalten können. Diese Tatsache führt zu einer weiteren Anforderung an die Komponente:

\begin{enumerate}
	\setcounter{enumi}{3}
	\item Die Komponente muss der Laufzeitumgebung einen Weg zur Verfügung stellen, mit dem Zustände (wie z.\,B. Zentrum und Zoomlevel einer Karte) gespeichert und vollständig wiederhergestellt werden können.
\end{enumerate}

Diesbezüglich bietet sich ein Memento-Pattern \cite{Gamma1994} an:

\begin{quote}
Without violating encapsulation, capture and externalize an object's internal state allowing the object to be restored to this state later.
\end{quote} 

Um Mementos umzusetzen, wird auf propertys zurückgegriffen. Eine Komponente muss ihren Zustand als propertys öffentlich machen und zwar so, dass durch Ändern von propertys kein inkonsistenter Zustand erreicht werden kann. Sie definiert das Format ihres Mementos, also welche propertys es ausmachen, in der Komponentenbeschreibung. Das Hilfesystem kann dann über die Methoden \texttt{getProperty(p)} und \texttt{setProperty(p,v)}, welche schon in der API der Komponente vorhanden sind, das Memento abrufen bzw. wiederherstellen. Eventuell registrierte PropertyLinks (Abschnitt~\ref{section:standderforschung:grundlagen:cruise_vizboard}) würden aktiviert und andere Komponenten ebenfalls verändert. Nachdem Events für eine Komponente zurückgehalten werden müssen, da sich das User Interface sonst ändern könnte, während der Benutzer Kommentare liest, haben PropertyLinks keinen Effekt.

\subsubsection{Ortsbezogene Bereichskommentare}

Datenbezogene Kommentare haben den Vorteil, dass sie auch in anderen Komponenten als der ursprünglich benutzten angezeigt werden können. Sie haben die Form eines Rechtecks, da so der Implementierungsaufwand für den Komponentenentwickler minimiert wird, obwohl prinzipiell beliebige geometrische Formen möglich sind. Andere Formen von Kommentaren sind zum Beispiel Pfeile oder Text, welche in der Nutzerstudie von \cite{Heer2007} am populärsten waren. Diese werden am besten als ortsbezogene Kommentare modelliert, da bei beiden Formen nicht eindeutig ist, welche Daten sie referenzieren. Siehe das Beispiel in Abbildung~\ref{figure:ortsbezogen}: Bezieht sich der Pfeil auf den Pixel am Ende der Pfeilspitze oder auf den roten Balken? Welche Daten soll der Text referenzieren?

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/konzeption-ortsbezogen.png}
   \caption{Ein ortsbezogener Kommentar mit Pfeil und Text}
   \label{figure:ortsbezogen}
\end{figure}

\subsubsection{Punktkommentare}

% speichern

Mit Datenpunkten verhält sich die Situation etwas einfacher als bei Bereichen. Es kann davon ausgegangen werden, dass Datenpunkte und deren DOM Elemente in einer $1:1$ (z.\,B. Balkendiagramm) oder $1:n$ (z.\,B. Scatterplot-Matrix) Relation stehen, da die Komponente sonst aggregieren würde. Im vorigen Abschnitt wurde für datenbezogene Kommentare ausgeschlossen, dass Komponenten Datenverarbeitung durchführen. Wenn der Komponentenentwickler im Markup der Komponente sichtbar machen würde, zu welchem Datenpunkt ein Element gehört, könnte das Hilfesystem mit Hilfe von CSS Selektoren diese finden und beispielsweise auswählbar machen, wenn ein Kommentar verfasst werden soll. Wird der Kommentar abgeschickt, muss die Komponente dem Hilfesystem zuerst mitteilen, welche Werte die visualisierten Attribute eines Datenpunkts haben. Das kann nicht automatisch aus dem DOM Element berechnet werden, weil der Maßstab unbekannt ist: Entspricht eine Fläche von $100\times100$~Pixel in der Treemap 10~Quadratmetern oder 1000~Hektar? Der Maßstab kann auch nicht in der Komponentenbeschreibung angegeben werden, weil von der Größe der Komponente abhängig ist. Bei einer Breite von 500~Pixel wäre er z.\,B. $1:100$, bei 250~Pixel Breite aber schon $1:200$. Die URI des Datenpunkts sowie die Werte der Attribute werden im Kommentar gespeichert, sodass sie in anderen Visualisierungen wiederverwendet werden können.

% markup

Zuvor muss allerdings noch geklärt werden, auf welche Weise der Komponentenentwickler die URIs im Markup sichtbar machen soll. Prinzipiell kommen dafür alle Möglichkeiten in Frage, die mit Hilfe von CSS Selektoren gefunden werden können. Dazu gehören HTML Markup Elemente wie \texttt{id} oder Datenattribute \texttt{data-*}, aber auch Microformats\footnote{\url{http://microformats.org/}} oder RDFa \cite{W3C2012}. Microformats werden ausgeschlossen, da bei diesen das Vokabular vorgegeben ist, während bei RDFa nur die Syntax definiert wird. Eine URI ist kein gültiger Wert für die \texttt{id} eines DOM Elements, deswegen wird auch sie ausgeschlossen. RDFa hat gegenüber Datenattributen den Vorteil, dass so auch zusätzliche Informationen über den Datenpunkt (beispielsweise das Label) ins Markup integriert werden können. Auf diese Weise kann das Hilfesystem unter Umständen den einen oder anderen Aufruf des DaRes einsparen und stattdessen HTML parsen, was zur Geschwindigkeit der Anwendung beiträgt.

% laden
Beim Laden von Punktkommentaren zählt das Hilfesystem erst die Anzahl von Kommentaren pro Datenpunkt und stellt diese Anzahl über dem visualisierten Datenpunkt dar. Das ist möglich, weil über die URI in Kombination mit CSS Selektoren die entsprechenden DOM Elemente identifiziert werden können.


\subsection{User Interface und Interaktion}
\label{section:konzeption:kommentare:ui}

% ### user interface & interaktion

In der Titelleiste gibt es zwei Buttons mit einem Sprechblasen-Icon, einmal ist eine Zahl darin (Kommentare ansehen) und einmal ein Pluszeichen (Kommentar hinzufügen). Eine ständig sichtbare textuelle Beschreibung wäre offensichtlicher, kann aber aufgrund des geringen Platzangebots nur mit einem Tooltip umgesetzt werden.

Wenn der Benutzer einen Kommentar verfassen will, erscheint eine Sidebar mit einer Textbox, Controls um die Annotationsform zu ändern (Auswahl, Rechteck, Pfeil, Text) und einem Button zum Bestätigen (Abbildung~\ref{figure:kommentare-step4}). Der Benutzer kann nun ein oder mehrere Rechtecke in der Visualisierung oder Datenpunkte markieren (linker Balken in Abbildung~\ref{figure:kommentare-step4}). Das Hilfesystem setzt die Komponente in den Ausgangszustand zurück, sobald der Benutzer bestätigt oder abgebrochen hat.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.75\textwidth]{images/konzeption-kommentare-step4.png}
   \caption{UI Mockup: Kommentar hinzufügen}
   \label{figure:kommentare-step4}
\end{figure}

Möchte der Benutzer Kommentare anderer lesen, wechselt der Inhalt der Sidebar zu einer Liste aller zu diesen Daten verfassten Kommentare (Abbildung~\ref{figure:kommentare-step2}). Ein Kommentar zeigt folgende Elemente.

\begin{itemize}
	\item Linke Spalte
	\begin{itemize}
		\item ID des Kommentars: Diese ist zur Referenzierung notwendig.
		\item Avatar des Benutzers und Benutzername: Diese sollen das Vertrauen der Benutzer untereinander erhöhen und so die Qualität der Kommentare verbessern \cite{Chiu2006}. Gespeichert und abgerufen werden sie im UserService von CRUISe.
		\item Datum der Erstellung oder letzten Editierung, was jünger ist. Wurde editiert, ist das Datum kursiv geschrieben.
		\item Editieren/Löschen-Buttons, falls der Kommentar selbst verfasst wurde.
		\item Antworten: Eine zweite Möglichkeit als die ID des Kommentars einzutippen. Die UI wechselt zu \enquote{Kommentar verfassen} und inkludiert die ID des betreffenden Kommentars.
		\item Annotationen anzeigen: Zeigt die Annotationen des Kommentars in der Visualisierung.
		\item Voting: Ein Benutzer kann einen fremden Kommentar genau einmal bewerten. Die Anzahl der Stimmen wird ebenfalls angezeigt. Anstatt \enquote{upvote/downvote} wird hier die Wortkombination \enquote{agree/disagree} verwendet, da bei der Nutzerstudie ersteres selten mit \enquote{bewerten} und manchmal mit \enquote{scrollen} assoziiert wurde.
	\end{itemize}
	\item Rechte Spalte
	\begin{itemize}
		\item Kommentartext mit Referenzen (durch \texttt{\#hash} gekennzeichnet) und URLs (unterstrichen).
	\end{itemize}
\end{itemize}

Referenzen auf andere Kommentare können angeklickt werden. Dann wird der gewählte Kommentar in der Sidebar angezeigt und die Titelleiste enthält einen Zurück-Button, mit dem der vorherige Zustand wiederhergestellt werden kann.

Die Datenpunkte in der Visualisierung werden mit einer Anzeige, wie viele Kommentare dazu vorhanden sind, erweitert (Abbildung~\ref{figure:kommentare-step2}). Sie sind oben rechts platziert, um so an iOS Badges zu erinnern und damit Assoziationen zu einem Hinweis zu wecken.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.75\textwidth]{images/konzeption-kommentare-step2.png}
   \caption{UI Mockup: Anzeige aller Kommentare}
   \label{figure:kommentare-step2}
\end{figure}

Diese Badges können angeklickt werden. Die Sidebar enthält dann alle Kommentare, die sich auf den gewählten Datenpunkt beziehen (Abbildung~\ref{figure:kommentare-step3c}).

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.75\textwidth]{images/konzeption-kommentare-step3c.png}
   \caption{UI Mockup: Alle Kommentare zum ausgewählten Datenpunkt}
   \label{figure:kommentare-step3c}
\end{figure}

Annotationen eines Kommentars müssen durch einen Klick auf den Button \enquote{show annotations} angezeigt werden. Der Viewport der Visualisierung wird dann abgedunkelt und nur die Annotationen des ausgewählten Kommentars bleiben sichtbar (Abbildung~\ref{figure:kommentare-step3a}).

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.75\textwidth]{images/konzeption-kommentare-step3a.png}
   \caption{UI Mockup: Ausgewählter Kommentar mit referenziertem Bereich und Datenpunkten}
   \label{figure:kommentare-step3a}
\end{figure}

\subsection{Backend}
\label{section:konzeption:kommentare:backend}

% ### backend

% welche daten enthält ein gespeichertes kommentar?

Den Ausführungen in den Abschnitten~\ref{section:konzeption:kommentare:features} und~\ref{section:konzeption:kommentare:api} nach enthält ein abgespeichertes Kommentar im DaRe folgende Daten:

\begin{itemize}
	\item ID des Kommentars, um darauf verweisen zu können.
	\item ID der Komponente, in der der Kommentar verfasst wurde. Das ist notwendig um ortsbezogene Kommentare wiederherstellen zu können. Bei datenbezogenen Kommentaren kann eventuell ein Verweis auf die ursprüngliche Komponente erstellt werden.
	\item ID des Datensatzes, der visualisiert wurde
	\item ID des Verfassers
	\item URIs der Datatype propertys, die visualisiert wurden
	\item Memento der Komponente zum Zeitpunkt des Kommentars
	\item \textit{Für jede Version des Kommentars}
	\begin{itemize}
		\item Versionsnummer
		\item Zeitpunkt
		\item Kommentartext
		\item \textit{Wenn ortsbezogene Elemente vorhanden}
		\begin{itemize}
			\item Für jedes Element (in relativen Einheiten)
			\begin{itemize}
				\item Wenn Pfeil: ($x_1,y_1,x_2,y_2$)
				\item Wenn Text: Text, $(x,y)$
				\item Wenn Rechteck: ($x_1,y_1,x_2,y_2$)
			\end{itemize}
		\end{itemize}
	\item \textit{Für jedes datenbezogene Element}
		\begin{itemize}
			\item Grenzwerte der visualisierten Datatype propertys. Ist ein Datatype Property nominalen Typs, besitzt also keine inhärente Ordnung (z.\,B. Länder), muss eine Menge von Datenpunkten angegeben werden.
		\end{itemize}
	\item \textit{Für jeden Datenpunkt}
		\begin{itemize}
			\item URI
			\item Werte der visualisierten Datatype propertys
		\end{itemize}
	\end{itemize}
\end{itemize}

% wie läuft das mit speichern?

Hat ein Benutzer Bereiche und Datenpunkte referenziert, sowie einen Kommentar geschrieben, sammelt das Hilfesystem die eben beschriebenen Daten der Komponente und sendet sie ans Data Repository. Das Speichern und Laden von Kommentaren liegt in dessen Verantwortung. 

% wie läuft das mit laden, vor allem wenn kommentare in anderer komponente gemacht wurden?

Sollen Kommentare angezeigt werden, schickt das Hilfesystem eine entsprechende Anfrage ans DaRe und empfängt die Daten aller relevanten Kommentare. Für ortsbezogene Bereichskommentare ist nichts weiter zu tun, sie können direkt in dieser Komponente gerendert werden. Um datenbezogene Bereichskommentare anzuzeigen, muss das Hilfesystem zuerst die Datengrenzen in Koordinaten in der Visualisierung transformieren lassen. Bei Punktkommentaren ist dies nicht nötig, weil das Hilfesystem über CSS Selektoren herausfinden kann, wo sie sich befinden sollen.

% event broker suspend/resume

Um zu gewährleisten, dass der Benutzer störungsfrei Kommentare lesen kann, muss das Hilfesystem den Event Broker (Abschnitt~\ref{section:standderforschung:grundlagen:cruise_vizboard}) veranlassen können, anfallende Events nicht weiterzuleiten (\enquote{suspend}) und in einer FIFO Warteschlange zwischenzulagern. Ansonsten könnte der Fall eintreten, dass die Komponente aktualisiert wird, während der Benutzer Kommentare zu den Daten liest oder eine andere Hilfe in Anspruch nimmt. Diese Funktion ist in Grundzügen bereits für das Handling von PropertyLinks vorhanden \cite[S. 161]{Pietschmann2012}. Nachdem die Kommentar UI geschlossen wurde, kann der Event Broker die gespeicherten Events weiterleiten (\enquote{resume}). Sie werden einfach in Reihenfolge weitergegeben. Das hat den Nachteil, dass sich das User Interface mehrmals schnell ändern könnte, bis alle pausierten Events abgearbeitet sind. Eine andere Möglichkeit wäre die Pausierungsfunktion auf Komponentenebene umzusetzen. Das würde allerdings Mehraufwand sowohl für den Komponentenentwickler, der die entsprechenden Methoden implementieren müste, als auch für das Hilfesystem, welches jede Komponente einzeln ansprechen muss, bedeuten.

\subsubsection{Weitere Nutzung}

% wie können kommentare noch genutzt werden?

Kommentare können auch Metainformationen über die Daten oder Komponente enthalten \cite{Chen2009}. Es wäre denkbar, mittels automatischer Textklassifikation \cite{Sebastiani2002} diese Kommentare zu identifizieren und als positiv oder negativ zu kategorisieren. Daraus ließe sich wiederum eine Bewertung für die Kombination (Datensatz, Komponente) berechnen\footnote{Am einfachsten ginge das indem bei Null gestartet wird und für jeden positiven Kommentar der Zähler um eins erhöht und für jeden Negativen um eins verringert wird.}. Der errechnete Wert könnte in Zukunft beim Ranking einer Komponente für einen ausgewählten Datensatz berücksichtigt werden. Wenn der Aufwand dafür gerechtfertigt werden kann, ist es auch möglich, eine zuvor definierte Ontologie aus Kommentaren zu extrahieren \cite{Alani2003}. Diese könnte zum Beispiel das Qualitätsmanagement von Komponenten automatisieren. Denkbar wäre, dass aus Kommentaren automatisch extrahiert wird, worüber sich die Benutzer beschweren. Ab einem Schwellwert kann dann der Komponentenentwickler informiert werden.

\section{History}
\label{section:konzeption:history}

% warum undo/redo?

In den verwandten Arbeiten (Abschnitt~\ref{section:standderforschung:verwandte_arbeiten}) wurde mehrmals empfohlen, dem Benutzer Undo/Redo von getätigten Aktionen zu ermöglichen. So können unerwünschte Ergebnisse einfach rückgängig gemacht werden. Heer et al. \cite{Heer2008} unterscheiden dabei zwei Modelle einer History: State und Action. Bei einer State History sind die Knoten Applikationszustände und die Kanten Aktionen, bei einer Action History ist es umgekehrt. Undo in einer Action History bedeutet in Reihenfolge inverse Aktionen auszuführen, in einer State History ist es die Wiederherstellung eines gespeicherten Zustands.

In diesem Abschnitt wird untersucht, wie in einem CRUISe Mashup, in dem die Komponenten lose gekoppelt sind, ein kompositionsübergreifendes Undo/Redo umgesetzt werden kann. Die Granularitätsstufe entspricht dabei Nutzerinteraktionen beziehungsweise zusammenhängenden anstatt einzelnen Events oder Operationen. Das sollte sich wie in den verwandten Arbeiten von Grammel \cite{Grammel2012} vorgeschlagen mit dem mentalen Modell des Benutzers decken, da für ihn Events und Operationen unsichtbar sind. Als Beispiel wird die Komposition in Abbildung~\ref{figure:dependency-graph-example} verwendet.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.75\textwidth]{images/konzeption-dependency-graph-example.png}
   \caption{Beispielhafte Komposition}
   \label{figure:dependency-graph-example}
\end{figure}

In Abschnitt~\ref{section:konzeption:kommentare:api} wurde ein Memento-Pattern für Komponenten eingeführt. Damit kann das Hilfesystem Zustände von Komponenten abrufen, speichern und wiederherstellen. Im Folgenden wird davon ausgegangen, dass diese Mementos ausreichen, um eine Komponente von einem konsistenten Zustand in einen anderen konsistenten Zustand zu überführen (und beispielsweise keine Operationen ausgeführt werden müssen). Das deckt sich mit dem Paradigma von CRUISe, wonach die Menge an propertys den Zustand einer Komponente vollständig beschreiben. Gegebenenfalls muss die Komponente selbst ihre Konsistenz überprüfen, beispielsweise wenn eine Liste von Flügen in einen späteren Zustand wiederhergestellt werden soll und einige inzwischen ausgebucht sind. Es stellt sich nun die Frage, wann die Mementos der Komponenten abgerufen werden sollen. Prinzipiell kann es vor oder nach einem Event (welches Operationen aufruft, die potentiell den Zustand der Komponente ändern) passieren.

% vorher - klappt nicht, funkt der dev dazwischen 

\textbf{Vor} einem Event die Mementos abzurufen ist nicht möglich, da ein Event erst registriert wird, wenn die Nachricht im Event Broker ankommt. Zu diesem Zeitpunkt kann eine Komponente ihren Zustand bereits geändert haben. Das Hilfesystem könnte eigene Event Handler auf die Operationen der aktionsrelevanten UI Elemente registrieren und so bemerken, wann ein Event ausgelöst wird. Allerdings kann das Hilfesystem erst Event Handler registrieren, wenn die Komponente initialisiert wurde. Zu diesem Zeitpunkt wurde der DOM geladen und Event Handler des Komponentenentwicklers registriert. Die Event Handler des Hilfesystems würden zwangsläufig nach den Handlern des Entwicklers ausgeführt. Wenn es soweit ist, könnte die Komponente schon ihren Zustand verändert haben und das Memento enthält nicht die gewünschten Attributwerte.

Eine mögliche Lösung wäre den Lebenszyklus der Komponenten zu modifizieren. Es könnte ein Zustand \emph{Rendered} zwischen \emph{Integrated} und \emph{Active} eingefügt werden (Abbildung~\ref{figure:cruise-lifecycle}), bei dem der DOM der Komponente vollständig vorhanden sein, aber Event Handler noch nicht registriert sein sollen. Zu diesem Zeitpunkt könnte das Hilfesystem seine Handler vor jenen des Komponentenentwicklers registrieren, die dann auch als erstes ausgeführt würden. Problematisch ist allerdings, wenn eine Komponente zur Laufzeit DOM Elemente erstellt und Event Handler registriert. Dieses Verhalten müsste man verbieten, um sicherzustellen dass Handler des Hilfesystems immer zuerst ausgeführt werden. Das ist aber nicht wünschenswert, weil diese Vorgabe möglicherweise große Anpassungen des Komponentencodes nötig macht und oft auch gar nicht umsetzbar ist.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.75\textwidth]{images/konzeption-cruise-lifecycle.png}
   \caption{UI Mockup: Modifizierter CRUISe Komponentenlebenszyklus}
   \label{figure:cruise-lifecycle}
\end{figure}

% nachher

Es bleibt die Möglichkeit \textbf{nach} einem Event Mementos abzurufen. Zunächst ist es schwierig festzustellen, wann \enquote{nach} einem Event überhaupt ist. Events können in dem Sinne kaskadieren, als dass sie Operationen aufrufen, die weitere Events feuern, die wiederum Operationen ausführen, die selbst Events feuern und so weiter. Aus dem Kommunikationsmodell kann a priori nicht eindeutig bestimmt werden, welche Events nach einem Event $e_0$ zu erwarten sind. Das ist eine Folge des \enquote{Black Box} Prinzips der Komponenten. Im folgenden Abschnitt wird ein Konzept erarbeitet, mit dem das Hilfesystem kaskadierende Events identifizieren kann.

\subsection{Backend}

% voraussetzungen

Ein Ansatz zur Lösung des Problems ist die aufrufende Methode in die Eventnachricht zu schreiben. Das muss der Komponentenentwickler übernehmen. So kann das Hilfesystem bzw. der Event Broker zur Laufzeit Eventkaskaden erkennen, da das Ziel einer Nachricht (CRUISe Operation) denselben Wert enthält wie die aufrufende Methode einer anderen Nachricht. Zusätzlich zur aufrufenden Methode muss noch ein Timestamp, eine eindeutige Event ID und die Instanz-ID der Komponente angegeben in einer Nachricht enthalten sein, was aber der Event Broker übernehmen kann.

% algorithmus

Der Ablauf des Algorithmus wird anhand der Situation in Abbildung~\ref{figure:dependency-graph} erklärt. Sie zeigt einen beispielhaften Ablauf, wo $e_3$ und $e_4$ gefeuert wurden und $o_3$ bzw. $o_4$ aufrufen, weil eine ursprünglich eine Aktion in Komponente A ausgeführt wurde.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/konzeption-dependency-graph.png}
   \caption{Möglicher Ablauf der Events in der beispielhaften Komposition}
   \label{figure:dependency-graph}
\end{figure}

Der Algorithmus funktioniert wie folgt:

\begin{enumerate}
	\item Komponente A feuert Event $e_1$.
	\item Das Hilfesystem registriert die Nachricht $e_1$ und sucht nach einer Collection mit einer Nachricht $e_i$, die der Vorgänger von $e_1 $ sein könnte. Da keine vorhanden ist, fügt das Hilfesystem $e_1$ in eine neu erstellte Collection hinzu und legt ein Timeout von $t$ Millisekunden fest. Läuft es ab, fährt der Algorithmus bei Schritt 7 fort. Außerdem wird $e_1$ bis dorthin der Methode $o_2$ von C zugeordnet.
	\item Innerhalb des Timeouts $t$ feuert Komponente C Event $e_3$.
	\item Das Hilfesystem registriert die Nachricht $e_3$ und überprüft, ob es eine Collection mit einem Vorgänger dafür gibt. Das ist der Fall, also liest das Hilfesystem aus der Nachricht, welche Methode sie geschickt hat ($o_2$). Danach wird eine Collection gesucht, welche eine der $o_2$ zugeordneten Nachrichten enthält. Findet das Hilfesystem eine, fügt es $e_3$ dieser hinzu und setzt den Timer auf~0 zurück. In diesem Beispiel ist das der Fall. Würde das Hilfesystem keine Collection finden, führe es fort wie in Schritt~2.
	\item Innerhalb des Timeouts $t$ feuert Komponente~C Event $e_4$.
	\item $e_4$ wird gleich wie $e_3$ in Schritt~4 behandelt.
	\item Das Timeout $t$ läuft ab.
	\item Das Hilfesystem markiert die Collection als geschlossen und entfernt die Assoziation zwischen enthaltenen Nachrichten sowie den Methoden der Komponenten. Da die zustandsverändernde Operation von Komponente D erst aufgerufen werden muss, legt es ein Timeout $t_D$ fest, nach dessen Ablauf die Mementos der Komponenten abgerufen werden können.
\end{enumerate}

% anmerkungen

Ein noch nicht betrachteter Punkt sind asynchrone Operationen (z.\,B. \texttt{setTimeout()}). Die Reihenfolge der Nachrichten spielt im vorgestellten Algorithmus keine Rolle\todo{proof?}, weswegen asynchrone Operationen wie synchrone behandelt werden, solange sie innerhalb des Timeouts $t$ ein Event feuern. Das festgelegte Timeout ist aber keine gute Designentscheidung, wenn es um Zugriffe auf externe APIs geht. Es kann nicht davon ausgegangen werden, dass sie innerhalb des Timeouts beantwortet werden. Aus diesem Grund wird bei der History -- wie bei den Kommentaren (Abschnitt~\ref{section:konzeption:kommentare}) auch -- ausgeschlossen, dass Komponenten externe Daten laden können.

Für das Timeout $t_D$, welches auf die Ausführung der Operation der letzten beteiligten Komponente wartet, kann der Wert aus der Bedienungshilfe (Abschnitt~\ref{section:konzeption:bedienung}) herangezogen werden, wenn vorhanden. Dieser teilt dem Hilfeservice, der die Comic Panels generiert, mit, wann die Zustandsveränderung der Komponente abgeschlossen ist. Ansonsten wird ein durch Tests bestimmter Standardwert verwendet.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=\textwidth]{images/konzeption-dependency-graph-diagram.png}
   \caption{Ablaufdiagramm des History Algorithmus}
   \label{figure:dependency-graph-diagram}
\end{figure}

Außerdem ist zu beachten, dass für die korrekte Arbeitsweise des vorgestellten Algorithmus jedes Event eine Nachricht senden \textbf{muss}, sei es auch nur \enquote{Methode ausgeführt}. Ansonsten könnte eine Komponente ihren Zustand verändern, ohne dass es der Event Broker und damit das Hilfesystem merkt. Die Undo-Reihenfolge wäre dann nicht mehr korrekt. Das impliziert weiterhin, dass Zustandsveränderungen ein Event feuern müssen. Diese Forderung ist schon umgesetzt, da zum Beispiel \texttt{setProperty(p,v)} eine Operation ist, die \texttt{propertyChanged} Events feuert und die Menge an propertys den Zustand einer Komponente vollständig beschreiben.

% mögliche stolpersteine

Bevor konkrete visuelle Umsetzungen der History präsentiert werden, muss diskutiert werden, wie mit von Komponenten (anstatt vom Benutzer) ausgelösten Aktionen umgegangen wird. Beispielsweise wäre eine Uhrzeit-Komponente denkbar, die jede volle Minute ein \texttt{minutePassed} Event auslöst. Klassische Implementierungen einer History löschen den Redo-Stack, wenn nach einem Undo eine neue, nicht in der History vorhandene Aktion ausgeführt wird. Im Falle der Uhrzeit-Komponente wäre das äußerst ungünstig, da sie spätestens nach einer Minute unerwünschterweise den Redo-Stack löschen würde. Derartige Komponenten von der History auszuschließen ist jedoch keine Option, da sie aufgrund des Ziels der \textit{Universalität} alle Komponenten unterstützen muss. Events nach einem Undo zu pausieren ist ebenfalls nicht möglich, da dann überhaupt keine neuen Aktionen mehr ausgeführt werden können. Deswegen sollten neue, durch Komponenten ausgelöste Aktionen, nach einem Undo weiter auf den Redo-Stack gelegt werden. Dieser kann gelöscht werden, sobald der Benutzer eine Aktion ausführt. Der im vorhergehenden Abschnitt vorgestellte Algorithmus kann eine Nutzeraktion aber nicht in allen Fällen von einer Komponentenaktion unterscheiden. Zwar gibt es in der SMCDL ein Attribut \texttt{trigger}, welches angibt, ob ein Event durch Nutzerinteraktion, infolge einer Operation oder interner Logik ausgelöst wird \cite[S. 98]{Pietschmann2012}. Dieses ist jedoch optional und außerdem muss es nicht immer festgelegt sein: Es ist möglich, dass ein Event sowohl durch eine Operation als auch durch Nutzerinteraktion ausgelöst wird.

Um dem beizukommen, kann das Hilfesystem eigene Eventhandler auf aktionsrelevanten UI Elementen registrieren. Diese sind in Folge der Erweiterungen durch die Bedienungshilfe (Abschnitt~\ref{section:konzeption:bedienung}) bekannt. Abbildung~\ref{figure:undo-ablauf} verdeutlicht die Funktionsweise: Zuerst wird eine Nachricht $e_1$ an den Event Broker gesendet (1). Dieser fügt sie einer Collection hinzu (2). Danach wird der Eventhandler des Hilfesystems aufgerufen (3). Das Hilfesystem weiß, zu welcher Komponente, Aktion und Operation der Eventhandler gehört (Abschnitt~\ref{section:konzeption:bedienung:api}) und kann in den Collections des Event Brokers nach entsprechenden Nachrichten suchen. Von diesen wird die aufrufende Methode gelöscht und sie werden in eine neue Collection eingefügt (4). Danach kann das Hilfesystem den Redo-Stack löschen, falls nötig.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.75\textwidth]{images/konzeption-undo-ablauf.png}
   \caption{Erkennung von Nutzerinteraktionen}
   \label{figure:undo-ablauf}
\end{figure}

\subsection{User Interface und Interaktion}
\label{section:konzeption:history:ui}

% unterscheidung verschiedener historys und festlegung, was wir haben

Der im vorangehenden Abschnitt vorgestellte Algorithmus, welcher zu gegebener Zeit Mementos der Komponenten abruft, speichert und wiederherstellt, macht die hier behandelte History zu einer State History. Um die State History einfach bedienen zu können, sollten die verschiedenen States erkennbar dargestellt werden.

\subsubsection{Umsetzung einer webbasierten State History}

% eigentlich können wir ja die bedienungshilfe dynamisch aufrufen? not. eh schon wenig zeit und dann können operationen noch beliebig lang dauern.

Prinzipiell kann der in Abschnitt~\ref{section:konzeption:bedienung:generierung} vorgestellte Algorithmus zur Generierung von Screenshots auch dynamisch aufgerufen werden. Alle notwendigen Informationen sind bekannt: Der geladene Datensatz, die Mappings, die betroffenen Komponenten, die ausgeführten Aktionen und Operationen. Das Hilfesystem könnte beim Start der kompositen Ansicht den Generierungsservice mit denselben Komponenten und Daten initialisieren. Nach jeder registrierten Operation würde es diese Daten an den Generierungsservice schicken, der einen Screenshot der Applikation in diesem Zustand zurück gibt. Jedoch sollte es nie länger als zwei Sekunden dauern, bis ein Screenshot in der History verfügbar ist. Von der Tatsache abgesehen, dass dieser Vorgang zeitkritisch ist, ist er leider auch nicht umsetzbar: Wegen des \enquote{Black Box} Prinzips der Komponenten können Zustandsveränderungen beliebig lange dauern. Deren obere Grenze ist zwar bekannt (Abschnitt~\ref{section:konzeption:bedienung:api}), aber der Generierungsservice müsste die Zeit trotzdem abwarten, bevor ein Screenshot erstellt werden kann. Diese Zeit muss von den veranschlagten zwei Sekunden abgezogen werden, um die verfügbare Rechen- und Transferzeit zu erhalten. Es erscheint unwahrscheinlich, dass der beschriebene Vorgang in so kurzer Zeit abgearbeitet werden kann. Außerdem könnte die History einen fehlerhaften Screenshot enthalten, wenn ein Screenshot frühzeitig angefertigt würde.

% aber wenigstens können wir den DOM kopieren? sorta, yes.

Eine andere Variante, um an realitätsgetreue Abbildungen von Komponentenzuständen zu gelangen, wäre ihren DOM zu kopieren und verkleinert in der History anzuzeigen. Problematisch sind dabei CSS Regeln mit absoluten Einheiten, wie zum Beispiel Pixel oder Punkt. Eine Lösung dafür wäre zur Laufzeit das CSS einer Komponente in relative Einheiten zu transformieren. Abbildung \ref{figure:transform-css} zeigt  einen naiven Algorithmus als ersten Ansatz. Dabei wird am Wurzelelement gestartet (\texttt{DIV B}) und die relative Breite und Höhe zum Elternknoten (\texttt{DIV A}) berechnet (Schritt 1). Diese Attribute werden im CSS gesetzt. Danach wird der Algorithmus rekursiv für die Kinder von \texttt{DIV B} aufgerufen, also \texttt{DIV C} und \texttt{D}, und nach demselben Prinzip fortgefahren.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=\textwidth]{images/konzeption-transform-css.png}
   \caption{Naiver Algorithmus um CSS zu in relative Einheiten zu transformieren}
   \label{figure:transform-css}
\end{figure}

Der vorgestellte Algorithmus hat einige offensichtliche Schwachstellen. Beispielsweise gibt es 

\begin{itemize}
	\item Elemente ohne definierte Breite oder Höhe (\texttt{svg:g}), 
	\item mit nicht-rechteckiger Größendefinition (\texttt{svg:circle}, \texttt{svg:path}) oder
	\item Attribute, welche ebenfalls skaliert werden müssen (\texttt{margin}, \texttt{x}).
\end{itemize}

Hinzu kommt, dass sowohl alle möglichen Elemente, also auch Clip Paths, Polygone, Polylinien und so weiter als auch deren Transformationen (verschieben, rotieren, skalieren, verzerren etc.) korrekt skaliert werden müssen. Außerdem ist der Vorgang möglicherweise sehr langsam, wenn der Browser nach jedem Update eines layoutrelevanten CSS Attributs (wie Breite oder Höhe) das Layout neu berechnen muss (\enquote{Reflow}) und währenddessen das User Interface blockiert. Der Vorgang erscheint zwar nicht einfach, aber lösbar und sollte dennoch möglichst vermieden werden.

% noch cooler ist es, wenn gleich der entwickler alles relativ schreibt

Noch besser als CSS zur Laufzeit zu transformieren wäre, wenn der Komponentenentwickler von vornherein relative Einheiten verwendete. Das wäre ohnehin zu bevorzugen, da Komponenten theoretisch beliebig ihre Größe ändern können. Dennoch sollte es kein Muss-Kriterium für den Komponentenentwickler sein, da es längere Entwicklungszeiten nötig macht und den Aufwand erhöht. Um  relative CSS Einheiten zu forcieren, wird deren Nutzung angenommen. Andernfalls muss der Komponentenentwickler in der Komponentenbeschreibung das Gegenteil angeben, sodass das CSS der Komponente zur Laufzeit transformiert wird.

\subsubsection{Visuelle Repräsentation der State History}

% timeline mit bildern

Wie in \cite{Heer2008} besteht die State History aus Bildern der Komponenten mit einer Seitenlänge von mindestens 120~Pixel (Abbildung~\ref{figure:undo-graphical}). Dabei werden Komponenten hervorgehoben, die sich seit dem vorhergehenden Applikationszustand verändert haben. Nach einem Klick auf einen Zustand wird die Komposition in diesen zurückgesetzt.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.75\textwidth]{images/konzeption-undo-graphical.png}
   \caption{UI Mockup: Grafische History}
   \label{figure:undo-graphical}
\end{figure}

% simple buttons als alternative

Sollte sich die dynamische Transformation von CSS Regeln als nicht praktikabel herausstellen, werden zwei Buttons für Undo und Redo eingesetzt (Abbildung~\ref{figure:undo-simple}), wenn Komponenten ohne relatives CSS in der Komposition vorhanden sind. Diese Art der History ist auch in jeder Desktopapplikation vorhanden. Die Buttons sind sofort verständlich und erfüllen ihren Zweck, allerdings wird die Interaktion umso mühsamer, je weiter der zu erreichende Anwendungszustand zurück liegt.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.25\textwidth]{images/konzeption-undo-simple.png}
   \caption{UI Mockup: Undo/Redo Buttons}
   \label{figure:undo-simple}
\end{figure}


\section{Meta-Hilfe}
\label{section:konzeption:meta-hilfe}

% warum brauchen wir meta-hilfe?

In diesem Konzept wurden bisher sieben unterschiedliche Hilfefunktionen erarbeitet: Intro, Bedienung, Feedback, Verlinkung, Kommunikation, Kommentare und History. Diese sind zwar optisch und vom Interaktionsdesign her konsistent, bringen aber trotzdem viel zusätzliche Komplexität in die Anwendung. Um die Hilfefunktionen und damit die Anwendung in vollem Umfang nutzen zu können (\emph{Vollständigkeit}), benötigt der Benutzer einige Informationen. Dazu gehört sowohl das Wissen, welche Hilfefunktionen existieren und wie sie aufgerufen werden, als auch konzeptionelle Dinge, wie z.\,B. dass Kommentare mit Bereichen und/oder Datenpunkten in der Visualisierung assoziiert sind. Es ist anzunehmen, dass diese Meta-Hilfe vor allem bei der ersten Nutzung von VizBoard benötigt wird. Aus diesem Grund sollte sie so \emph{unaufdringlich} wie möglich gestaltet sein. Prinzipiell können Hilfestellungen unterteilt werden in dynamische Hilfe, die dem Nutzer bei Bedarf angeboten wird, und statische Hilfe, die der Nutzer selbst aufrufen muss.

\subsection{Statische Meta-Hilfe}

% statische hilfe

Die einfachste Lösung für die statische Meta-Hilfe wäre ein Button in der rechten oberen Ecke, der bei Bedarf eine klassische Hilfefunktion aufruft. Dort werden die verschiedenen Funktionen in Wort und Bild erklärt und ein Tutorialvideo gezeigt. Das bedeutet relativ viel Zeit- und Klickaufwand, bis der Nutzer bei den gewünschten Informationen ist, aber es hat auch Vorteile: Durch den statischen Hilfeknopf ist immer klar, wo weitergeholfen wird. Außerdem kann er gegebenenfalls für andere Sachen benutzt werden, beispielsweise könnte dort konfiguriert werden, ob der Pfeil in der Kommunikationshilfe bei jeder Nachricht angezeigt werden soll.

In der Nutzerstudie war die Kommentarfunktion nicht offensichtlich. Die Teilnehmer hatten Probleme sie aufzurufen, zu benutzen und die möglichen Funktionen zu erkennen. Deswegen sollte das Intro (Abschnitt~\ref{section:konzeption:intro}) am Ende zusätzlich das notwendigste für die Nutzung der Kommentarfunktion erklären. Dazu gehört zum Beispiel, wie Kommentare angezeigt oder geschrieben werden (inklusive möglicher Annotationen) und dass sie bewertet werden können. Außerdem sollte das Intro auf die statische Meta-Hilfe hinweisen.

\subsection{Dynamische Meta-Hilfe}
\label{section:konzeption:meta-hilfe:dynamisch}

% zweite lösung: kontextabhängige dynamische hilfe
Ein Nachteil der statischen Hilfe ist, dass sie nicht lernt und sich dem Benutzer nicht anpasst. Die dynamische Hilfe ändert das. Allerdings stellt sich die Frage, woher sie weiß, wann sie welche Hilfe anbieten soll.

% user affection
% auch argumentieren, warum sie so umgesetzt wird
% user affection kann man nicht ohne weiteres messen, mit hmm's wird es vermutlich auch nicht wahnsinnig gut gehen

Die beste Lösung wäre sicher, wenn das Hilfesystem erkennen könnte, wenn der Benutzer verwirrt oder verärgert ist. Das fällt unter den Begriff \enquote{User Affection Detection/Recognition}. Mögliche Ansätze dazu benötigen Sensoren wie EEG oder Eyetracking, die in VizBoard nicht verfügbar sind \cite{Li2005, Liao2006}. Eine andere Variante wäre Rückschlüsse auf den Gemütszustand des Benutzers mit Hidden Markov Models \cite{Rabiner1986} zu ziehen. Allerdings könnten in VizBoard nur Mausklicks und Tastaturanschläge als Beobachtungen verwendet werden, was vermutlich nicht zu zufriedenstellenden Ergebnissen führen würde.

% deswegen versuchen aus interaktionsgeschichte, komposition, umgebung und nutzerinformationen regeln zu schließen --> supervised learning

Eine weitere Lösungsmöglichkeit ist das Konzept von Trace-Based Reasoning \cite{Cordier2013} anzuwenden. Durch maschinelles Lernen \cite{Kotsiantis2007} von Daten über Nutzer, Komposition, Umgebung und Interaktionsgeschichte werden Regeln z.\,B. in Form eines Decision Trees gefunden, wann Hilfe angeboten werden soll. So kann das Hilfesystem aus vergangenen Erfahrungen mit Nutzern lernen. Der Nachteil ist allerdings, dass die Ergebnisse nicht zufriedenstellend sein werden, bis dem Hilfesystem ausreichend Trainingsdaten zur Verfügung stehen. Abbildung~\ref{figure:architektur-dynhilfe} zeigt einen Überblick des Systems.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=\textwidth]{images/konzeption-architektur-dynhilfe.png}
   \caption{Architektur der dynamischen Hilfefunktion}
   \label{figure:architektur-dynhilfe}
\end{figure}

Der Ablauf ist wie folgt:

\begin{enumerate}
	\item Der Nutzer interagiert wie gewohnt mit dem Mashup.
	\item Das Hilfesystem nimmt die Interaktionen des Nutzers auf.
	\item Das Hilfesystem schickt die erfassten Daten an die Wissensbasis. Um die dynamische Hilfe auch für andere auf CRUISe basierende Mashups verfügbar zu machen, sollte diese im CoRe integriert sein.
	\item Die Wissensbasis erlernt Regeln aus den Daten, beispielsweise männliche Architekten brauchen in der Nacht Hilfe zur Kommunikation, wenn sie die Komponente XY nutzen.
	\item Die Wissensbasis schickt den generierten Classifier an das Hilfesystem.
	\item Das Hilfesystem benutzt den Classifier, um den geeigneten Zeitpunkt für ein Hilfeangebot zu finden.
	\item Das Hilfesystem bietet Hilfe an.
	\item Der Benutzer profitiert von der Hilfe.
\end{enumerate}

Supervised Machine Learning Algorithmen gehen als Datengrundlage von einer Tabelle aus, in der die Zeilen Instanzen und die Spalten Attribute oder Facetten der Instanzen sind (Abbildung~\ref{figure:sml-daten}). Die Menge von Spalten wird \enquote{Feature Vector} genannt. 

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/konzeption-sml-daten.png}
   \caption{Datengrundlage für SML Algorithmen}
   \label{figure:sml-daten}
\end{figure}

Je nach Algorithmus können Attribute unterschiedlichen oder festen Typs sein: Decision Trees arbeiten sowohl mit nominalen als auch ordinalen und quantitativen Variablen, während Support Vector Machines nur quantitative Daten unterstützen. Allen Algorithmen gemein ist jedoch, dass Attribute eindimensional sein müssen und beispielsweise keine Arrays oder Mengen sein dürfen. Weil für die Meta-Hilfe verschiedene Daten herangezogen werden müssen, wird ein Decision Tree Algorithmus gewählt. Ein klassifizierender Decision Tree nimmt einen Feature Vector als Input und weist ihn einer von mehreren Kategorien zu. Im Fall der dynamischen Meta-Hilfe sind das \enquote{Keine Hilfe nötig} und die verschiedenen Hilfefunktionen (Abbildung~\ref{figure:sml-ziel}).

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/konzeption-sml-ziel.png}
   \caption{Klassifizierender Decision Tree Algorithmus}
   \label{figure:sml-ziel}
\end{figure}

Nun stellt sich die Frage, welche Daten für das maschinelle Lernen herangezogen werden sollen, d.\,h. wie der Feature Vector aussieht. Wie bereits erwähnt, sind verschachtelte Attribute wie Arrays oder Mengen nicht zulässig, d.\,h. es können nicht alle Interaktionen des Nutzers herangezogen werden (weil sie nicht eine Zelle der Tabelle passen). Darum werden die Facetten mehrerer Interaktionen, zum Beispiel in welcher Komponente sie stattfand oder welche Operation es war, zum Feature Vector hinzugefügt. Da die Anzahl von Spalten der Tabelle Einfluss auf die Laufzeit des Algorithmus hat (weniger ist besser), aber mehr Spalten potentiell mehr Erkenntnisse ermöglichen (mehr ist besser) und das Hilfeangebot nicht zu spät erfolgen darf (weniger ist besser), scheinen fünf Interaktionen ein guter Kompromiss zu sein (Abbildung~\ref{figure:sml-ziel}). Jedoch sollte das in Tests genauer evaluiert werden. Es erscheint sinnvoll folgende Informationen zu erfassen:

\begin{itemize}
	\item Alter, Geschlecht, Domäne und Ort des Benutzers: Diese können im Context oder User Service von VizBoard gespeichert sein. Mit Hilfe der Domäne soll fachabhängigen Fehlinterpretationen beigekommen werden, beispielsweise falls Mathematiker dazu tendieren Pfeile verkehrt herum zu deuten. Falls Menschen in Asien Icons anders interpretieren sollten, kann der Ort des Benutzers das Hilfesystem darauf hinweisen.
	\item Zeit und Datum der Interaktion: Sie sind nötig um Tag und Nacht unterscheiden zu können. Menschen sind bei Nacht eher müde und wenig konzentriert, benötigen daher früher Hilfe.
	\item Für die letzten 5~Interaktionen des Benutzers: Grafische Repräsentation der Komponente, Aktion und vergangene Zeit seit Nutzungsstart. Je genereller die gespeicherten Informationen, desto besser für das Hilfesystem, welches die Erkenntnisse in umso mehr Komponenten verwenden kann.
	\item Ob Hilfe angeboten wurde und wenn ja, welche Funktion: Diese Information ist nötig, um Fehlinterpretationen des Hilfesystems zu erkennen (Abbildung~\ref{figure:meta-dyn-id}).
	\item Ob Hilfe aufgerufen wurde und wenn ja, welche Funktion: Dieses Attribut soll durch den Decision Tree vorhergesagt werden.
\end{itemize}

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/konzeption-meta-dyn-id.png}
   \caption{Erkennung von False Positives und False Negatives}
   \label{figure:meta-dyn-id}
\end{figure}

Das Hilfesystem schickt alle fünf Interaktionen einen solchen Datensatz an die Wissensbasis, welche ihn zu den Trainingsdaten hinzufügt. Außerdem wird der Datensatz an den Classifier weitergegeben, der das letzte Attribut vorhersagt. Ist das Ergebnis ein anderes als \enquote{Keine Hilfe nötig}, bietet das Hilfesystem dem Benutzer Hilfe zur entsprechenden Funktion an. Damit die Wissensbasis einen initialen Classifier generieren kann, müssen zunächst auf die beschriebene Art und Testdaten gesammelt werden. Mit diesen kann die Wissensbasis einen ersten Classifier generieren und iterativ verbessern.

\subsection{User Interface und Interaktion}

Der Button für die Meta-Hilfe befindet sich in der rechten oberen Ecke des Viewports (Abbildung~\ref{figure:meta-step1}). Er ist rot, damit er vom Benutzer bemerkt wird und rund, weil er so aus dem bisher verwendeten optischen Konzept ausbricht und auffällt, aber nicht fehl am Platz wirkt.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/konzeption-meta-step1.png}
   \caption{UI Mockup: Statischer Button für Meta-Hilfe}
   \label{figure:meta-step1}
\end{figure}

Nachdem der Benutzer darauf geklickt hat, wird der Viewport abgedunkelt und ein Fenster überblendet, welches Hilfe zu verschiedenen Themen enthält (Abbildung~\ref{figure:meta-step2}). Von dort können ebenfalls die verschiedenen Hilfefunktionen (wie z.\,B. das Intro) aufgerufen werden.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/konzeption-meta-step2.png}
   \caption{UI Mockup: Statische Meta-Hilfe}
   \label{figure:meta-step2}
\end{figure}

Wenn das Hilfesystem dem Benutzer Hilfe anbietet, rotiert der Button, wird orange eingefärbt und in der Sidebar erscheint das entsprechende Hilfeangebot (Abbildung~\ref{figure:meta-dyn}). Der Benutzer kann es nutzen, indem er darauf klickt oder selbstständig zur Hilfefunktion navigiert. Tut er das für 5~Interaktionen nicht oder schließt die Sidebar, wird der Button zurück rotiert. 

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/konzeption-meta-dyn.png}
   \caption{UI Mockup: Dynamische Meta-Hilfe}
   \label{figure:meta-dyn}
\end{figure}

\section{Synthese}
\label{section:konzeption:synthese}

Für das Konzept wurde das Markup einer Komponente, die Komponentenbeschreibung sowie die API einer Komponente, das CoRe und der Event Broker erweitert. In diesem Abschnitt werden die Änderungen zusammengefasst.

\subsubsection{Markup einer Komponente}

\begin{itemize}
	\item Datenattribute (Legende und Freitext), um Begriffe zur automatischen Verlinkung zu kennzeichnen.
	\item Datenattribut, um Wurzelelement der Visualisierung zu kennzeichnen (Kommentare, History).
	\item RDFa Attribute, die Datenpunkte kennzeichnen und eventuell beschreiben (Kommentare).
\end{itemize}

\subsubsection{Komponentenbeschreibung}

\begin{itemize}
	\item Annotation, ob eine Property Teil des Mementos ist (Kommentare, History).
	\item VISO Operationen, welche eine Aktion ausführen (Bedienung).
	\item CSS Selektoren für jede Operation, um UI Elemente für Operation zu kennzeichnen (Bedienung).
	\item Konzept, welches Aktion näher beschreibt (Verlinkung).
	\item Anzahl an Sekunden, die vor einem Screenshot gewartet werden soll (Bedienung).
	\item Nähere Beschreibung einer Aktion durch Freitext oder Referenz auf Datenvariable (Bedienung).
	\item Ob Hilfe für Capability/Operation generiert werden soll oder nicht (Bedienung).
	\item Optionale Zusatzinformationen zur VISO Operation, beispielsweise welche Taste gedrückt werden muss (Bedienung).
	\item Beispieldaten für Parameter, falls von VISO Operation benötigt (Kommunikation). Das ist beispielsweise bei einer Drag Operation nötig.
	\item Testdatensatz: Entweder ID eines DaRe Datensatzes mit SPARQL Query für Mappings oder Informationen über einen hochgeladenen Datensatz (Bedienung).
	\item Ob die Komponente Datenverarbeitung durchführt (Kommentare).
	\item Ob die Komponente externe Daten lädt (Kommentare).
	\item Ob die Komponente beliebig skalierbar ist oder deren CSS zur Laufzeit transformiert werden muss (History).
\end{itemize}

\subsubsection{API einer Komponente}

\begin{itemize}
	\item Eine Methode, um Koordinaten in Datenpunkte umzurechnen (Kommentare).
	\item Die Umkehrung der Methode (Datenpunkte $\to$ Koordinaten) (Kommentare).
	\item Eine Methode, welche Attribute zu URIs von Datenpunkten ausgibt (Kommentare).
\end{itemize}

\subsubsection{VISO}

\begin{itemize}
	\item Beschreibung einer grafischen Repräsentation (Intro).
	\item Link zu Tutorialvideo (Intro).
\end{itemize}

\subsubsection{CoRe}

\begin{itemize}
	\item Ursprüngliches Mapping an MRE weiterleiten (Intro, Kommentare).
	\item Wissensbasis für dynamische Meta-Hilfe sowie Schnittstelle zum Zugriff darauf.
\end{itemize}

\subsubsection{DaRe}

\begin{itemize}
	\item Kommentare speichern sowie eine Schnittstelle zum Abruf.
	\item Abruf und Speicherung von Konzeptbeschreibungen sowie Schnittstelle zum Zugriff (Bedienung, Verlinkung).
\end{itemize}

\subsubsection{Event Broker}

\begin{itemize}
	\item Methode, welche Weiterleitung von Events pausiert (Kommentare).
	\item Methode, welche Weiterleitung von Events wieder aufnimmt (Kommentare).
\end{itemize}

\subsubsection{Event Nachricht}

Für die History müssen folgende Attribute enthalten sein:

\begin{itemize}
	\item Aufrufende Operation,
	\item Timestamp,
	\item eindeutige ID, beispielsweise eine fortlaufende Nummer.
\end{itemize}

\subsubsection{Context Service}

\begin{itemize}
	\item Alter, Aufenthaltsort, Geschlecht, Domäne des Benutzers (Kommentare, Meta-Hilfe).
\end{itemize}

\subsubsection{CRUISe}

\begin{itemize}
	\item Jedes Event muss eine Nachricht schicken (History).
\end{itemize}

\section{Zusammenfassung}
\label{section:konzeption:zusammenfassung}

\todo[inline]{Hier fehlt Text.}

\chapter{Implementierung}
\label{chapter:implementierung}

In den folgenden Abschnitten wird die prototypische Implementierung der Konzepte Bedienung (Abschnitt~\ref{section:konzeption:bedienung}), Kommunikation (Abschnitt~\ref{section:konzeption:kommunikation}) und Kommentare (Abschnitt~\ref{section:konzeption:kommentare}) beschrieben. Sie sind aufgeilt in Frontend (Abschnitt~\ref{section:implementierung:frontend}) und Backend (Abschnitt~\ref{section:implementierung:backend}).

\section{Frontend}
\label{section:implementierung:frontend}
 % frontend ist ja für alle mehr oder weniger gleich, zumindest die grundlage. deswegen zuerst.

% welche libraries?
Das Frontend der implementierten Konzepte wurde mit Backbone.js\footnote{\url{http://backbonejs.org/}}, einem populären Javascript MVC Framework, und dessen Erweiterung Marionette.js\footnote{\url{http://marionettejs.com/}} geschrieben. Des Weiteren kamen die Bibliotheken jQuery\footnote{\url{http://jquery.com/}} (von Backbone verwendet), jQuery UI\footnote{\url{http://jqueryui.com/}} und D3 \cite{Bostock2011} zum Einsatz.
% warum diese?

% 1 - extjs ist zu abstrakt. ich muss ja haupsächlich dom knoten suchen, kopieren, klasse setzen etc.
Zunächst muss begründet werden, warum ein anderes Javascript Framework als das in CRUISe bereits eingesetzte ExtJS\footnote{\url{http://www.sencha.com/products/extjs}} gewählt wurde. Hier müssen zwei Einsatzzwecke unterschieden werden:

\begin{enumerate}
	\item Als MVC Framework, welches verschiedene Views und Models definiert und strukturiert, sowie
	\item als Bibliothek für generische DOM Operationen.
\end{enumerate}

Für letzteres wird jQuery eingesetzt, da ExtJS mehr vom DOM abstrahiert als jQuery. Mit ExtJS denkt der Entwickler nicht in \texttt{div}s oder \texttt{span}s, sondern in generischen Komponenten wie Listen, Panels und Dialogen. Nicht alle UI Konzepte können damit umgesetzt werden. Beispielsweise werden für Kommentare an einzelnen Ressourcen eine Art Badge angezeigt, was einem \texttt{div} mit runden Ecken entspricht. Davon abgesehen ist jQuery bereits in der TSR Codebase vorhanden.

Als MVC Framework wird Backbone unter anderem deswegen eingesetzt, weil in der Einführung des Konzepts (Abschnitt~\ref{section:konzeption:einfuehrung}) ein visueller Unterschied zwischen Hilfesystem und Komponenten gefordert wurde. CRUISe Komponenten verwenden bereits die generischen ExtJS Styles, weswegen das Frontend eigene Styles für das recht komplexe, von ExtJS generierte Markup definieren müsste. Dies erschien zu viel Aufwand zu sein. Von der Einheitlichkeit der Codebase abgesehen gab es auch keinen Grund, ExtJS zu verwenden, weil die UI des Hilfe Frontends recht einfach aufgebaut ist.

% wenn schon kein extjs, warum gerade backbone und nicht knockback, spine oder eins von den andern tausend?
Nun stellt sich noch die Frage, warum gerade Backbone.js und nicht eines der vielen anderen Frameworks\footnote{Für eine Übersicht der Wichtigsten sei auf \url{http://todomvc.com/} verwiesen, wo 33~Javascript MVC Frameworks aufgelistet sind.} gewählt wurde. Einerseits hat der Autor damit bereits grundlegende Erfahrung gesammelt, sodass die Einarbeitungszeit entfiel. Andererseits ist es gut dokumentiert und sehr populär, weswegen im Internet viele Informationen zu finden sind.

% marionettejs macht backbone code lesbarer und einfacher zu warten
Marionette.js erweitert Backbone um verschiedene Konzepte (z.\,B. Regionen und unterschiedliche Views für Items, Collections und Bäume) und automatisiert oft vorkommende Anweisungen, wie zum Beispiel einen View zu rendern und in den DOM einzufügen. Der Code ist dadurch kürzer, lesbarer und einfacher zu warten.

% und was hat d3 hier zu suchen?
D3 wird hauptsächlich beim Hinzufügen von Annotationen eingesetzt, wo ein SVG-Element über die Komponente gelegt wird, in welchem der Benutzer seine Annotationen zeichnen kann. Außerdem kann D3 im Gegensatz zu jQuery sowohl mit HTML- als auch mit SVG-Elementen umgehen. Einige Methoden, die im Frontend gebraucht werden, unterstützt jQuery nicht für DOM Elemente mit SVG Namespace (Beispiele dafür sind \texttt{.width()}, \texttt{.addClass()} oder jQuery UIs \texttt{.position()}). Zwar existiert ein SVG Plugin\footnote{\url{https://github.com/kbwood/svg}} für jQuery, dieses weist aber eine unnötig komplizierte API auf. Deswegen wird für die Größenbestimmung oder Positionierung von SVG Elementen D3 verwendet, da es ohnehin schon eingesetzt wird.

\subsection{Clientseitige Architektur}
\label{section:implementierung:frontend:architektur}

Das Assistance Subsystem arbeitet unabhängig vom Rest der Thin Server Runtime (Abbildung~\ref{figure:cruise-architektur-assistance}). Nachdem alle Komponenten integriert wurden, wird es vom Application Manager falls erwünscht gestartet.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.75\textwidth]{images/implementierung-cruise-architektur.png}
   \caption{Architektur von CRUISe mit Assistance}
   \label{figure:cruise-architektur-assistance}
\end{figure}

Um es zu konfigurieren, wird beim Start ein Objekt mit folgenden Informationen übergeben:

\begin{itemize}
	\item \texttt{comment\_url}: Die URL zum Kommentar Backend (Abschnitt~\ref{section:implementierung:backend:kommentare}).
	\item \texttt{core\_url}: Die URL zum CoRe Service.
	\item \texttt{dataset\_id}: Die ID des geladenen Datensatzes, notwendig für Kommentare.
	\item \texttt{user\_id}: Die ID des angemeldeten Benutzers.
	\item \texttt{user\_name}: Der Benutzername des angemeldeten Nutzers.
	\item \texttt{components}: Ein Array mit Informationen zu jeder Komponente.
\end{itemize}

Die notwendigen Informationen zu einer Komponente sind folgende:

\begin{itemize}
	\item \texttt{component\_id}: Die URI der Komponente.
	\item \texttt{component}: Die ID des DOM Elements, in dem sich die Komponente befindet.
	\item \texttt{visualization}: Die ID des DOM Elements, welches die Visualisierung enthält.
	\item \texttt{visualized\_propertys}: Ein Array der dargestellten propertys.
	\item \texttt{data\_annotations\_enabled}: Ob datenbezogene Bereichskommentare zulässig sind.
	\item \texttt{reference}: Eine Referenz zur Instanz der Komponente, um die API aufrufen zu können.
	\item \texttt{memento}: Ein Array der propertys, welche das Memento der Komponente ausmachen.
	\item \texttt{capabilities}: Ein Array von Objekten mit Informationen über jede Capability.
\end{itemize}

Für jede Capability müssen folgende Informationen angegeben werden:

\begin{itemize}
	\item \texttt{capability}: Die ID der Capability.
	\item \texttt{action}: Ein Label, welches die Capability beschreibt, z.\,B. \enquote{sort a movie (Studio)}.
	\item \texttt{component}: Die ID des DOM Elements, in dem sich die Komponente befindet.
	\item \texttt{operation}: Die ID einer atomaren VISO Operation dieser Capability.
	\item \texttt{elements}: Der CSS Selektor, welcher die DOM Elemente für diese Capability findet.
\end{itemize}

Alle diese Informationen werden vom ApplicationManager aus den SMCDLs der Komponenten gelesen, nachdem diese erfolgreich integriert wurden. Um festzustellen, ob eine Komponente datenbezogene Bereichskommentare unterstützt, wird ein Request ans CoRe gesendet, der die Kodierung der visuellen Attribute aller propertys zurückgibt. Findet sich darunter mindestens einmal die Position oder Breite beziehungsweise Höhe -- also etwas, was sich entlang der X- oder Y-Achse messen lässt -- so werden die angesprochenen Kommentare unterstützt. Für die Generierung eines passenden Labels wird der \texttt{LabelGenerator} von EDYRA herangezogen.


\subsection{API einer Komponente}
\label{section:implementierung:frontend:api}

Wie in der Konzeption (Abschnitt~\ref{chapter:konzeption}) erläutert, muss die API einer Komponente um zusätzliche Funktionalität erweitert werden, um Kommentare zu unterstützen und Hilfegenerierung möglich zu machen. Das ist hauptsächlich deswegen nötig, weil die Komponente eine \enquote{Black Box} ist und das Hilfesystem keine Annahmen über die Art der Darstellung von Informationen machen kann. Allerdings sind die meisten Methoden optional: Möchte der Komponentenentwickler keine Kommentare unterstützen, sollen sie einfach nicht implementiert werden.

\begin{itemize}
	\item \texttt{loadTestdata( data )} lädt Testdaten in die Komponente. Diese Methode muss als einzige unbedingt implementiert werden. Die Testdaten werden als String übergeben, um kein Serialisierungsformat (z.\,B. JSON oder XML) vorzuschreiben. Das Parsen des Strings ist der Komponente überlassen. Nachdem in der Regel bereits eine interne Methode besteht, die Daten in die Komponente lädt, stellt die Implementierung von \texttt{loadTestdata} kaum Mehraufwand dar.
	\item \texttt{coordinatesToData( x1, y1, x2, y2 )} wandelt das durch die vier Koordinaten angegebene Rechteck in Grenzwerte von propertys um. Dabei wird ein JSON Array von Objekten mit Attributen \texttt{uri}, \texttt{from} und \texttt{to} zurückgegeben. Für jede in der Komponente dargestellte Property, welche mit den visuellen Attributen Breite, Höhe oder Position kodiert ist, findet sich ein durch die URI gekennzeichnetes Objekt im Array (siehe Abbildung~\ref{figure:coordinatesToData}). Weist eine Property ein nominales Scale of Measurement auf, sind \texttt{from} und \texttt{to} identisch und enthalten ein Array von möglichen Werten.
	\item \texttt{dataToCoordinates( p1, p2 ... )} wandelt von \texttt{coordinatesToData} erhaltene datenbezogene \enquote{Grenzpunkte} wieder in Koordinaten um. Dazu liefert die Methode ein Objekt mit den Attributen \texttt{x1}, \texttt{x2}, \texttt{y1} und \texttt{y2} zurück.
	\item \texttt{getVisualizedpropertys()} liefert ein Array mit den URIs der in der Komponente visualisierten Propertys zurück. Das ist notwendig, damit das Hilfesystem Kommentare für Komponenten laden kann. Diese Propertys bestehen zur Zeit aus der Kombination von Datensatz ID, URI der Klasse der Property (rdfs:domain) und URI der Property. So sind sie eindeutig identifizierbar. Jedoch wäre es möglich, dass eine andere Property owl:sameAs implementiert. Diese identischen Propertys können nicht gefunden werden. Deswegen sollte in Zukunft kein einzelner String, sondern ein Objekt für jede Property geliefert werden, sodass das Backend nach identischen Propertys suchen kann.
	\item \texttt{getDataFromResource()} gibt die Werte der dargestellten propertys eines Datenpunkts zurück.
\end{itemize}

\begin{figure}[htbp]
   \centering
   \includegraphics[width=\textwidth]{images/implementierung-coordinatesToData.png}
   \caption{Die Methode \texttt{coordinatesToData}}
   \label{figure:coordinatesToData}
\end{figure}

Außerdem wurde das Markup einer Komponente entsprechend erweitert. Die Visualisierung in der Komponente wird mit einem Datenattribut \texttt{data-vizboard-visualization} gekennzeichnet. Das Visualisierungselement muss genau so groß sein wie der dargestellte Datenbereich und die Repräsentationen der Datenpunkte enthalten. Abbildung~\ref{figure:ui-visualization} zeigt ein Beispiel. Damit das Hilfesystem die Repräsentationen der Datenpunkte finden kann, wird deren kodierte URI mit dem RDFa Attribut \texttt{resource} annotiert (siehe Listing~\ref{code:visualization-markup}).

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/implementierung-ui-visualization.png}
   \caption{Visualisierungselement in einem Liniendiagramm}
   \label{figure:ui-visualization}
\end{figure}

\lstset{language=HTML}
\begin{lstlisting}[caption={Markup einer Visualisierung}, label=code:visualization-markup]
<svg>
	<g data-vizboard-visualization="true">
		<rect class="bg" x="0" y="0" width="100" height="100"/>
		<circle class="datapoint" cx="0" cy="90" resource="http%3A%2F%2Fsomeuri1"/>
		<circle class="datapoint" cx="100" cy="0" resource="http%3A%2F%2Fsomeuri2"/>
	</g>
</svg>
\end{lstlisting}

\subsection{Kommentare}
\label{section:implementierung:frontend:kommentare}

Im Folgenden wird auf die Implementierung der Kommentare (Abschnitt~\ref{section:konzeption:kommentare}) eingegangen. Sie erlauben es Benutzern, Erkenntnisse untereinander auszutauschen.

\subsubsection{Kommentar schreiben}

Kommentare werden über Buttons in der Titelleiste einer Komponente aufgerufen. Unterstützt eine Komponente keine Kommentare, sind die Buttons inaktiv. In Abbildung~\ref{figure:ui-write-comment} ist zu sehen, wie ein Kommentar verfasst wird. Um den Bereich um die Visualisierung herum abzudunkeln, wird ein SVG-Element in die Komponente eingefügt. Es enthält eine Maske\footnote{\url{https://developer.mozilla.org/en-US/docs/Web/SVG/Tutorial/Clipping_and_masking}}, welche die Visualisierung freistellt.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.75\textwidth]{images/implementierung-ui-write-comment.png}
   \caption{User Interface um einen Kommentar zu verfassen}
   \label{figure:ui-write-comment}
\end{figure}

Auf diesem SVG Element kann der Benutzer wie in gängigen Zeichenprogrammen üblich Rechtecke und Pfeile zeichnen. Um Text hinzuzufügen, muss er zuerst auf den Visualisierungsbereich klicken und damit die Koordinaten festlegen, an denen der Text erscheinen soll. Danach öffnet sich ein Texteingabedialog und nachdem der Benutzer bestätigt hat, wird der Text ins SVG Element gezeichnet. Der Text kann später editiert oder wie alle Annotationen auch gelöscht werden.

Selektionen verhalten sich etwas anders als Text, Rechtecke und Pfeile, da sie nicht mit SVG Elementen dargestellt werden. Um zu bestimmen, wann sich die Maus über einem Datenpunkt befindet, wird ein \texttt{mousemove} Event Handler eingesetzt. In diesem werden die aktuellen Mauskoordinaten sowie alle Bounding Boxes der Datenpunkte abgefragt und dann verglichen, ob sich die Koordinaten innerhalb einer Bounding Box befinden. Analog dazu arbeitet der \texttt{click} Handler, welcher Datenpunkte selektiert oder deselektiert. Die Event Handler können nicht auf den Datenpunkten selbst registriert werden, weil diese keine Mausevents auslösen, da sich das SVG Element über ihnen befindet. Das hat allerdings den praktischen Nebeneffekt, dass vom Entwickler vorgesehene Mausevents in der Visualisierung ebenfalls nicht ausgelöst werden, solange die \enquote{Kommentar schreiben} UI aktiv ist.

Nachdem der Benutzer den Kommentar bestätigt hat, werden die Koordinaten und Dimensionen der Annotationen in relative Einheiten (zur Größe der Visualisierung) umgerechnet und an das Kommentar Backend (siehe Abschnitt~\ref{section:implementierung:backend:kommentare}) gesendet.

\subsubsection{Kommentare lesen}

Um Kommentare zu lesen, muss erst ein Button in der Titelleiste der jeweiligen Komponente betätigt werden. Danach wird das entsprechende User Interface neben der Komponente angezeigt (Abbildung~\ref{figure:ui-read-comments}).

\begin{figure}[htbp]
   \centering
   \includegraphics[width=\textwidth]{images/implementierung-ui-read-comments.png}
   \caption{User Interface um Kommentare zu lesen}
   \label{figure:ui-read-comments}
\end{figure}

Die Annotationen sind verschiedene DOM Elemente, welche bei Bedarf angezeigt oder versteckt werden. Flächenbasierte Annotationen werden als SVG \texttt{rect}s, \texttt{line}s und \texttt{text}s umgesetzt, deren Position relativ zur Größe der Visualisierung ist (siehe vorheriger Abschnitt).

\subsubsection{Einschränkungen}

Die Lösung, \texttt{mouseover} über Datenpunkten mit Hilfe der Bounding Box festzustellen funktioniert zwar, hat aber einen Nachteil: Da die Bounding Box immer rechteckig ist, können \enquote{false positives} auftreten (Abbildung~\ref{figure:kommentar-bbox}). Variante A ist der Idealfall; die Bounding Box ist gleich groß wie die Repräsentation des Datenpunkts. Das ändert sich allerdings, wenn die Repräsentation transformiert wird (45$^\circ$ Rotation in Variante B) oder eine nicht-eckige Form hat (Kreis in Variante C).

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/implementierung-kommentar-bbox.png}
   \caption{Genauigkeit der Bounding Box eines Elements}
   \label{figure:kommentar-bbox}
\end{figure}

Eine Möglichkeit, um diese Einschränkung zu umgehen, ist eine weitere Funktion in die API einer Komponente hinzuzufügen. Sie teilt dem Hilfesystem mit, ob ein Punkt $(x,y)$ innerhalb eines Datenpunkts liegt oder nicht. Diese Funktion kann optional genutzt werden: Ist sie implementiert, verwendet sie das Hilfesystem. Ansonsten arbeitet es wie bisher mit Bounding Boxes.

Flächenbasierte Annotationen werden relativ zur Größe der Visualisierung positioniert. Das kann problematisch sein, wenn die Visualisierung genau so groß wie die Komponente ist und diese in unterschiedlicher Größe gerendert wird (siehe Abbildung~\ref{figure:area-anno}).

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.75\textwidth]{images/implementierung-area-anno.png}
   \caption{Problem von flächenbasierten Annotationen bei unterschiedlicher Visualisierungsgröße: Das Zentrum ist in beiden Visualisierungen das Jahr~1990, in der unteren ist aber ein vollkommen anderer Bereich markiert.}
   \label{figure:area-anno}
\end{figure}

Dieses Problem kann nicht wirklich umgangen werden, da die Komponenten \enquote{Black Boxes} sind und unbekannt ist, wie sich der Inhalt einer Visualisierung mit unterschiedlicher Größe ändert. Deswegen sollten Komponenten so weit wie möglich datenbasierte Annotationen unterstützen und, falls es aufgrund der visuellen Darstellung nicht möglich ist, den Inhalt einer Visualisierung proportional skalieren.

\subsection{Bedienung}
\label{section:implementierung:frontend:bedienung}

Dieser Abschnitt befasst sich mit der Bedienungshilfe (Abschnitt~\ref{section:konzeption:bedienung}). Mit ihr lernen Benutzer, wie sie Aktionen in Komponenten ausführen können.

Dafür wird die Komponente zunächst abgedunkelt und für Aktionen notwendige UI Elemente hervorgehoben (Abbildung~\ref{figure:ui-howto-step1}). Die Kreise unten links und oben rechts sind abgeschnitten, weil die Datenpunkte sich an der Grenze des dargestellten Datenbereichs befinden und von der SVG Maske abgeschnitten werden.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/implementierung-ui-howto-step1.png}
   \caption{Assistance zur Bedienung, Schritt 1}
   \label{figure:ui-howto-step1}
\end{figure}

Der Algorithmus, um alle eine Aktion auslösenden UI Elemente in ein anderes \texttt{div} zu kopieren, ist wie folgt: 

\begin{enumerate}
	\item Es wird ein teilweise transparentes, dunkles \texttt{div} in die Komponente eingefügt, um den dunklen Hintergrund herzustellen.
	\item Danach wird ein weiteres \texttt{div} erstellt, die \enquote{Rootcopy}. Diese hat dieselbe Größe und Position wie die Komponente.
	\item In die Rootcopy wird wiederum ein \texttt{svg} Element eingefügt, welches sie ausfüllt. Das hat den Grund, dass aktionsauslösende UI Elemente auch SVG \texttt{rect}s oder ähnliches sein können. Sie werden vom Browser nur gerendert, wenn sie sich auch in einem \texttt{svg} befinden.
	\item Damit Kopien in der Rootcopy möglichst gleich aussehen wie die Originale, werden in der Komponente gesetzte CSS Styles auf die Rootcopy übertragen.
	\item Danach werden alle von einem CSS Selektor getroffenen Elemente entweder in die Rootcopy selbst oder ins \texttt{svg} kopiert und gleich wie die Originale positioniert. Bei SVG-Elementen ist das durch die Kopie des DOM Elements schon geschehen, da ihr visueller Zustand im Markup gespeichert ist (z.\,B. in Form von \texttt{x}, \texttt{transform} oder \texttt{width} Attributen). Bei HTML Elementen werden die CSS Klassen mitkopiert. Das CSS kann allerdings Regeln enthalten, die von der Struktur des Markups abhängig sind, z.\,B. \texttt{position: relative; width: 80\%;}. Da diese in der Rootcopy nicht dasselbe Ergebnis liefern, werden Breite und Höhe noch einmal explizit gesetzt.
	\item Bei jedem durch Selektor $s_i$ getroffenen Element und dessen Kopie wird außerdem ein Attribut \texttt{data-vizboard-copy} auf \texttt{copy<i>} gesetzt. Der Grund dafür ist die Verbindung zwischen Aktionen und UI Elementen: Bei \texttt{mouseover} über einer Aktion in der Liste werden alle dafür notwendigen UI Elemente hervorgehoben. Um diese zu finden, kann der Selektor nicht in der Rootcopy ausgeführt werden: Selektoren wie z.\,B. \texttt{:nth-child(odd)} würden falsche Ergebnisse liefern. Aus diesem Grund werden die Selektoren bei \texttt{mouseover} in der Komponente ausgeführt und die Kopien der Elemente über den Wert von \texttt{data-vizboard-copy} gefunden (siehe Abbildung~\ref{figure:rootcopy}).
	\item Die aktionsauslösenden UI Elemente müssen nicht leer sein, weswegen dort gesetzte Styles auch bei Kindknoten sichtbar sein könnten, z.\,B. wenn eine CSS Property auf \texttt{inherit} gesetzt ist. Aus diesem Grund werden bestimmte CSS propertys (\texttt{border}, \texttt{color}, \texttt{background}) in den Kopien auf die Werte der Originale fixiert.
	\item Aktionsauslösende UI Elemente können andere aktionsauslösende UI Elemente enthalten. Das wäre beispielsweise der Fall, wenn das anonyme \texttt{div} in Abbildung~\ref{figure:rootcopy}, welches die \texttt{div.bar} enthält, eine dritte Aktion auslösen würde. Damit diese nicht mehrfach in der Rootcopy vorhanden sind, wird für jedes Original einer Kopie überprüft, ob es Knoten mit dem Attribut \texttt{data-vizboard-copy} enthält. Falls ja, wird ein CSS Selektor aus dem Knoten generiert und alle davon getroffenen Elemente in der Kopie gelöscht.
\end{enumerate}

\begin{figure}[htbp]
   \centering
   \includegraphics[width=\textwidth]{images/implementierung-rootcopy.png}
   \caption{Die CSS Selektoren würden in der Rootcopy falsche Treffer liefern, da sowohl die Reihenfolge als auch die Elternknoten der DOM Elemente verändert sind. Deswegen werden Originale und Kopien über das Attribut \texttt{data-vizboard-copy} verknüpft und auffindbar gemacht.}
   \label{figure:rootcopy}
\end{figure}

\subsubsection{Einschränkungen}

% highlight

In diesem Abschnitt werden die Grenzen der gewählten Strategien zur Darstellung der Bedienungshilfe aufgezeigt. Zunächst ist es so, dass die Komponente nicht abgedunkelt werden kann, wenn das relevante UI Element zu groß ist. Die Styles zur Hervorhebung werden außerdem an der Wurzel des UI Elements gesetzt. Falls diese von Kindknoten überschrieben werden, ist kein Effekt sichtbar. Außerdem ist es möglich, dass die Komponente über ihrer abgedunkelten Kopie sichtbar ist, wenn das Attribut \texttt{z-index} entsprechend gesetzt ist. Um das zu verhindern, könnte den Komponentenentwicklern von CRUISe ein Maximalwert des Attributs vorgeschrieben werden, welcher nach der Registrierung einer Komponente überprüft wird. Dieser beträgt in den meisten Browsern 2.147.483.647 \cite{Puidokas2009}, also könnte den Entwicklern immer noch ein Bereich von Null bis zwei Milliarden zur Verfügung gestellt werden. Momentan wird der \texttt{z-index} von Kopien auf 0 gesetzt und von Originalen nicht verändert.

% performance

Ein weiteres Problem der vorgestellten und implementierten Bedienungshilfe ist Performance. War das Markup der Komponente tief verschachtelt, dauerte die Generierung von Kopien der aktionsauslösenden UI Elemente bis zu 15 Sekunden. Das war bei einer ExtJS Tabelle mit Testdaten von 60~Filmen in 6~Spalten der Fall, mit größeren Datensätzen würde es noch viel länger dauern. Nach einer Inspektion mit den Chrome Developer Tools stellte sich heraus, dass eine Kombination aus exzessivem \enquote{Layout Thrashing} und häufiger Garbage Collection das Problem war. Das Layout Thrashing hatte folgende Auslöser: Zunächst musste für jedes der  Elemente die sichtbare Bounding Box berechnet werden, wofür Zugriff auf die Offsets nötig ist. Dafür wird ein aktuelles Layout benötigt, der Browser muss es also berechnen. Danach wird die Kopie in den DOM eingefügt, was das Layout invalidiert und es somit beim nächsten Element erneut berechnet werden muss. Zum Teil kann der Algorithmus bestimmt optimiert werden, aber nachdem Datensätze in VizBoard beliebig groß und Komponenten in CRUISe beliebig verschachtelt sein können, sollte auf diese Art der Darstellung verzichtet werden. Stattdessen sollten aktionsauslösende UI Elemente in ihrer normalen Kontext hervorgehoben werden, ohne aufwändige Erstellung von Kopien.

% panels

Auch die Darstellung von Panels unterliegt gewissen Einschränkungen. Abbildung~\ref{figure:ui-howto-step2} zeigt die Bedienungshilfe für ein Liniendiagramm. Positiv zu bewerten ist, dass die Bilder quadratisch sind und so die Panels ausfüllen. Allerdings ist das Ergebnis der Aktion (der Kreis ist orange gefüllt) im dritten Panel nur sehr schwer zu erkennen. Unter Umständen sollte doch wieder wie im Konzept ursprünglich vorgesehen, aber nach der formativen Nutzerstudie verworfen, ein viertes Panel am Anfang eingefügt werden. Dieses sollte den Ursprungszustand der Komponente darstellen und so ähnlich wie bei einem Suchbild zum Vergleich dienen. Eine andere Möglichkeit wäre die Panels zu vergrößern, was aber nur in Maßen möglich ist und nicht sehr viel Wirkung zeigen wird.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/implementierung-ui-howto-step2.png}
   \caption{Assistance zur Bedienung, Liniendiagramm}
   \label{figure:ui-howto-step2}
\end{figure}

In Abbildung~\ref{figure:ui-howto-step2-bad} ist die SIMILE Timeline\footnote{\url{http://www.simile-widgets.org/timeline/}} als Negativbeispiel zu sehen. Das relevante Element ist so groß wie die Komponente selbst und hat mit mehr als~6.5 ein recht extremes Seitenverhältnis, weswegen sie das quadratische Panel nur unzureichend ausfüllt. Die dargestellte Komponente ist außerdem so programmiert, dass sie ihren Zustand kaum merklich verändert.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=\textwidth]{images/implementierung-ui-howto-step2-bad.png}
   \caption{Assistance zur Bedienung, SIMILE Timeline}
   \label{figure:ui-howto-step2-bad}
\end{figure}

Eine mögliche Lösung wäre, das quadratische Panel immer zu füllen. Dann stellt sich allerdings die Frage, welcher Ausschnitt des Bilds gezeigt und wie dieser bestimmt und gefunden werden soll. Füllt man beispielsweise von links, sähe man in diesem Beispiel in allen Bildern hauptsächlich graue Fläche. Dem Problem könnte auch beigekommen werden, wenn die Panels das Seitenverhältnis ihrer Bilder annähmen. Allerdings ist das Layout der Panels dann unvorhersehbar. Ein Kompromiss könnte sein, die Panels quadratisch zu lassen und die Bilder füllend darzustellen, aber es dem Benutzer zu ermöglichen, innerhalb der Panels zu scrollen. Da aber hier die Interaktion etwas kompliziert würde, sollte zunächst ein passender Layoutalgorithmus versucht werden. Er sollte sowohl das Seitenverhältnis der einzelnen Bilder möglichst beibehalten, als auch einem Comic ähneln. Dass ein ansprechenderes Layout als aneinandergereihte Quadrate nötig ist, wurde schon in der formativen Nutzerstudie klar. 

\subsection{Kommunikation}
\label{section:implementierung:frontend:kommunikation}

Im Folgenden wird auf die Hilfe zur Kommunikation zwischen Komponenten (Abschnitt~\ref{section:konzeption:kommunikation}) eingegangen. Sie ist im Prinzip eine Erweiterung der Bedienungshilfe (Abschnitt~\ref{section:implementierung:frontend:bedienung}), da sie jeweils das Panel mit dem Ergebnis einer Aktion in einer Komponente zeigt. Die Kommunikationshilfe wurde in den CapView von EDYRA \cite{Radeck2013} integriert, da dieser bereits Verbindungen zwischen Komponenten anzeigen kann (Abbildung~\ref{figure:ui-capview}).

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/implementierung-ui-capview.png}
   \caption{Erweiterter CapView}
   \label{figure:ui-capview}
\end{figure}

Dazu wird das schwarze Fragezeichen in der Methode \texttt{drawPath} im ConnectionManager des CapView, welche die Verbindungen zwischen Capabilities von Komponenten zeichnet, erstellt und hinzugefügt. In Abbildung~\ref{figure:ui-communication} ist die Kommunikationshilfe zwischen SIMILE Timeline und Liniendiagramm zu sehen.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/implementierung-ui-communication.png}
   \caption{Assistance zur Kommunikation}
   \label{figure:ui-communication}
\end{figure}

\section{Backend}
\label{section:implementierung:backend}

Die folgenden Abschnitte behandeln das Backend des Prototypen. Sie adressieren Kommentare (Abschnitt~\ref{section:implementierung:backend:kommentare}) und Bedienung und Kommunikation (Abschnitt~\ref{section:implementierung:backend:bedienung}). Das Backend ist sowohl im CoRe (Bedienung/Kommunikation) als auch im DaRe (Kommentare) angesiedelt.

\subsection{Kommentare}
\label{section:implementierung:backend:kommentare}

Das Backend der Kommentare wurde ins Data Repository integriert, da dort bereits Datensätze gespeichert werden und eine entsprechende Infrastruktur existiert. Im Folgenden wird auf die Art der Persistierung, die Architektur und die REST API desselben eingegangen.

\subsubsection{Repository}

In der Konzeption der Kommentare (Abschnitt~\ref{section:konzeption:kommentare}) wurde das Data Repository als geeigneter Speicherort identifiziert. Dieses enthält durch Metainformationen erweiterte semantische Datensätze, die im Frontend von Komponenten geladen und visualisiert werden können. Aus diesem Grund wurde für Kommentare ein eigenes Modell angelegt, sodass sie von \enquote{regulären} Daten getrennt sind.

Zwischen Front- und Backend wird ein Kommentar auf verschiedene Weise serialisiert (Abbildung~\ref{figure:kommentare-backend}). Das webbasierte Frontend kann JSON am besten verarbeiten, das DaRe Backend ist in Java geschrieben und arbeitet mit einem Jena TDB Triplestore, wo Kommentare letztendlich abgelegt werden. Zwar könnte das Backend ausschließlich zwischen JSON und RDF konvertieren, aber so ist es möglich bestehende Java-Bibliotheken für verschiedene Zwecke (wie z.\,B. Textklassifikation) einzusetzen.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.75\textwidth]{images/implementierung-kommentare-backend.png}
   \caption{Verschiedene Serialisierungen eines Kommentars}
   \label{figure:kommentare-backend}
\end{figure}

Die verschiedenen Serialisierungsformate sind im Anhang zu finden.

\subsubsection{Architektur}

Die Architektur des Backends für Kommentare orientiert sich an den verschiedenen notwendigen Serialisierungen eines Kommentars (siehe vorhergehender Abschnitt). Sie besteht aus drei Klassen, die dem \enquote{Separation of Concerns} Prinzip folgend genau eine Zuständigkeit haben:

\begin{itemize}
	\item Der \textbf{CommentRequestHandler} nimmt HTTP Requests entgegen und leitet sie an das CommentBackend weiter.
	\item Das \textbf{CommentBackend} stellt das Interface zum Triplestore dar, in dem die Kommentare abgelegt werden.
	\item Der \textbf{CommentConverter} setzt zwischen verschiedenen Serialisierungen eines Kommentars (JSON, RDFS, Java) um.
\end{itemize}

Abbildung~\ref{figure:kommentare-backend-architektur} zeigt die Architektur am Beispiel eines \texttt{GET} Requests des Frontends. Braun eingefärbte Kästchen stellen Java Klassen im Backend dar.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.75\textwidth]{images/implementierung-kommentare-backend-architektur.png}
   \caption{Architektur des Kommentar Backends}
   \label{figure:kommentare-backend-architektur}
\end{figure}

Folgende Schritte werden durchlaufen:

\begin{enumerate}
	\item Das Frontend sendet einen \texttt{GET} Request an das Backend, welcher vom Comment Request Handler behandelt wird.
	\item Der Request Handler ruft die Methode des Comment Backends auf, welche Kommentare im Datensatz sucht.
	\item Das Comment Backend startet eine Jena TDB Transaktion.
	\item Mit Hilfe der Jena API erstellt das Comment Backend eine semantische Repräsentation der Kommentare.
	\item Das Comment Backend übergibt die RDFS Kommentare dem Comment Converter.
	\item Der Comment Converter konvertiert diese in eine Liste von Java Objekten.
	\item Das Comment Backend gibt diese Liste zurück an den Request Handler.
	\item Dieser ruft noch einmal den Converter auf, um eine JSON Repräsentation der Kommentare zu bekommen.
	\item Der Converter konvertiert Java Objekte in einen JSON String.
	\item Der Request Handler sendet den JSON String an das Frontend.
\end{enumerate}

Es spricht natürlich nichts dagegen in solchen Fällen ein Kommentar direkt von RDF in JSON zu konvertieren, ohne den Umweg über Java. Im Prototyp wurde darauf aber verzichtet, da es nur zusätzliche Schreibarbeit dargestellt und keinen merkbaren Nutzen gebracht hätte.

\subsubsection{REST API}

Um Kommentare dem Frontend zur Verfügung zu stellen, bot sich eine REST API an, da kein Zustand gespeichert werden muss. Eine SOAP Schnittstelle kam nicht in Frage, da das DaRe bereits ein REST Schnittstelle anbietet und einfach ergänzt werden konnte. Es wurden vier Methoden implementiert:

\begin{itemize}
	\item \texttt{GET dare/comment} gibt alle Kommentare aus. Sind \texttt{property} (für visualisierte propertys) oder \texttt{component} (für Komponenten) Query Parameter vorhanden, wird nach diesen gefiltert und Kommentare gesucht, die mindestens ein Kriterium erfüllen.
	\item \texttt{GET dare/comment/\{id\}} gibt Kommentar mit ID \texttt{id} aus.
	\item \texttt{POST dare/comment} nimmt ein Kommentar in \texttt{application/json} entgegen, speichert es ab und antwortet im Erfolgsfall mit Statuscode \texttt{201 Created}.
	\item \texttt{PUT dare/comment/vote/\{id\}} nimmt ein JSON Objekt entgegen und setzt die Anzahl an angegebenen Stimmen. Ist kein \texttt{Authorization} Header vorhanden, antwortet die Methode mit \texttt{401 Unauthorized}. Hat der Benutzer schon einmal diese Anzahl an Stimmen abgegeben, ist die Antwort \texttt{403 Forbidden} und ansonsten \texttt{200 OK}. Auf diese Weise ist \texttt{PUT} wie von RFC 2616 \cite{W3C:rfc2616} gefordert idempotent.
	\item \texttt{DELETE dare/comment/\{id\}} löscht den Kommentar mit ID \texttt{id} aus dem Datensatz. Der \texttt{Authorization} Header muss den Benutzer enthalten, der den Kommentar erstellt hat.
\end{itemize}

Die beiden \texttt{GET} Methoden nehmen optional einen HTTP \texttt{Authorization} Header entgegen, der die Benutzer ID (ohne Passwort) angibt. Dann enthalten zurückgelieferte Kommentare Informationen, ob dieser Benutzer schon gevotet hat und wenn ja, wie.

Bei der Methode \texttt{PUT dare/comment/vote} überprüft das DaRe nur die Existenz eines \texttt{Authorization} Headers und erstellt einen neuen Benutzer im Kommentar Backend, wenn dieser unbekannt ist. Die Methode \texttt{POST} kann ohne Credentials aufgerufen werden. In der Praxis müsste der Header Benutzer ID und Passwort enthalten, sodass das DaRe diese Daten überprüfen kann, indem es eine entsprechende Anfrage an die REST API des User Services stellt. Auf diese Weise würde verhindert, dass beliebige Personen Kommentare erzeugen oder bewerten können. Da die Benutzerinformationen im \texttt{Authorization} Header mit Base64 \cite{Josefsson2006} kodiert und nicht verschlüsselt o.\,ä. werden, sollte die Kommunikation zwischen DaRe und Frontend außerdem mit Transport Layer Security gesichert sein.

\subsection{Bedienung und Kommunikation}
\label{section:implementierung:backend:bedienung}

Das Backend zur Generierung und Auslieferung der Bilder für die User Assistance wurde im CoRe integriert, da dort Komponenten registriert und gespeichert werden. Die folgenden Abschnitte behandeln seine Architektur, die Erweiterungen der SMCDL, den Generierungsalgorithmus und die zur Verfügung gestellte API.

\subsubsection{Architektur}

Abbildung~\ref{figure:bedienung-backend} zeigt, wie die Bilder für das Hilfesystem im Backend generiert werden. Sobald der Entwickler eine neue Komponente im CoRe registriert, validiert das CoRe diese und transformiert sie in ein semantisches Modell (MCDO). Danach startet das CoRe den Generierungsservice (Assistance Generator). Dieser erstellt eine JSON Datei mit den notwendigen Informationen aus der SMCDL, beispielsweise welche Aktionen (Capabilities) wie ausgeführt werden, und eine HTML Datei, die alle notwendigen Resourcen, wie etwa Stylesheets und Skripte, enthält. Die JSON und HTML Datei wird an PhantomJS übergeben, welches die Informationen einliest und Screenshots der Komponente erstellt. Testdaten werden von einer in der SMCDL angegebenen URL geladen (siehe Abschnitt~\ref{section:konzeption:bedienung:api}). Die bereits bestehende SOAP API des CoRe wurde so erweitert, dass das Hilfesystem auf die URLs der Bilder zugreifen kann. Dafür ist der Assistance Service zuständig.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.75\textwidth]{images/implementierung-bedienung-backend.png}
   \caption{Generierung der Bilder für das Hilfesystem}
   \label{figure:bedienung-backend}
\end{figure}

Auf die einzelnen Bestandteile des Vorgangs wird im Folgenden näher eingegangen.

\subsubsection{SMCDL}

Die SMCDL wurde erweitert, sodass Entwickler die wichtigen Interaktionen in ihrer Komponente annotieren können. Dazu wurden Elemente für atomare, sequentielle und parallele Operationen eingefügt. Mit Hilfe des Attributs \texttt{generateAssistance} signalisiert der Entwickler, dass für die entsprechende Capability Hilfe generiert werden soll. Das optionale Attribut \texttt{wait} teilt dem Hilfeservice mit, wie lange nach dem Ausführen der VISO Operationen gewartet werden soll, bevor er einen Screenshot erstellt. VISO Operationen entsprechen Nutzeraktionen wie klicken, draggen oder scrollen und sind nicht mit CRUISe Operationen einer Komponente zu verwechseln.

Eine atomare Operation besteht aus einem Element mit folgenden Attributen (Listing~\ref{code:smcdl-ui}):

\begin{itemize}
	\item \texttt{id} ist zur Unterscheidung von anderen Operationen nötig.
	\item \texttt{element} gibt einen CSS Selektor an, mit dem die UI Elemente gefunden werden können. welche die Aktion auslösen.
	\item \texttt{type} gibt die VISO Operation an. Zur Zeit werden die Mausoperationen Klick, Doppelklick, Move, Drag und Scroll unterstützt.
	\item \texttt{modifier} konkretisiert die Operation, indem es z.\,B. angibt, welche Maustaste verwendet werden soll.
\end{itemize}

Um zusätzlich angeben zu können, wie weit der Hilfeservice scrollen soll, kann der atomaren Operation ein JSON Objekt mit den Attributen \texttt{dx} und \texttt{dy} zur Verfügung gestellt werden (Listing~\ref{code:smcdl-system}). Dafür wurde das Element \texttt{exampledata} so angepasst, dass es in einer VISO Operation enthalten sein kann. Im Kontext von Klickoperationen geben diese Informationen den Abstand vom Zentrum des Elements an.

\lstset{language=XML}
\begin{lstlisting}[caption={SMCDL für UI Capability}, label=code:smcdl-ui]
<capability
	id="capPan"
	activity="actions:Pan"
	entity="travel:Event"
	wait="2s"
	generateAssistance="true">
	
	<atomicoperation
		id="panByDblClick"
		element="div.background"
		type="op:DoubleClick"
		modifier="op:LeftButton">
		<exampledata>{ 'dx': -500, 'dy': 0 }</exampledata>
	</atomicoperation>
</capability>
\end{lstlisting}

Falls der Entwickler keine Hilfe wünscht, müssen keine Elemente außer \texttt{capability} und dessen Attribute \texttt{id}, \texttt{activity} und \texttt{entity} angegeben werden. Soll für diese Capability Hilfe generiert werden, müssen \texttt{generateAssistance} und die \texttt{atomicoperation} ohne \texttt{exampledata} unbedingt angegeben werden. 

Falls die Capability nicht vom Benutzer (UI Capability), sondern von der Komponente ausgeführt wird (System Capability), enthält \texttt{capability} Beispieldaten, die an die entsprechende Operation der Komponente weitergegeben werden.

\lstset{language=XML}
\begin{lstlisting}[caption={SMCDL für System Capability}, label=code:smcdl-system]
<operation
	name="highlightPoint">
	
	<capability
		id="capHighlight"
		activity="action:brushAction"
		entity="travel:Event"
		provider="system"
		generateAssistance="true">
		
		<exampledata>{ 'uri': 'http://mmt.inf.tu-dresden/vizBoard/SimileTimelineTestData#event1' }</exampledata>
	</capability>
	
	<parameter
		name="uri"
		type="xs:string" />
	
</operation>
\end{lstlisting}

Damit die Komponente während der Hilfegenerierung auch tatsächlich Daten anzeigt, muss der Komponentenentwickler in der SMCDL eine URL zu Testdaten angeben (Listing~\ref{code:smcdl-testdata}). Dafür wurde ein weiteres Element \texttt{testdata} hinzugefügt. Es kann entweder eine \texttt{url} zu Testdaten enthalten, welche vor der Hilfegenerierung abgerufen werden, oder aus einer Datensatz ID des DaRe (\texttt{darefileid}) und einer SPARQL Query (\texttt{mapping}) bestehen, welche die zu ladenden Daten definieren.

\lstset{language=XML}
\begin{lstlisting}[ caption={SMCDL für Testdaten}, label=code:smcdl-testdata ]
<testdata>
	<url>http://entwicklerseite.com/testdata/Testdata.json</url>
</testdata>
\end{lstlisting}

Zur Laufzeit und während der Hilfegenerierung muss das Hilfesystem Komponenten in zuvor gespeicherte Zustände zurücksetzen können. Dazu wird das Memento verwendet, welches eine Menge von Propertys ist, deren Werte gespeichert werden müssen. Um anzugeben, welche propertys einer Komponente Teil ihres Mementos sind, kann der Entwickler diese mit einem Attribut \texttt{isMemento} versehen (Listing~\ref{code:smcdl-memento}). Sie unterscheiden sich von \texttt{required} Propertys, die zur Initialisierung der Komponente unbedingt gesetzt sein müssen, weil bei Mementos eben das nicht der Fall ist: Eine Property \texttt{sorted}, welche angibt wonach eine Tabelle aktuell sortiert ist, muss bei der Initialisierung nicht bekannt, aber dennoch Teil des Mementos sein.

\lstset{language=XML}
\begin{lstlisting}[ caption={SMCDL für Memento}, label=code:smcdl-memento ]
<property name="highlighted" required="false" isMemento="true" type="xs:string" />
\end{lstlisting}

Im Konzept wurde festgelegt, dass Komponenten keine externen Daten laden oder selbst Datenverarbeitung durchführen dürfen, falls sie Kommentare unterstützen wollen. Für die History ist es notwendig zu wissen, ob das CSS einer Komponente auf relativen Einheiten basiert. Diese Informationen werden am Wurzelelement in der SMCDL als Attribute angegeben (Listing~\ref{code:smcdl-zusatz}).

\lstset{language=XML}
\begin{lstlisting}[ caption={SMCDL für Zusatzinformationen}, label=code:smcdl-zusatz ]
<component
	id="http://cruise/ui/SimileTimeline"
	name="SimileTimeline"
	version="1.0"
	isUI="true"
	doesDataProcessing="false"
	loadsExternalData="false"
	hasRelativeStyle="false">
\end{lstlisting}

Die vorgestellten zusätzlichen Elemente und Attribute der SMCDL wurden zusätzlich auch als semantische Konzepte in der MCDO modelliert. Im nächsten Abschnitt wird gesondert auf die VISO Operationen eingegangen, da diese die größte Neuerung darstellen.

\subsubsection{VISO Operationen}

Um Nutzeraktionen semantisch darstellen zu können, wurde eine kleine Ontologie dafür erstellt (Abbildung~\ref{figure:activity-ops}), welche hauptsächlich Desktopinteraktionen nachempfunden ist. Sie besteht aus den zwei Klassen Operation und Modifier, wobei eine Operation eine Aktion beschreibt (z.\,B. klicken) und der optionale Modifier die Details liefert (z.\,B. welche Maustaste). Jede der Klassen hat Subklassen für jedes Eingabegerät, momentan Maus und Tastatur. Soll die Ontologie in Zukunft auch Touchinteraktionen beschreiben, müssen zwei Klassen \texttt{TouchOperation} und \texttt{TouchModifier} eingefügt werden. \texttt{TouchOperation} würde die Geste beschreiben, also etwa Touch, Pinch oder Swipe. Ein \texttt{TouchModifier} könnte etwa die Anzahl der verwendeten Finger festlegen.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/implementierung-activity-ops.png}
   \caption{Die \texttt{activity-operations} Ontologie}
   \label{figure:activity-ops}
\end{figure}

Folgende Instanzen sind aktuell in der Ontologie vorhanden:

\begin{itemize}
	\item MouseOperation: Click, DoubleClick, Move, Scroll, Drag.
	\item MouseModifier: LeftButton, MouseWheel, RightButton.
	\item KeyboardOperation: TypeOperation
	\item KeyboardModifier: AltKey, BackspaceKey, ReturnKey, CommandKey, ControlKey, ShiftKey, SpaceKey.
\end{itemize}


\subsubsection{Assistance Generator \& PhantomJS}

% phantomjs wird vom assistancegenerator (java) gestartet
% vorher html datei erstellen (skeleton.html)
% und notwendige infos so rausschreiben, dass sie phantom lesen kann (mcdl.json)

Bevor der Assistance Generator die PhantomJS Binary startet, erzeugt er eine Datei \texttt{mcdl.json}. Dort werden alle zur Generierung wichtigen Informationen gespeichert, zum Beispiel die Capabilities, Testdaten und das Memento der Komponente. Außerdem wird eine Datei \texttt{skeleton.html} erstellt, welche alle Abhängigkeiten der Komponente enthält. Wenn keine Abhängigkeit von jQuery angegeben wurde, wird es ebenfalls geladen. Diese Dateien werden zusammen mit anderen Informationen (z.\,B. dem Pfad zu den Dateien) an PhantomJS weitergegeben, welches das Generierungsskript \texttt{generate.js} startet.

Das Skript liest die Informationen der \texttt{mcdl.json} ein und führt den in \texttt{generate.js} enthaltenen Algorithmus aus:

\begin{enumerate}
	\item Zunächst wird der Konstruktor der Komponente sowie die Operationen \texttt{enable} und \texttt{show} aufgerufen.
	\item Danach wird ein Memento vom initialen Zustand der Komponente abgerufen, um diesen später wiederherstellen zu können.
	\item Die Testdaten der Komponente werden geladen, indem selbige aus der \texttt{mcdl.json} über die Methode \texttt{loadTestdata} an die Komponente gegeben werden.
	\item Es werden sequentiell für alle Capabilities Screenshots generiert. Die Größe der Bilder entspricht dabei den in der SMCDL angegebenen \texttt{default} Werten für Breite und Höhe einer Komponente. Es wird nacheinander jeweils die erste atomare Operation jeder (UI) Capability behandelt. Für den Prototypen wurde hier auf sequentielle und parallele Operationen verzichtet, sie stellen aber nur eine Erweiterung des umgesetzten Prinzips dar und können bei Bedarf einfach implementiert werden.
\end{enumerate}

Ist die aktuell Behandelte eine UI Capability, werden die dazugehörigen UI Elemente mit dem CSS Selektor aus der SMCDL gefunden, hervorgehoben und die Bounding Box des ersten Elements abgefragt. Danach wird ein Screenshot der Komponente erstellt und als PNG Datei abgespeichert. Der Dateiname setzt sich aus der ID der Operation und der Bounding Box im Format \texttt{XxYxWxH} zusammen, also beispielsweise \texttt{clickButton-12.5x12.5x50x50.png}. Das Bild wird in einem Ordner, der nach der ID der Capability benannt ist, abgelegt (z.\,B. capSelect in Abbildung~\ref{figure:ordner}). Danach wird das CSS der hervorgehobenen DOM Elemente zurückgesetzt und die VISO Operation (also z.\,B. ein Klick) auf dem ersten der Elemente ausgeführt. Das Hilfesystem wartet die angegebene Anzahl von Sekunden, bevor es ein letztes Bild \texttt{result.png} erstellt und im Ordner der Komponente ablegt.

Handelt es sich um eine System Capability, sind keine UI Elemente beteiligt. In diesem Fall wird nur die CRUISe Operation mit den angegebenen Beispieldaten ausgeführt und danach ein Screenshot \texttt{result.png} erstellt.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.4\textwidth]{images/implementierung-ordner.png}
   \caption{Beispielhafte Ordnerstruktur einer Komponente im Assistance Generator}
   \label{figure:ordner}
\end{figure}

Nachdem die Generierung der Screenshots abgeschlossen ist, wird der Assistance Service darüber informiert, wo der Ordner mit den Bildern der behandelten Komponente liegt. Er kopiert die Bilder ins öffentliche Verzeichnis (siehe nächster Abschnitt), von wo sie für das Frontend erreichbar sind.

\subsubsection{API}

Damit das Frontend des Hilfesystems auf die generierten Bilder zugreifen kann, wurde die SOAP API des CoRe entsprechend erweitert. Die Methode \texttt{getImagesByComponentAndCapability} nimmt eine \texttt{componentId} und eine \texttt{capabilityId} entgegen und antwortet mit den Pfaden zu den gewünschten Bildern im JSON Format (Listing~\ref{code:soap-images}). Diese sind relativ zum öffentlich zugänglichen CoRe Ordner des Servers. Das Attribut \texttt{bbox} gibt dabei die Bounding Box der relevanten Elemente relativ zur Größe des Bildes in der Form $[ x, y, w, h ]$ an. Sie wird aus dem Dateinamen des Bildes extrahiert und ist notwendig, um im Frontend auf den gewünschten Teilbereich zoomen zu können.

\lstset{language=json}
\begin{lstlisting}[caption={Antwort des SOAP Interfaces}, label=code:soap-images]
{
	"result": "assistanceImgs/<id>/capPan/result.png",
	"operations": {
		"dragBand": {
			"type": "atomic",
			"id": "dragBand",
			"label": "Drag",
			"bbox": [ 0,	0, 100, 69.167 ],
			"url": "assistanceImgs/<id>/capPan/dragBand-0x0x100x69.167.png"
	}
}
\end{lstlisting}

\section{Zusammenfassung}
\label{section:implementierung:zusammenfassung}

%#####################################################

\chapter{Evaluation}
\label{chapter:evaluation}

Nachdem basierend auf dem Szenario, den Grundlagen und dem Konzept ein Prototyp entwickelt wurde, wird in diesem Abschnitt dessen Tauglichkeit überprüft. Das Hilfesystem soll drei Aufgaben erfüllen:

\begin{enumerate}
	\item Es soll dem Benutzer erleichtern, Komponenten verschiedener Entwickler zu bedienen (Abschnitte \ref{section:konzeption:intro}, \ref{section:konzeption:bedienung}, \ref{section:konzeption:feedback}, \ref{section:konzeption:kommunikation}, \ref{section:konzeption:history}, \ref{section:konzeption:meta-hilfe}).
	\item Es soll dem Benutzer helfen, die in den Komponenten dargestellten Informationen zu verstehen und Erkenntnisse zu gewinnen (Abschnitte \ref{section:konzeption:verlinkung}, \ref{section:konzeption:kommentare}).
	\item Gleichzeitig soll dem Komponentenentwickler die Möglichkeit gegeben werden, seine Komponenten schnell und einfach in das Hilfesystem zu integrieren.
\end{enumerate}

Im nächsten Abschnitt wird untersucht, ob Aufgabe~1 erfüllt wird. Abschnitt~\ref{section:evaluation:entwicklungsaufwand} behandelt Aufgabe~3. Da Aufgabe~2 im Prototypen durch Kommentare umgesetzt wird, kann für sie keine qualitative Evaluation durchgeführt werden. Maximal würde das Leseverständnis der Testpersonen überprüft. Durch die Implementierung im Prototypen wurde aber die Machbarkeit dieser Aufgabe des Konzepts nachgewiesen.

\section{Nutzerstudie}
\label{section:evaluation:nutzerstudie}

Das Hilfesystem soll die Effektivität und Effizienz der Nutzung eines Mashups erhöhen. Ziel ist nun zu überprüfen, wie das Hilfesystem angenommen wird und ob es verständlich genug ist. Zehn Teilnehmer verwendeten dieselbe Mashup Komposition und mussten fünf Fragen beantworten, deren Lösung mehr oder weniger offensichtlich ist. Währenddessen wurde falls notwendig nachgefragt, ob die Erklärungen verständlich sind, ob etwas anderes erwartet wurde und ob eine andere Darstellung der Hilfe mehr geholfen hätte. Es wurden Effizienz- und Effektivitätsmetriken in Form der benötigten Zeit zur Lösung und der Korrektheit der Lösung für jede Frage aufgenommen.

\subsection{Mashupkomposition}

Die Teilnehmer benutzten ein Mashup aus drei Komponenten (Abbildung~\ref{figure:objekt}): Eine SIMILE Timeline, ein Liniendiagramm und eine Tabelle. 

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.75\textwidth]{images/evaluation-objekt.png}
   \caption{Objekt der Nutzerstudie}
   \label{figure:objekt}
\end{figure}

Als Datensatz wurden die ersten 60~Filme (alphabetisch sortiert) aus der DBpedia verwendet. Jeder Film hatte folgende Attribute: Titel, Beschreibung, Wikipedia Link, Budget, Einnahmen, Datum der Veröffentlichung, Studio. Eine Selektion in der Tabelle hatte Hervorhebungen in den anderen zwei Komponenten zur Folge, ein Selektion in der Timeline passte das Liniendiagramm an.

\subsection{Aufgaben}

Die Teilnehmer sollten folgende Aufgaben lösen:

\begin{enumerate}
	\item \enquote{Wann erschien der Film Ever After (Jahr, Monat, Tag)?} Zur Lösung dieser Aufgabe mussten sie den Film zuerst in der Tabelle und danach in der Timeline auswählen oder direkt in der Timeline danach suchen und auswählen.
	\item \enquote{War Chaplin im Vergleich zu anderen Filmen in diesem Zeitraum eher länger oder eher kürzer?} Die Teilnehmer mussten den Film Chaplin auswählen und im Liniendiagramm seine vertikale Position ablesen.
	\item \enquote{Welcher Film wurde am drittbilligsten produziert?} Um diese Frage zu lösen, mussten die Teilnehmer die Tabelle nach Budget sortieren. Für manche ist das intuitiv, andere sollten dazu die Hilfe benötigen.
	\item \enquote{Wer führte bei Big Night Regie?} Hier musste der Film ausgewählt und seine Beschreibung gelesen werden.
	\item \enquote{Welcher der beiden Filme ist länger: Cassandras Dream oder Gaby: A true story?} Diese Frage ist die schwierigste von allen. Die gedachte Lösungsstrategie ist wie folgt: Zuerst müssen die beiden Filme ausgewählt werden, um sie im Liniendiagramm zu finden. Selbiges musste dann ungefähr auf den Teilbereich der beiden Filme gezoomt werden, sodass die vertikale Position genauer abgelesen und die Filme verglichen werden können.
\end{enumerate}


% ein paar aufgaben, zwischen 3 und 5, die nicht ganz offensichtlich sind. abhängigkeiten zwischen komponenten wären eine variante (zb highlight in linechart nur über tabelle) oder versteckte funktionen (doppelklick to pan, anyone?). 3 aufgaben mind., zwei ist ne komische zahl.
% zeitlimit 2 minuten pro aufgabe
% vorher grob erklären, dann und währenddessen keine fragen
% effektivität und effizienz messen (wie effizienz?), für joy of use SUS fragebogen danach

\subsection{Teilnehmer}

Die Teilnehmer der Nutzerstudie wurden im Starbucks in der Prager Straße in Dresden (Abbildung~\ref{figure:location}) zufällig ausgewählt. Sie waren zwischen~18 und 53~Jahren alt (Durchschnitt 30.3~Jahre, Median 27.5~Jahre, Standardabweichung 10.84~Jahre) und zu 60~\% weiblich (siehe Tabelle~\ref{table:evaluation-teilnehmer}). Als Gegenleistung für ihre Zeit bekamen sie einen Gutschein über 5~Euro.

\begin{table}[htbp]
	\centering
    \begin{tabular}{c|c|c|c|c}
    Teilnehmer   & Geschlecht & Alter & Domäne/Beruf & Englisch	 \\
    \hline
    Teilnehmer 1 & M          & 30    & Fachberater 			& B2 \\ 
    Teilnehmer 2 & W          & 28    & Krankenpflegerin 		& B1 \\ 
    Teilnehmer 3 & W          & 18    & Studentin  			& B1 \\ 
    Teilnehmer 4 & M          & 20    & Student  				& B2 \\ 
    Teilnehmer 5 & M          & 27    & IT 					& C1 \\ 
	Teilnehmer 6 & M          & 26    & IT 					& A1 \\ 
	Teilnehmer 7 & W          & 22    & Studentin (Psychologie)& C1 \\ 
	Teilnehmer 8 & W          & 42    & Bürokauffrau 			& A1 \\ 
	Teilnehmer 9 & W          & 53    & Grundschullehrerin 	& A1 \\ 
	Teilnehmer 10 & W         & 37    & Betriebswirtin 		& B1 \\ 
    \end{tabular}
    \caption{Teilnehmer der Nutzerstudie}
    \label{table:evaluation-teilnehmer}
\end{table}

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.75\textwidth]{images/evaluation-location.jpg}
   \caption{Ort der Nutzerstudie}
   \label{figure:location}
\end{figure}

\subsection{Durchführung}

Zunächst wurde den Teilnehmern der Studie grob erklärt, was ein Mashup ausmacht: Es gäbe verschiedene Fenster, welche dieselben Daten auf unterschiedliche Weise darstellen. Außerdem bestünden Zusammenhänge zwischen diesen Fenstern in dem Sinne, dass sie auf Änderungen in anderen Fenstern reagierten und sich anpassten. Jedoch gelte das nicht für alle Fenster und nicht in jede Richtung. Danach wurden sie über die zu lösenden Aufgaben aufgeklärt. Die Teilnehmer wurden gebeten, dass sie, falls sie nicht weiter wissen, die Hilfefunktionen nutzen sollten anstatt lange zu probieren. Sie wurden auf die Bedienungs- und Kommunikationshilfe aufmerksam gemacht und erhielten außerdem den Hinweis, dass sie währenddessen nachfragen dürften um eine der Hilfefunktionen zu finden.

Danach wurden sie gebeten, die fünf Fragen zu beantworten. Dazu verwendeten sie das vorgestellte Mashup auf einem Macbook Air (13~Zoll, Mid 2012). Es wurde keine Maus zur Verfügung gestellt, die Teilnehmer benutzten das Touchpad des Notebooks. Für jede Aufgabe wurde die Zeit gestoppt und festgehalten, ob sie eine Hilfefunktion verwendeten. Danach füllten die Teilnehmer einen Fragebogen mit allgemeinen Informationen (Alter, Beruf, Geschlecht, Sprachniveau Englisch) und einen SUS \cite{Brooke1996} Fragebogen aus. Das \enquote{System}, welches in den SUS Fragen angesprochen wird, referenzierte dabei VizBoard als Ganzes, inklusive Hilfesystem. Den Teilnehmern sollte nicht zugemutet werden, mental zwischen Hilfesystem und VizBoard zu trennen.

\subsection{Ergebnisse}

% nur in 30 % der fälle wurde bedienungshilfe verwendet, obwohl ich sie dazu ermuntert habe
% das kann jetzt ein paar gründe haben. einerseits ist es ja so, dass heutzutage kaum wer anleitungen liest oder eben hilfefunktionen verwendet (zumindest bei mir weil meistens weil die erwartungen eh sehr niedrig sind). alles muss intuitiv sein etc. dafür hab ich eigentlich die dyn. meta-hilfe konzipiert.
% weitere folge: technisch gesehen ist meine kontrollgruppe nicht viel anders als die treatment group
% außerdem: da, wo es eigentlich gepasst hat, dass sie die hilfe aufrufen, ist der funke nicht so richtig übergesprungen. und ansonsten scheint es nicht das gewesen zu sein, was sie erwartet haben. leider weiß ich nicht, WAS sie erwartet haben, da war ich nicht geistesgegenwärtig genug um das zu fragen

Zunächst muss festgestellt werden, dass die Teilnehmer nur in einem Drittel der möglichen Fälle (17 von 50 Fragen) die Bedienungshilfe verwendeten (Abbildung~\ref{figure:result-helptask}). Das legt den Schluss nahe, dass die Bedienungshilfe in der Praxis noch weniger aufgerufen würde, da die Teilnehmer vor der Studie dazu ermuntert wurden. Ausprobieren war bei 90~\% der Teilnehmer die bevorzugte Strategie, dabei hätte ihnen die dynamische Meta-Hilfe (Abschnitt~\ref{section:konzeption:meta-hilfe:dynamisch} im Konzept) vermutlich mehr geholfen als die statische Bedienungshilfe.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/evaluation-result-helptask.png}
   \caption{Wie viele Teilnehmer die Hilfe aufriefen, aufgeschlüsselt nach Aufgabe}
   \label{figure:result-helptask}
\end{figure}


% gängige probleme bei der bedienungshilfe
% die panels als aktionselemente verkannt, war tw. schon bei formativer studie so --> besseres layout
% wording war nicht immer super. was heißt "click left button", wenn da nur ein touchpad ohne sichtbare buttons ist? sollte vielleicht vereinfacht werden, sodass left button default modifier ist und nicht explizit erwähnt wird
% versucht die gehighlighteten elemente der hilfe zu benutzen. vielleicht hilfefenster shaky shaky wenn das passiert? um drauf hinzuweisen, dass das erst geschlossen werden muss
% und "highlight by example" funktioniert nicht so toll.

Während die Teilnehmer versuchten, die Bedienungshilfe zu verstehen, waren ein paar Missverständisse gehäuft zu beobachten. Zwei Testpersonen versuchten die Comic Panels zu klicken, wobei eine dazu durch die Beschriftung \enquote{Click Left Button} in der Mitte verleitet wurde. Dieses Verhalten zeigten auch schon Testpersonen der formativen Studie, woraus geschlossen wurde, dass ein ansprechenderes, mehr nach Comic aussehendes Layout notwendig ist.

Die Formulierung der Operation im mittleren Panel sollte klarer sein, da sie für drei Teilnehmer nicht ganz verständlich war. Für manche war sie zu genau, sie suchten beim Touchpad des Macbooks nach einer linken oder rechten Taste\footnote{Das Touchpad des Macbooks hat nur eine physische Taste. Ein Rechtsklick wird ausgelöst, nachdem diese mit zwei Fingern gleichzeitig gedrückt wurde.}. Diesen Personen hätte \enquote{Click} voll ausgereicht. Für eine andere war die Beschreibung wiederum zu ungenau, sie verkannte das linke Panel als Aktionselement. Ihr wäre mit der Beschreibung \enquote{Click Left Mouse Button} mehr geholfen, weswegen die Formulierungen möglichst genau sein sollten.

Fast die Hälfte der Teilnehmer sah sich die Bedienungshilfe an und versuchte danach auf den von der Hilfe hervorgehobenen Elementen zu arbeiten. Aus diesem Grund sollte deutlicher gemacht werden, dass diese nur eine Kopie darstellen, oder nach Klick noch einmal abgefragt werden, ob die Hilfe aufgerufen oder geschlossen werden soll.

% kommunikationshilfe wurde gar nicht verwendet, obwohl sie einigen wahrscheinlich geholfen hätte. zeichen dafür, dass dyn. hilfefkt. schon gut wären.

Nur ein Teilnehmer rief die Kommunikationshilfe auf. Die anderen hatten sie vergessen oder erhofften sich nicht viel davon, obwohl sie ihnen vermutlich geholfen hätte. Um die Benutzer stärker darauf hinzuweisen, sollte die dynamische Kommunikationshilfe umgesetzt und in einer Studie evaluiert werden. Den Testpersonen, welche die Kommunikationshilfe nicht von selber benutzten, wurde sie am Ende gezeigt. Sie war für alle verständlich, was wohl auch daran liegt, dass die Captions der Bilder einen erklärenden Satz bilden (\enquote{Select a movie to highlight a movie.}).

% vergleich von effizienz und effektivität unter teilnehmern mit/ohne hilfe pro aufgabe ist wahrscheinlich sinnlos. die leute, welche keine hilfe brauchten, hatten oft einen ungefähren plan, brauchten sie also gar nicht. natürlich sind sie schneller als die leute, welche erst die hilfe aufrufen und verstehen müssen.

% SUS score: durchwachsen

Die Ergebnisse des SUS Fragebogens sind durchwachsen, aber insgesamt positiv (Abbildung~\ref{figure:result-sus}). Der Median beträgt 73.75 (Standardabweichung 17.64), was nach \cite{Bangor2009} einem \enquote{Gut} entspricht.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/evaluation-result-sus.png}
   \caption{SUS Ergebnisse}
   \label{figure:result-sus}
\end{figure}

% 10: alle aufgaben gelöst, bei zwei deutlich länger gebraucht als median. hatte nicht verstanden, das hilfe kopie.
% 7: hat sich erst hilfe angekuckt und dann alles super gelöst, bis auf die letzte aufgabe
% 4: ist mein ausreisser nach unten, die hat weder einen plan gehabt, wie das system funktioniert noch ansatzweise eine lösungsstrategie. weiß auch gar nicht, was der geholfen hätte. weniger aufregung vielleicht.
% 2: wirkte eigentlich sehr sicher. hat auch im feedback angemerkt, dass sie es ganz cool findet

Auffällig sind die vier Teilnehmer, welche einen SUS Score von weniger als~60 vergaben. Nummer~2 wirkte während der Studie sehr sicher und merkte auch im Feedback an, dass sie das System VizBoard an sich interessant und nützlich findet. Zeitlich befand sie sich im Mittelfeld. Teilnehmerin~4 hatte kein mentales Modell dafür, wie Mashups funktionieren und konnte deswegen auch keine Lösungsstrategie planen, weswegen sie sehr lange für jede Frage benötigte. Teilnehmerin Nummer~7 sah sich erst alle Hilfefunktionen an und löste danach alle Fragen vergleichsweise schnell, bis auf die letzte auch alle korrekt. Die letzte Teilnehmerin konnte alle Aufgaben lösen, benötigte aber bei zwei davon deutlich länger als die anderen. Sie hatte Probleme zu verstehen, dass die Hilfe Kopien erstellte, auf denen sie nicht arbeiten kann.

Den Beobachtungen nach zu urteilen hätten zumindest die Bewertungen der Teilnehmerinnen~2 und~7 eigentlich besser ausfallen müssen.

\section{Entwicklungsaufwand}
\label{section:evaluation:entwicklungsaufwand}

Wie einführend erwähnt ist ein Ziel des vorgestellten Konzepts, Komponenten mit möglichst wenig Aufwand in das Hilfesystem integrieren zu können. Unter Aufwand fällt hier sowohl zeitlicher Aufwand für Planung und Umsetzung als auch Entwicklungsaufwand in Form von Lines of Code (LOC). Je größer die Codebase einer Komponente, desto höher ist der Wartungsaufwand im Laufe der Zeit.

Nun ist es nicht möglich, alle verschiedenen Varianten einer Hilfefunktion zu analysieren und zu vergleichen, weswegen beispielhaft nur ein Konzept umgesetzt wird. Als Testobjekt wird die SIMILE Timeline\footnote{\url{http://www.simile-widgets.org/timeline/}} (Abbildung~\ref{figure:simile-timeline}) eingesetzt, da sie mehr Interaktionen als nur \enquote{Auswahl} bietet.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=\textwidth]{images/evaluation-simile-timeline.png}
   \caption{SIMILE Timeline}
   \label{figure:simile-timeline}
\end{figure}

\subsection{Eigenes Hilfekonzept}
\label{section:evaluation:entwicklungsaufwand:eigeneskonzept}

Da der Autor der Arbeit sich in den Grundlagen schon mit der Präsentation und dem Aufbau von Hilfefunktionen und Erklärungen beschäftigt hat, ist er keine geeignete Testperson. Aus diesem Grund wurde ein befreundeter Medieninformatikstudent gefragt, auf welche Weise er die verschiedenen möglichen Interaktionen der SIMILE Timeline einem Benutzer erklären würde. Er entschied sich für ein animiertes GIF, welches am Anfang eingeblendet wird. Die Konzeption dauerte 11~Minuten. Der Autor hat danach die entsprechenden Bilder und die Animation erstellt (Abbildung~\ref{figure:entwicklung-gif}). Das dauerte insgesamt 22~Minuten.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.5\textwidth]{images/evaluation-entwicklung-gif.png}
   \caption{Frames des animierten GIFs}
   \label{figure:entwicklung-gif}
\end{figure}

Die Integration in die Komponente dauerte weitere 10~Minuten und benötigte 8~Zeilen (Listing~\ref{code:integration-gif}).

\lstset{language=Java}
\begin{lstlisting}[caption={Integration des GIFs}, label=code:integration-gif]
var help = $( document.createElement( "img" ) );
help.attr( "src", "images/help.gif" )
	.attr( "width", this.width )
	.attr( "height", this.height );
help.on( "click", function() {
	$( this ).remove();
});
$( this.body.el.dom ).append( help );
\end{lstlisting}

Alles in allem wurden 43~Minuten für diese Hilfefunktion aufgewendet.

\subsection{Vorgestelltes Hilfekonzept}
\label{section:evaluation:entwicklungsaufwand:konzept}

Für die Integration der Bedienungshilfe in die Komponente müssen die notwendigen Informationen in die SMCDL Datei eingefügt werden. Wie im vorherigen Abschnitt auch wurde ein Kommilitone gebeten, diese Aufgabe auszuführen. Er hat bereits Erfahrung mit CRUISe Komponenten und integrierte z.\,B. die SIMILE Timeline. Nachdem er ein Tutorial\footnote{\url{https://trac.mmt.inf.tu-dresden.de/CRUISe/wiki/tutorials/assistance}, ein TRAC Account ist nötig.} gelesen hatte, sollte er die SMCDL \enquote{seiner} SIMILE Timeline entsprechend anpassen. Er benötigte nach eigenen Aussagen 10~Minuten, um das Tutorial zu lesen und 22~Minuten für die tatsächliche Umsetzung, also insgesamt 32~Minuten.

\subsection{Auswertung}
\label{section:evaluation:entwicklungsaufwand:auswertung}

Für die Integration einer individuellen Hilfefunktion waren 43~Minuten nötig; die SMCDL einer bestehenden Komponente anzupassen erforderte einen Zeitaufwand von 32~Minuten (Abbildung~\ref{figure:zeit}). Das vorgestellte Hilfekonzept kann also schneller integriert werden als individuelle Hilfefunktionen.

\begin{figure}[htbp]
   \centering
   \includegraphics[width=0.25\textwidth]{images/evaluation-zeit.png}
   \caption{Benötigte Zeit zur Integration}
   \label{figure:zeit}
\end{figure}

Der Unterschied beträgt aber nur 11~Minuten und es waren verschiedene Personen beteiligt, weswegen die Zahlen eher als Richtwerte zu sehen sind. Allerdings ist festzuhalten, dass das vorgestellte Hilfekonzept einige Vorteile gegenüber einer individuellen Hilfe hat.

Zunächst ist es flexibler: Kommen Funktionen hinzu oder werden welche im Laufe der Entwicklung entfernt, muss im Falle der individuellen Hilfe der ganze Prozess der Hilfeerstellung erneut durchlaufen werden. Das bedeutet Screenshots machen, in ein Grafikverarbeitungsprogramm wie Photoshop laden, dort die Hilfestellungen einfügen, exportieren, alle Bilder in eine andere Software laden und die Sequenz als GIF exportieren. Verwendet der Entwickler aber das vorgestellte Hilfekonzept, muss er nur die SMCDL anpassen und updaten.

Ein weiterer Vorteil ist die einfachere Wartbarkeit. Im vorgestellten Beispiel waren nur acht Zeilen Quellcode nötig, allerdings hindert den Komponentenentwickler nichts daran bessere und fortgeschrittenere Hilfefunktionen zu implementieren, die mehr Quellcode nötig machen. Dieser zusätzliche Quellcode, der beim vorgestellten Hilfekonzept nicht notwendig ist, erhöht die Komplexität der Software und macht sie damit schwieriger wartbar.

Zuletzt gibt es Eigenschaften, die mit einem individuellen Hilfesystem gar nicht umgesetzt werden können. Dazu gehören einheitliche Formulierungen, Interaktionen und Aussehen. Ein einheitliches Look and Feel ist jedoch wichtig für die Bedienbarkeit von Software (vgl. verwandte Arbeiten, Abschnitt~\ref{section:standderforschung:verwandte_arbeiten}).

\section{Zusammenfassung}

\chapter{Zusammenfassung und Ausblick}

\newpage % needed because of changing pagenumbering and missing backmatter
%\backmatter % no numbering (letters) of appendices, if backmatter activated
\pagenumbering{roman}

\appendix
\chapter{Anhang}

\section{Implementierung}

\subsection{JSON Format eines Kommentars}

\lstset{language=JSON}
\begin{lstlisting}
{
  "comment_id": "id",
  "user_id": "bob",
  "dataset_id": "testdataset",
  "component_id": "http://cruise/ui/SimileTimeline",
  "score": 0,
  "response_to": null, // id of other comment
  "memento": {
    "selection": null,
    "centerDate": "2011-09-14T12:00:00.000Z",
    "mousewheelscroll": true,
    "height": 375,
    "width": 600
  },
  "visualized_propertys": [
    // strings of form
    // dataset + class uri + property uri
  ],
  "versions": [
    {
      "number": 1,
      "text": "This is a test.",
      "timestamp": 1382258459433,
      "annotations": [{
        "uri": "http://dbpedia.org/resource/Date_Movie",
        "values": {
          // values of propertys
        },
        "type": "point"
      },
      {
        "type": "area",
        "visualization_width": 800,
        "visualization_height": 352,
        "elements": [
          {
            "type": "arrow",
            "x1": 56.75,
            "x2": 58.875,
            "y1": 20.738636,
            "y2": 42.613636
          },
          {
            "type": "text",
            "x": 51.375,
            "text": "Testcomment",
            "y": 17.329546
          }
        ]},
        {
          "type": "data",
          "items": [
            {
              "uri": "http://mmt.inf.tu-dresden.de/testdata/films#release",
              "from": "2010-01-20T06:00:00.000Z",
              "to": "2019-11-24T12:00:00.000Z"
            }]
         }]
     }]
  }
\end{lstlisting}

\subsection{RDF Format eines Kommentars}

\todo[inline]{Das muss ich noch machen, aber im Prinzip isses nur ein semantisches Äquivalent zum Java Klassendiagramm. Aber gut, man muss auch wissen, wie alles heißt.}

\subsection{Java Klassendiagramm eines Kommentars}

\begin{figure}[htbp]
   \centering
   \includegraphics[width=\textwidth]{images/implementierung-kommentare-klassendiagramm.png}
   \caption{Java Klassendiagramm für Kommentare}
   \label{figure:kommentare-klassendiagramm}
\end{figure}

\section{Evaluation}

\lstset{language=XML}
\begin{lstlisting}[caption={Beschreibung der Capabilities}, label=code:integration-capability]
<capability
	id="capPan"
	activity="action:Pan"
	entity="world:Movie"
	generateAssistance="true">
	
	<atomicoperation
		id="dblClick"
		element="div.timeline-band"
		type="op:DoubleClick"
		modifier="op:LeftButton" />
	
	<atomicoperation
		id="drag"
		element="div.timeline-band"
		type="op:Drag" />
	
	<atomicoperation
		id="scroll"
		element="div.timeline-band"
		type="op:Scroll" />
</capability>

<capability
	id="capSelect"
	activity="action:Select"
	entity="world:Movie"
	generateAssistance="true">
	
	<atomicoperation
		id="click"
		element="div.timeline-event-label"
		type="op:Click"
		modifier="op:LeftButton" />
</capability>
\end{lstlisting}

%#####################################################
\printbibliography[title=Literaturverzeichnis]

%\printindex

\end{document}